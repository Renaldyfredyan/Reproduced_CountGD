{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce5be0dd-7e43-4d6c-a1ac-5cc5bf02bfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/renaldy_fredyan/PhDResearch/CountGD/Reproduced_CountGD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced_CountGD/')\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "!export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92fc81c-00cd-4ad8-a822-763ba969ab43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "Loading config file from config/cfg_fsc147_vit_b_debug.py\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-08 13:18:55,999 | \u001b[34mgit:\n",
      "  sha: d3d2539b1c084bb62ba04308a2ace9b4476442ea, status: has uncommited changes, branch: main\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-08 13:18:56,001 | \u001b[34mCommand: main.py --output_dir ./gdino_train -c config/cfg_fsc147_vit_b_debug.py --datasets config/datasets_fsc147.json --pretrain_model_path checkpoints/groundingdino_swinb_cogcoor.pth --options text_encoder_type=checkpoints/bert-base-uncased\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-08 13:18:56,003 | \u001b[34mFull config saved to ./gdino_train/config_args_all.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-08 13:18:56,004 | \u001b[34mworld size: 1\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-08 13:18:56,005 | \u001b[34mrank: 0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-08 13:18:56,005 | \u001b[34mlocal_rank: 0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-08 13:18:56,006 | \u001b[34margs: Namespace(config_file='config/cfg_fsc147_vit_b_debug.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='config/datasets_fsc147.json', remove_difficult=False, fix_size=False, output_dir='./gdino_train', note='', device='cuda', seed=42, resume='', pretrain_model_path='checkpoints/groundingdino_swinb_cogcoor.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=2, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=30, lr_drop=10, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[10, 20], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=False, label_list=['alcohol bottle', 'baguette roll', 'ball', 'banana', 'bead', 'bee', 'birthday candle', 'biscuit', 'boat', 'bottle', 'bowl', 'box', 'bread roll', 'brick', 'buffalo', 'bun', 'calamari ring', 'can', 'candle', 'cap', 'car', 'cartridge', 'cassette', 'cement bag', 'cereal', 'chewing gum piece', 'chopstick', 'clam', 'coffee bean', 'coin', 'cotton ball', 'cow', 'crane', 'crayon', 'croissant', 'crow', 'cup', 'cupcake', 'cupcake holder', 'fish', 'gemstone', 'go game piece', 'goat', 'goldfish snack', 'goose', 'ice cream', 'ice cream cone', 'instant noodle', 'jade stone', 'jeans', 'kidney bean', 'kitchen towel', 'lighter', 'lipstick', 'm&m piece', 'macaron', 'match', 'meat skewer', 'mini blind', 'mosaic tile', 'naan bread', 'nail', 'nut', 'onion ring', 'orange', 'pearl', 'pen', 'pencil', 'penguin', 'pepper', 'person', 'pigeon', 'plate', 'polka dot tile', 'potato', 'rice bag', 'roof tile', 'screw', 'shoe', 'spoon', 'spring roll', 'stair', 'stapler pin', 'straw', 'supermarket shelf', 'swan', 'tomato', 'watermelon', 'window', 'zebra'], val_label_list=['ant', 'bird', 'book', 'bottle cap', 'bullet', 'camel', 'chair', 'chicken wing', 'donut', 'donut holder', 'flamingo', 'flower', 'flower pot', 'grape', 'horse', 'kiwi', 'milk carton', 'oyster', 'oyster shell', 'package of fresh cut fruit', 'peach', 'pill', 'polka dot', 'prawn cracker', 'sausage', 'seagull', 'shallot', 'shirt', 'skateboard', 'toilet paper roll'])\n",
      "\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-08 13:18:56,009 | \u001b[34mbuild model ... ...\u001b[0m\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755849709/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "final text_encoder_type: checkpoints/bert-base-uncased\n",
      "load tokenizer done.\n",
      "final text_encoder_type: checkpoints/bert-base-uncased\n",
      "load tokenizer done.\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-08 13:19:04,209 | \u001b[34mbuild model, done.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-08 13:19:04,214 | \u001b[34mnumber of params:236717952\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-08 13:19:04,219 | \u001b[34mparams before freezing:\n",
      "{\n",
      "  \"transformer.level_embed\": 1024,\n",
      "  \"transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.0.norm1.weight\": 256,\n",
      "  \"transformer.encoder.layers.0.norm1.bias\": 256,\n",
      "  \"transformer.encoder.layers.0.linear1.weight\": 524288,\n",
      "  \"transformer.encoder.layers.0.linear1.bias\": 2048,\n",
      "  \"transformer.encoder.layers.0.linear2.weight\": 524288,\n",
      "  \"transformer.encoder.layers.0.linear2.bias\": 256,\n",
      "  \"transformer.encoder.layers.0.norm2.weight\": 256,\n",
      "  \"transformer.encoder.layers.0.norm2.bias\": 256,\n",
      "  \"transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.1.norm1.weight\": 256,\n",
      "  \"transformer.encoder.layers.1.norm1.bias\": 256,\n",
      "  \"transformer.encoder.layers.1.linear1.weight\": 524288,\n",
      "  \"transformer.encoder.layers.1.linear1.bias\": 2048,\n",
      "  \"transformer.encoder.layers.1.linear2.weight\": 524288,\n",
      "  \"transformer.encoder.layers.1.linear2.bias\": 256,\n",
      "  \"transformer.encoder.layers.1.norm2.weight\": 256,\n",
      "  \"transformer.encoder.layers.1.norm2.bias\": 256,\n",
      "  \"transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.2.norm1.weight\": 256,\n",
      "  \"transformer.encoder.layers.2.norm1.bias\": 256,\n",
      "  \"transformer.encoder.layers.2.linear1.weight\": 524288,\n",
      "  \"transformer.encoder.layers.2.linear1.bias\": 2048,\n",
      "  \"transformer.encoder.layers.2.linear2.weight\": 524288,\n",
      "  \"transformer.encoder.layers.2.linear2.bias\": 256,\n",
      "  \"transformer.encoder.layers.2.norm2.weight\": 256,\n",
      "  \"transformer.encoder.layers.2.norm2.bias\": 256,\n",
      "  \"transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.3.norm1.weight\": 256,\n",
      "  \"transformer.encoder.layers.3.norm1.bias\": 256,\n",
      "  \"transformer.encoder.layers.3.linear1.weight\": 524288,\n",
      "  \"transformer.encoder.layers.3.linear1.bias\": 2048,\n",
      "  \"transformer.encoder.layers.3.linear2.weight\": 524288,\n",
      "  \"transformer.encoder.layers.3.linear2.bias\": 256,\n",
      "  \"transformer.encoder.layers.3.norm2.weight\": 256,\n",
      "  \"transformer.encoder.layers.3.norm2.bias\": 256,\n",
      "  \"transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.4.norm1.weight\": 256,\n",
      "  \"transformer.encoder.layers.4.norm1.bias\": 256,\n",
      "  \"transformer.encoder.layers.4.linear1.weight\": 524288,\n",
      "  \"transformer.encoder.layers.4.linear1.bias\": 2048,\n",
      "  \"transformer.encoder.layers.4.linear2.weight\": 524288,\n",
      "  \"transformer.encoder.layers.4.linear2.bias\": 256,\n",
      "  \"transformer.encoder.layers.4.norm2.weight\": 256,\n",
      "  \"transformer.encoder.layers.4.norm2.bias\": 256,\n",
      "  \"transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.5.norm1.weight\": 256,\n",
      "  \"transformer.encoder.layers.5.norm1.bias\": 256,\n",
      "  \"transformer.encoder.layers.5.linear1.weight\": 524288,\n",
      "  \"transformer.encoder.layers.5.linear1.bias\": 2048,\n",
      "  \"transformer.encoder.layers.5.linear2.weight\": 524288,\n",
      "  \"transformer.encoder.layers.5.linear2.bias\": 256,\n",
      "  \"transformer.encoder.layers.5.norm2.weight\": 256,\n",
      "  \"transformer.encoder.layers.5.norm2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
      "  \"transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
      "  \"transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
      "  \"transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
      "  \"transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
      "  \"transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
      "  \"transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
      "  \"transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
      "  \"transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
      "  \"transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
      "  \"transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
      "  \"transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
      "  \"transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
      "  \"transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
      "  \"transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
      "  \"transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
      "  \"transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
      "  \"transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
      "  \"transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.norm1.weight\": 256,\n",
      "  \"transformer.decoder.layers.0.norm1.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
      "  \"transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.norm2.weight\": 256,\n",
      "  \"transformer.decoder.layers.0.norm2.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.linear1.weight\": 524288,\n",
      "  \"transformer.decoder.layers.0.linear1.bias\": 2048,\n",
      "  \"transformer.decoder.layers.0.linear2.weight\": 524288,\n",
      "  \"transformer.decoder.layers.0.linear2.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.norm3.weight\": 256,\n",
      "  \"transformer.decoder.layers.0.norm3.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.norm1.weight\": 256,\n",
      "  \"transformer.decoder.layers.1.norm1.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
      "  \"transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.norm2.weight\": 256,\n",
      "  \"transformer.decoder.layers.1.norm2.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.linear1.weight\": 524288,\n",
      "  \"transformer.decoder.layers.1.linear1.bias\": 2048,\n",
      "  \"transformer.decoder.layers.1.linear2.weight\": 524288,\n",
      "  \"transformer.decoder.layers.1.linear2.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.norm3.weight\": 256,\n",
      "  \"transformer.decoder.layers.1.norm3.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.norm1.weight\": 256,\n",
      "  \"transformer.decoder.layers.2.norm1.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
      "  \"transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.norm2.weight\": 256,\n",
      "  \"transformer.decoder.layers.2.norm2.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.linear1.weight\": 524288,\n",
      "  \"transformer.decoder.layers.2.linear1.bias\": 2048,\n",
      "  \"transformer.decoder.layers.2.linear2.weight\": 524288,\n",
      "  \"transformer.decoder.layers.2.linear2.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.norm3.weight\": 256,\n",
      "  \"transformer.decoder.layers.2.norm3.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.norm1.weight\": 256,\n",
      "  \"transformer.decoder.layers.3.norm1.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
      "  \"transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.norm2.weight\": 256,\n",
      "  \"transformer.decoder.layers.3.norm2.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.linear1.weight\": 524288,\n",
      "  \"transformer.decoder.layers.3.linear1.bias\": 2048,\n",
      "  \"transformer.decoder.layers.3.linear2.weight\": 524288,\n",
      "  \"transformer.decoder.layers.3.linear2.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.norm3.weight\": 256,\n",
      "  \"transformer.decoder.layers.3.norm3.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.norm1.weight\": 256,\n",
      "  \"transformer.decoder.layers.4.norm1.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
      "  \"transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.norm2.weight\": 256,\n",
      "  \"transformer.decoder.layers.4.norm2.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.linear1.weight\": 524288,\n",
      "  \"transformer.decoder.layers.4.linear1.bias\": 2048,\n",
      "  \"transformer.decoder.layers.4.linear2.weight\": 524288,\n",
      "  \"transformer.decoder.layers.4.linear2.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.norm3.weight\": 256,\n",
      "  \"transformer.decoder.layers.4.norm3.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.norm1.weight\": 256,\n",
      "  \"transformer.decoder.layers.5.norm1.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
      "  \"transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.norm2.weight\": 256,\n",
      "  \"transformer.decoder.layers.5.norm2.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.linear1.weight\": 524288,\n",
      "  \"transformer.decoder.layers.5.linear1.bias\": 2048,\n",
      "  \"transformer.decoder.layers.5.linear2.weight\": 524288,\n",
      "  \"transformer.decoder.layers.5.linear2.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.norm3.weight\": 256,\n",
      "  \"transformer.decoder.layers.5.norm3.bias\": 256,\n",
      "  \"transformer.decoder.norm.weight\": 256,\n",
      "  \"transformer.decoder.norm.bias\": 256,\n",
      "  \"transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
      "  \"transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
      "  \"transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
      "  \"transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
      "  \"transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
      "  \"transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
      "  \"transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
      "  \"transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
      "  \"transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
      "  \"transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
      "  \"transformer.tgt_embed.weight\": 230400,\n",
      "  \"transformer.enc_output.weight\": 65536,\n",
      "  \"transformer.enc_output.bias\": 256,\n",
      "  \"transformer.enc_output_norm.weight\": 256,\n",
      "  \"transformer.enc_output_norm.bias\": 256,\n",
      "  \"transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
      "  \"transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
      "  \"transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
      "  \"transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
      "  \"transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
      "  \"transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
      "  \"feature_map_proj.weight\": 458752,\n",
      "  \"feature_map_proj.bias\": 256,\n",
      "  \"feature_map_encoder.layers.0.norm1.weight\": 256,\n",
      "  \"feature_map_encoder.layers.0.norm1.bias\": 256,\n",
      "  \"feature_map_encoder.layers.0.norm2.weight\": 256,\n",
      "  \"feature_map_encoder.layers.0.norm2.bias\": 256,\n",
      "  \"feature_map_encoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"feature_map_encoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"feature_map_encoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"feature_map_encoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"feature_map_encoder.layers.0.mlp.linear1.weight\": 524288,\n",
      "  \"feature_map_encoder.layers.0.mlp.linear1.bias\": 2048,\n",
      "  \"feature_map_encoder.layers.0.mlp.linear2.weight\": 524288,\n",
      "  \"feature_map_encoder.layers.0.mlp.linear2.bias\": 256,\n",
      "  \"feature_map_encoder.layers.1.norm1.weight\": 256,\n",
      "  \"feature_map_encoder.layers.1.norm1.bias\": 256,\n",
      "  \"feature_map_encoder.layers.1.norm2.weight\": 256,\n",
      "  \"feature_map_encoder.layers.1.norm2.bias\": 256,\n",
      "  \"feature_map_encoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"feature_map_encoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"feature_map_encoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"feature_map_encoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"feature_map_encoder.layers.1.mlp.linear1.weight\": 524288,\n",
      "  \"feature_map_encoder.layers.1.mlp.linear1.bias\": 2048,\n",
      "  \"feature_map_encoder.layers.1.mlp.linear2.weight\": 524288,\n",
      "  \"feature_map_encoder.layers.1.mlp.linear2.bias\": 256,\n",
      "  \"feature_map_encoder.layers.2.norm1.weight\": 256,\n",
      "  \"feature_map_encoder.layers.2.norm1.bias\": 256,\n",
      "  \"feature_map_encoder.layers.2.norm2.weight\": 256,\n",
      "  \"feature_map_encoder.layers.2.norm2.bias\": 256,\n",
      "  \"feature_map_encoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"feature_map_encoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"feature_map_encoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"feature_map_encoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"feature_map_encoder.layers.2.mlp.linear1.weight\": 524288,\n",
      "  \"feature_map_encoder.layers.2.mlp.linear1.bias\": 2048,\n",
      "  \"feature_map_encoder.layers.2.mlp.linear2.weight\": 524288,\n",
      "  \"feature_map_encoder.layers.2.mlp.linear2.bias\": 256,\n",
      "  \"feature_map_encoder.norm.weight\": 256,\n",
      "  \"feature_map_encoder.norm.bias\": 256,\n",
      "  \"bert.embeddings.word_embeddings.weight\": 23440896,\n",
      "  \"bert.embeddings.position_embeddings.weight\": 393216,\n",
      "  \"bert.embeddings.token_type_embeddings.weight\": 1536,\n",
      "  \"bert.embeddings.LayerNorm.weight\": 768,\n",
      "  \"bert.embeddings.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.0.attention.self.query.weight\": 589824,\n",
      "  \"bert.encoder.layer.0.attention.self.query.bias\": 768,\n",
      "  \"bert.encoder.layer.0.attention.self.key.weight\": 589824,\n",
      "  \"bert.encoder.layer.0.attention.self.key.bias\": 768,\n",
      "  \"bert.encoder.layer.0.attention.self.value.weight\": 589824,\n",
      "  \"bert.encoder.layer.0.attention.self.value.bias\": 768,\n",
      "  \"bert.encoder.layer.0.attention.output.dense.weight\": 589824,\n",
      "  \"bert.encoder.layer.0.attention.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.0.attention.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.0.attention.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.0.intermediate.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.0.intermediate.dense.bias\": 3072,\n",
      "  \"bert.encoder.layer.0.output.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.0.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.0.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.0.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.1.attention.self.query.weight\": 589824,\n",
      "  \"bert.encoder.layer.1.attention.self.query.bias\": 768,\n",
      "  \"bert.encoder.layer.1.attention.self.key.weight\": 589824,\n",
      "  \"bert.encoder.layer.1.attention.self.key.bias\": 768,\n",
      "  \"bert.encoder.layer.1.attention.self.value.weight\": 589824,\n",
      "  \"bert.encoder.layer.1.attention.self.value.bias\": 768,\n",
      "  \"bert.encoder.layer.1.attention.output.dense.weight\": 589824,\n",
      "  \"bert.encoder.layer.1.attention.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.1.attention.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.1.attention.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.1.intermediate.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.1.intermediate.dense.bias\": 3072,\n",
      "  \"bert.encoder.layer.1.output.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.1.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.1.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.1.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.2.attention.self.query.weight\": 589824,\n",
      "  \"bert.encoder.layer.2.attention.self.query.bias\": 768,\n",
      "  \"bert.encoder.layer.2.attention.self.key.weight\": 589824,\n",
      "  \"bert.encoder.layer.2.attention.self.key.bias\": 768,\n",
      "  \"bert.encoder.layer.2.attention.self.value.weight\": 589824,\n",
      "  \"bert.encoder.layer.2.attention.self.value.bias\": 768,\n",
      "  \"bert.encoder.layer.2.attention.output.dense.weight\": 589824,\n",
      "  \"bert.encoder.layer.2.attention.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.2.attention.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.2.attention.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.2.intermediate.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.2.intermediate.dense.bias\": 3072,\n",
      "  \"bert.encoder.layer.2.output.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.2.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.2.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.2.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.3.attention.self.query.weight\": 589824,\n",
      "  \"bert.encoder.layer.3.attention.self.query.bias\": 768,\n",
      "  \"bert.encoder.layer.3.attention.self.key.weight\": 589824,\n",
      "  \"bert.encoder.layer.3.attention.self.key.bias\": 768,\n",
      "  \"bert.encoder.layer.3.attention.self.value.weight\": 589824,\n",
      "  \"bert.encoder.layer.3.attention.self.value.bias\": 768,\n",
      "  \"bert.encoder.layer.3.attention.output.dense.weight\": 589824,\n",
      "  \"bert.encoder.layer.3.attention.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.3.attention.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.3.attention.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.3.intermediate.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.3.intermediate.dense.bias\": 3072,\n",
      "  \"bert.encoder.layer.3.output.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.3.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.3.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.3.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.4.attention.self.query.weight\": 589824,\n",
      "  \"bert.encoder.layer.4.attention.self.query.bias\": 768,\n",
      "  \"bert.encoder.layer.4.attention.self.key.weight\": 589824,\n",
      "  \"bert.encoder.layer.4.attention.self.key.bias\": 768,\n",
      "  \"bert.encoder.layer.4.attention.self.value.weight\": 589824,\n",
      "  \"bert.encoder.layer.4.attention.self.value.bias\": 768,\n",
      "  \"bert.encoder.layer.4.attention.output.dense.weight\": 589824,\n",
      "  \"bert.encoder.layer.4.attention.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.4.attention.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.4.attention.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.4.intermediate.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.4.intermediate.dense.bias\": 3072,\n",
      "  \"bert.encoder.layer.4.output.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.4.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.4.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.4.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.5.attention.self.query.weight\": 589824,\n",
      "  \"bert.encoder.layer.5.attention.self.query.bias\": 768,\n",
      "  \"bert.encoder.layer.5.attention.self.key.weight\": 589824,\n",
      "  \"bert.encoder.layer.5.attention.self.key.bias\": 768,\n",
      "  \"bert.encoder.layer.5.attention.self.value.weight\": 589824,\n",
      "  \"bert.encoder.layer.5.attention.self.value.bias\": 768,\n",
      "  \"bert.encoder.layer.5.attention.output.dense.weight\": 589824,\n",
      "  \"bert.encoder.layer.5.attention.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.5.attention.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.5.attention.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.5.intermediate.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.5.intermediate.dense.bias\": 3072,\n",
      "  \"bert.encoder.layer.5.output.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.5.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.5.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.5.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.6.attention.self.query.weight\": 589824,\n",
      "  \"bert.encoder.layer.6.attention.self.query.bias\": 768,\n",
      "  \"bert.encoder.layer.6.attention.self.key.weight\": 589824,\n",
      "  \"bert.encoder.layer.6.attention.self.key.bias\": 768,\n",
      "  \"bert.encoder.layer.6.attention.self.value.weight\": 589824,\n",
      "  \"bert.encoder.layer.6.attention.self.value.bias\": 768,\n",
      "  \"bert.encoder.layer.6.attention.output.dense.weight\": 589824,\n",
      "  \"bert.encoder.layer.6.attention.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.6.attention.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.6.attention.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.6.intermediate.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.6.intermediate.dense.bias\": 3072,\n",
      "  \"bert.encoder.layer.6.output.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.6.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.6.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.6.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.7.attention.self.query.weight\": 589824,\n",
      "  \"bert.encoder.layer.7.attention.self.query.bias\": 768,\n",
      "  \"bert.encoder.layer.7.attention.self.key.weight\": 589824,\n",
      "  \"bert.encoder.layer.7.attention.self.key.bias\": 768,\n",
      "  \"bert.encoder.layer.7.attention.self.value.weight\": 589824,\n",
      "  \"bert.encoder.layer.7.attention.self.value.bias\": 768,\n",
      "  \"bert.encoder.layer.7.attention.output.dense.weight\": 589824,\n",
      "  \"bert.encoder.layer.7.attention.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.7.attention.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.7.attention.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.7.intermediate.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.7.intermediate.dense.bias\": 3072,\n",
      "  \"bert.encoder.layer.7.output.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.7.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.7.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.7.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.8.attention.self.query.weight\": 589824,\n",
      "  \"bert.encoder.layer.8.attention.self.query.bias\": 768,\n",
      "  \"bert.encoder.layer.8.attention.self.key.weight\": 589824,\n",
      "  \"bert.encoder.layer.8.attention.self.key.bias\": 768,\n",
      "  \"bert.encoder.layer.8.attention.self.value.weight\": 589824,\n",
      "  \"bert.encoder.layer.8.attention.self.value.bias\": 768,\n",
      "  \"bert.encoder.layer.8.attention.output.dense.weight\": 589824,\n",
      "  \"bert.encoder.layer.8.attention.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.8.attention.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.8.attention.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.8.intermediate.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.8.intermediate.dense.bias\": 3072,\n",
      "  \"bert.encoder.layer.8.output.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.8.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.8.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.8.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.9.attention.self.query.weight\": 589824,\n",
      "  \"bert.encoder.layer.9.attention.self.query.bias\": 768,\n",
      "  \"bert.encoder.layer.9.attention.self.key.weight\": 589824,\n",
      "  \"bert.encoder.layer.9.attention.self.key.bias\": 768,\n",
      "  \"bert.encoder.layer.9.attention.self.value.weight\": 589824,\n",
      "  \"bert.encoder.layer.9.attention.self.value.bias\": 768,\n",
      "  \"bert.encoder.layer.9.attention.output.dense.weight\": 589824,\n",
      "  \"bert.encoder.layer.9.attention.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.9.attention.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.9.attention.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.9.intermediate.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.9.intermediate.dense.bias\": 3072,\n",
      "  \"bert.encoder.layer.9.output.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.9.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.9.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.9.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.10.attention.self.query.weight\": 589824,\n",
      "  \"bert.encoder.layer.10.attention.self.query.bias\": 768,\n",
      "  \"bert.encoder.layer.10.attention.self.key.weight\": 589824,\n",
      "  \"bert.encoder.layer.10.attention.self.key.bias\": 768,\n",
      "  \"bert.encoder.layer.10.attention.self.value.weight\": 589824,\n",
      "  \"bert.encoder.layer.10.attention.self.value.bias\": 768,\n",
      "  \"bert.encoder.layer.10.attention.output.dense.weight\": 589824,\n",
      "  \"bert.encoder.layer.10.attention.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.10.attention.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.10.attention.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.10.intermediate.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.10.intermediate.dense.bias\": 3072,\n",
      "  \"bert.encoder.layer.10.output.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.10.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.10.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.10.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.11.attention.self.query.weight\": 589824,\n",
      "  \"bert.encoder.layer.11.attention.self.query.bias\": 768,\n",
      "  \"bert.encoder.layer.11.attention.self.key.weight\": 589824,\n",
      "  \"bert.encoder.layer.11.attention.self.key.bias\": 768,\n",
      "  \"bert.encoder.layer.11.attention.self.value.weight\": 589824,\n",
      "  \"bert.encoder.layer.11.attention.self.value.bias\": 768,\n",
      "  \"bert.encoder.layer.11.attention.output.dense.weight\": 589824,\n",
      "  \"bert.encoder.layer.11.attention.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.11.attention.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.11.attention.output.LayerNorm.bias\": 768,\n",
      "  \"bert.encoder.layer.11.intermediate.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.11.intermediate.dense.bias\": 3072,\n",
      "  \"bert.encoder.layer.11.output.dense.weight\": 2359296,\n",
      "  \"bert.encoder.layer.11.output.dense.bias\": 768,\n",
      "  \"bert.encoder.layer.11.output.LayerNorm.weight\": 768,\n",
      "  \"bert.encoder.layer.11.output.LayerNorm.bias\": 768,\n",
      "  \"feat_map.weight\": 196608,\n",
      "  \"feat_map.bias\": 256,\n",
      "  \"input_proj.0.0.weight\": 65536,\n",
      "  \"input_proj.0.0.bias\": 256,\n",
      "  \"input_proj.0.1.weight\": 256,\n",
      "  \"input_proj.0.1.bias\": 256,\n",
      "  \"input_proj.1.0.weight\": 131072,\n",
      "  \"input_proj.1.0.bias\": 256,\n",
      "  \"input_proj.1.1.weight\": 256,\n",
      "  \"input_proj.1.1.bias\": 256,\n",
      "  \"input_proj.2.0.weight\": 262144,\n",
      "  \"input_proj.2.0.bias\": 256,\n",
      "  \"input_proj.2.1.weight\": 256,\n",
      "  \"input_proj.2.1.bias\": 256,\n",
      "  \"input_proj.3.0.weight\": 2359296,\n",
      "  \"input_proj.3.0.bias\": 256,\n",
      "  \"input_proj.3.1.weight\": 256,\n",
      "  \"input_proj.3.1.bias\": 256,\n",
      "  \"backbone.0.patch_embed.proj.weight\": 6144,\n",
      "  \"backbone.0.patch_embed.proj.bias\": 128,\n",
      "  \"backbone.0.patch_embed.norm.weight\": 128,\n",
      "  \"backbone.0.patch_embed.norm.bias\": 128,\n",
      "  \"backbone.0.layers.0.blocks.0.norm1.weight\": 128,\n",
      "  \"backbone.0.layers.0.blocks.0.norm1.bias\": 128,\n",
      "  \"backbone.0.layers.0.blocks.0.attn.relative_position_bias_table\": 2116,\n",
      "  \"backbone.0.layers.0.blocks.0.attn.qkv.weight\": 49152,\n",
      "  \"backbone.0.layers.0.blocks.0.attn.qkv.bias\": 384,\n",
      "  \"backbone.0.layers.0.blocks.0.attn.proj.weight\": 16384,\n",
      "  \"backbone.0.layers.0.blocks.0.attn.proj.bias\": 128,\n",
      "  \"backbone.0.layers.0.blocks.0.norm2.weight\": 128,\n",
      "  \"backbone.0.layers.0.blocks.0.norm2.bias\": 128,\n",
      "  \"backbone.0.layers.0.blocks.0.mlp.fc1.weight\": 65536,\n",
      "  \"backbone.0.layers.0.blocks.0.mlp.fc1.bias\": 512,\n",
      "  \"backbone.0.layers.0.blocks.0.mlp.fc2.weight\": 65536,\n",
      "  \"backbone.0.layers.0.blocks.0.mlp.fc2.bias\": 128,\n",
      "  \"backbone.0.layers.0.blocks.1.norm1.weight\": 128,\n",
      "  \"backbone.0.layers.0.blocks.1.norm1.bias\": 128,\n",
      "  \"backbone.0.layers.0.blocks.1.attn.relative_position_bias_table\": 2116,\n",
      "  \"backbone.0.layers.0.blocks.1.attn.qkv.weight\": 49152,\n",
      "  \"backbone.0.layers.0.blocks.1.attn.qkv.bias\": 384,\n",
      "  \"backbone.0.layers.0.blocks.1.attn.proj.weight\": 16384,\n",
      "  \"backbone.0.layers.0.blocks.1.attn.proj.bias\": 128,\n",
      "  \"backbone.0.layers.0.blocks.1.norm2.weight\": 128,\n",
      "  \"backbone.0.layers.0.blocks.1.norm2.bias\": 128,\n",
      "  \"backbone.0.layers.0.blocks.1.mlp.fc1.weight\": 65536,\n",
      "  \"backbone.0.layers.0.blocks.1.mlp.fc1.bias\": 512,\n",
      "  \"backbone.0.layers.0.blocks.1.mlp.fc2.weight\": 65536,\n",
      "  \"backbone.0.layers.0.blocks.1.mlp.fc2.bias\": 128,\n",
      "  \"backbone.0.layers.0.downsample.reduction.weight\": 131072,\n",
      "  \"backbone.0.layers.0.downsample.norm.weight\": 512,\n",
      "  \"backbone.0.layers.0.downsample.norm.bias\": 512,\n",
      "  \"backbone.0.layers.1.blocks.0.norm1.weight\": 256,\n",
      "  \"backbone.0.layers.1.blocks.0.norm1.bias\": 256,\n",
      "  \"backbone.0.layers.1.blocks.0.attn.relative_position_bias_table\": 4232,\n",
      "  \"backbone.0.layers.1.blocks.0.attn.qkv.weight\": 196608,\n",
      "  \"backbone.0.layers.1.blocks.0.attn.qkv.bias\": 768,\n",
      "  \"backbone.0.layers.1.blocks.0.attn.proj.weight\": 65536,\n",
      "  \"backbone.0.layers.1.blocks.0.attn.proj.bias\": 256,\n",
      "  \"backbone.0.layers.1.blocks.0.norm2.weight\": 256,\n",
      "  \"backbone.0.layers.1.blocks.0.norm2.bias\": 256,\n",
      "  \"backbone.0.layers.1.blocks.0.mlp.fc1.weight\": 262144,\n",
      "  \"backbone.0.layers.1.blocks.0.mlp.fc1.bias\": 1024,\n",
      "  \"backbone.0.layers.1.blocks.0.mlp.fc2.weight\": 262144,\n",
      "  \"backbone.0.layers.1.blocks.0.mlp.fc2.bias\": 256,\n",
      "  \"backbone.0.layers.1.blocks.1.norm1.weight\": 256,\n",
      "  \"backbone.0.layers.1.blocks.1.norm1.bias\": 256,\n",
      "  \"backbone.0.layers.1.blocks.1.attn.relative_position_bias_table\": 4232,\n",
      "  \"backbone.0.layers.1.blocks.1.attn.qkv.weight\": 196608,\n",
      "  \"backbone.0.layers.1.blocks.1.attn.qkv.bias\": 768,\n",
      "  \"backbone.0.layers.1.blocks.1.attn.proj.weight\": 65536,\n",
      "  \"backbone.0.layers.1.blocks.1.attn.proj.bias\": 256,\n",
      "  \"backbone.0.layers.1.blocks.1.norm2.weight\": 256,\n",
      "  \"backbone.0.layers.1.blocks.1.norm2.bias\": 256,\n",
      "  \"backbone.0.layers.1.blocks.1.mlp.fc1.weight\": 262144,\n",
      "  \"backbone.0.layers.1.blocks.1.mlp.fc1.bias\": 1024,\n",
      "  \"backbone.0.layers.1.blocks.1.mlp.fc2.weight\": 262144,\n",
      "  \"backbone.0.layers.1.blocks.1.mlp.fc2.bias\": 256,\n",
      "  \"backbone.0.layers.1.downsample.reduction.weight\": 524288,\n",
      "  \"backbone.0.layers.1.downsample.norm.weight\": 1024,\n",
      "  \"backbone.0.layers.1.downsample.norm.bias\": 1024,\n",
      "  \"backbone.0.layers.2.blocks.0.norm1.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.0.norm1.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.0.attn.relative_position_bias_table\": 8464,\n",
      "  \"backbone.0.layers.2.blocks.0.attn.qkv.weight\": 786432,\n",
      "  \"backbone.0.layers.2.blocks.0.attn.qkv.bias\": 1536,\n",
      "  \"backbone.0.layers.2.blocks.0.attn.proj.weight\": 262144,\n",
      "  \"backbone.0.layers.2.blocks.0.attn.proj.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.0.norm2.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.0.norm2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.0.mlp.fc1.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.0.mlp.fc1.bias\": 2048,\n",
      "  \"backbone.0.layers.2.blocks.0.mlp.fc2.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.0.mlp.fc2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.1.norm1.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.1.norm1.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.1.attn.relative_position_bias_table\": 8464,\n",
      "  \"backbone.0.layers.2.blocks.1.attn.qkv.weight\": 786432,\n",
      "  \"backbone.0.layers.2.blocks.1.attn.qkv.bias\": 1536,\n",
      "  \"backbone.0.layers.2.blocks.1.attn.proj.weight\": 262144,\n",
      "  \"backbone.0.layers.2.blocks.1.attn.proj.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.1.norm2.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.1.norm2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.1.mlp.fc1.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.1.mlp.fc1.bias\": 2048,\n",
      "  \"backbone.0.layers.2.blocks.1.mlp.fc2.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.1.mlp.fc2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.2.norm1.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.2.norm1.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.2.attn.relative_position_bias_table\": 8464,\n",
      "  \"backbone.0.layers.2.blocks.2.attn.qkv.weight\": 786432,\n",
      "  \"backbone.0.layers.2.blocks.2.attn.qkv.bias\": 1536,\n",
      "  \"backbone.0.layers.2.blocks.2.attn.proj.weight\": 262144,\n",
      "  \"backbone.0.layers.2.blocks.2.attn.proj.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.2.norm2.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.2.norm2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.2.mlp.fc1.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.2.mlp.fc1.bias\": 2048,\n",
      "  \"backbone.0.layers.2.blocks.2.mlp.fc2.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.2.mlp.fc2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.3.norm1.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.3.norm1.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.3.attn.relative_position_bias_table\": 8464,\n",
      "  \"backbone.0.layers.2.blocks.3.attn.qkv.weight\": 786432,\n",
      "  \"backbone.0.layers.2.blocks.3.attn.qkv.bias\": 1536,\n",
      "  \"backbone.0.layers.2.blocks.3.attn.proj.weight\": 262144,\n",
      "  \"backbone.0.layers.2.blocks.3.attn.proj.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.3.norm2.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.3.norm2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.3.mlp.fc1.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.3.mlp.fc1.bias\": 2048,\n",
      "  \"backbone.0.layers.2.blocks.3.mlp.fc2.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.3.mlp.fc2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.4.norm1.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.4.norm1.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.4.attn.relative_position_bias_table\": 8464,\n",
      "  \"backbone.0.layers.2.blocks.4.attn.qkv.weight\": 786432,\n",
      "  \"backbone.0.layers.2.blocks.4.attn.qkv.bias\": 1536,\n",
      "  \"backbone.0.layers.2.blocks.4.attn.proj.weight\": 262144,\n",
      "  \"backbone.0.layers.2.blocks.4.attn.proj.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.4.norm2.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.4.norm2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.4.mlp.fc1.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.4.mlp.fc1.bias\": 2048,\n",
      "  \"backbone.0.layers.2.blocks.4.mlp.fc2.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.4.mlp.fc2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.5.norm1.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.5.norm1.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.5.attn.relative_position_bias_table\": 8464,\n",
      "  \"backbone.0.layers.2.blocks.5.attn.qkv.weight\": 786432,\n",
      "  \"backbone.0.layers.2.blocks.5.attn.qkv.bias\": 1536,\n",
      "  \"backbone.0.layers.2.blocks.5.attn.proj.weight\": 262144,\n",
      "  \"backbone.0.layers.2.blocks.5.attn.proj.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.5.norm2.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.5.norm2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.5.mlp.fc1.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.5.mlp.fc1.bias\": 2048,\n",
      "  \"backbone.0.layers.2.blocks.5.mlp.fc2.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.5.mlp.fc2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.6.norm1.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.6.norm1.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.6.attn.relative_position_bias_table\": 8464,\n",
      "  \"backbone.0.layers.2.blocks.6.attn.qkv.weight\": 786432,\n",
      "  \"backbone.0.layers.2.blocks.6.attn.qkv.bias\": 1536,\n",
      "  \"backbone.0.layers.2.blocks.6.attn.proj.weight\": 262144,\n",
      "  \"backbone.0.layers.2.blocks.6.attn.proj.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.6.norm2.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.6.norm2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.6.mlp.fc1.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.6.mlp.fc1.bias\": 2048,\n",
      "  \"backbone.0.layers.2.blocks.6.mlp.fc2.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.6.mlp.fc2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.7.norm1.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.7.norm1.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.7.attn.relative_position_bias_table\": 8464,\n",
      "  \"backbone.0.layers.2.blocks.7.attn.qkv.weight\": 786432,\n",
      "  \"backbone.0.layers.2.blocks.7.attn.qkv.bias\": 1536,\n",
      "  \"backbone.0.layers.2.blocks.7.attn.proj.weight\": 262144,\n",
      "  \"backbone.0.layers.2.blocks.7.attn.proj.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.7.norm2.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.7.norm2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.7.mlp.fc1.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.7.mlp.fc1.bias\": 2048,\n",
      "  \"backbone.0.layers.2.blocks.7.mlp.fc2.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.7.mlp.fc2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.8.norm1.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.8.norm1.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.8.attn.relative_position_bias_table\": 8464,\n",
      "  \"backbone.0.layers.2.blocks.8.attn.qkv.weight\": 786432,\n",
      "  \"backbone.0.layers.2.blocks.8.attn.qkv.bias\": 1536,\n",
      "  \"backbone.0.layers.2.blocks.8.attn.proj.weight\": 262144,\n",
      "  \"backbone.0.layers.2.blocks.8.attn.proj.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.8.norm2.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.8.norm2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.8.mlp.fc1.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.8.mlp.fc1.bias\": 2048,\n",
      "  \"backbone.0.layers.2.blocks.8.mlp.fc2.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.8.mlp.fc2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.9.norm1.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.9.norm1.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.9.attn.relative_position_bias_table\": 8464,\n",
      "  \"backbone.0.layers.2.blocks.9.attn.qkv.weight\": 786432,\n",
      "  \"backbone.0.layers.2.blocks.9.attn.qkv.bias\": 1536,\n",
      "  \"backbone.0.layers.2.blocks.9.attn.proj.weight\": 262144,\n",
      "  \"backbone.0.layers.2.blocks.9.attn.proj.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.9.norm2.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.9.norm2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.9.mlp.fc1.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.9.mlp.fc1.bias\": 2048,\n",
      "  \"backbone.0.layers.2.blocks.9.mlp.fc2.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.9.mlp.fc2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.10.norm1.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.10.norm1.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.10.attn.relative_position_bias_table\": 8464,\n",
      "  \"backbone.0.layers.2.blocks.10.attn.qkv.weight\": 786432,\n",
      "  \"backbone.0.layers.2.blocks.10.attn.qkv.bias\": 1536,\n",
      "  \"backbone.0.layers.2.blocks.10.attn.proj.weight\": 262144,\n",
      "  \"backbone.0.layers.2.blocks.10.attn.proj.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.10.norm2.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.10.norm2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.10.mlp.fc1.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.10.mlp.fc1.bias\": 2048,\n",
      "  \"backbone.0.layers.2.blocks.10.mlp.fc2.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.10.mlp.fc2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.11.norm1.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.11.norm1.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.11.attn.relative_position_bias_table\": 8464,\n",
      "  \"backbone.0.layers.2.blocks.11.attn.qkv.weight\": 786432,\n",
      "  \"backbone.0.layers.2.blocks.11.attn.qkv.bias\": 1536,\n",
      "  \"backbone.0.layers.2.blocks.11.attn.proj.weight\": 262144,\n",
      "  \"backbone.0.layers.2.blocks.11.attn.proj.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.11.norm2.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.11.norm2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.11.mlp.fc1.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.11.mlp.fc1.bias\": 2048,\n",
      "  \"backbone.0.layers.2.blocks.11.mlp.fc2.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.11.mlp.fc2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.12.norm1.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.12.norm1.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.12.attn.relative_position_bias_table\": 8464,\n",
      "  \"backbone.0.layers.2.blocks.12.attn.qkv.weight\": 786432,\n",
      "  \"backbone.0.layers.2.blocks.12.attn.qkv.bias\": 1536,\n",
      "  \"backbone.0.layers.2.blocks.12.attn.proj.weight\": 262144,\n",
      "  \"backbone.0.layers.2.blocks.12.attn.proj.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.12.norm2.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.12.norm2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.12.mlp.fc1.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.12.mlp.fc1.bias\": 2048,\n",
      "  \"backbone.0.layers.2.blocks.12.mlp.fc2.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.12.mlp.fc2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.13.norm1.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.13.norm1.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.13.attn.relative_position_bias_table\": 8464,\n",
      "  \"backbone.0.layers.2.blocks.13.attn.qkv.weight\": 786432,\n",
      "  \"backbone.0.layers.2.blocks.13.attn.qkv.bias\": 1536,\n",
      "  \"backbone.0.layers.2.blocks.13.attn.proj.weight\": 262144,\n",
      "  \"backbone.0.layers.2.blocks.13.attn.proj.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.13.norm2.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.13.norm2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.13.mlp.fc1.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.13.mlp.fc1.bias\": 2048,\n",
      "  \"backbone.0.layers.2.blocks.13.mlp.fc2.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.13.mlp.fc2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.14.norm1.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.14.norm1.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.14.attn.relative_position_bias_table\": 8464,\n",
      "  \"backbone.0.layers.2.blocks.14.attn.qkv.weight\": 786432,\n",
      "  \"backbone.0.layers.2.blocks.14.attn.qkv.bias\": 1536,\n",
      "  \"backbone.0.layers.2.blocks.14.attn.proj.weight\": 262144,\n",
      "  \"backbone.0.layers.2.blocks.14.attn.proj.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.14.norm2.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.14.norm2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.14.mlp.fc1.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.14.mlp.fc1.bias\": 2048,\n",
      "  \"backbone.0.layers.2.blocks.14.mlp.fc2.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.14.mlp.fc2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.15.norm1.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.15.norm1.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.15.attn.relative_position_bias_table\": 8464,\n",
      "  \"backbone.0.layers.2.blocks.15.attn.qkv.weight\": 786432,\n",
      "  \"backbone.0.layers.2.blocks.15.attn.qkv.bias\": 1536,\n",
      "  \"backbone.0.layers.2.blocks.15.attn.proj.weight\": 262144,\n",
      "  \"backbone.0.layers.2.blocks.15.attn.proj.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.15.norm2.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.15.norm2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.15.mlp.fc1.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.15.mlp.fc1.bias\": 2048,\n",
      "  \"backbone.0.layers.2.blocks.15.mlp.fc2.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.15.mlp.fc2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.16.norm1.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.16.norm1.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.16.attn.relative_position_bias_table\": 8464,\n",
      "  \"backbone.0.layers.2.blocks.16.attn.qkv.weight\": 786432,\n",
      "  \"backbone.0.layers.2.blocks.16.attn.qkv.bias\": 1536,\n",
      "  \"backbone.0.layers.2.blocks.16.attn.proj.weight\": 262144,\n",
      "  \"backbone.0.layers.2.blocks.16.attn.proj.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.16.norm2.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.16.norm2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.16.mlp.fc1.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.16.mlp.fc1.bias\": 2048,\n",
      "  \"backbone.0.layers.2.blocks.16.mlp.fc2.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.16.mlp.fc2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.17.norm1.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.17.norm1.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.17.attn.relative_position_bias_table\": 8464,\n",
      "  \"backbone.0.layers.2.blocks.17.attn.qkv.weight\": 786432,\n",
      "  \"backbone.0.layers.2.blocks.17.attn.qkv.bias\": 1536,\n",
      "  \"backbone.0.layers.2.blocks.17.attn.proj.weight\": 262144,\n",
      "  \"backbone.0.layers.2.blocks.17.attn.proj.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.17.norm2.weight\": 512,\n",
      "  \"backbone.0.layers.2.blocks.17.norm2.bias\": 512,\n",
      "  \"backbone.0.layers.2.blocks.17.mlp.fc1.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.17.mlp.fc1.bias\": 2048,\n",
      "  \"backbone.0.layers.2.blocks.17.mlp.fc2.weight\": 1048576,\n",
      "  \"backbone.0.layers.2.blocks.17.mlp.fc2.bias\": 512,\n",
      "  \"backbone.0.layers.2.downsample.reduction.weight\": 2097152,\n",
      "  \"backbone.0.layers.2.downsample.norm.weight\": 2048,\n",
      "  \"backbone.0.layers.2.downsample.norm.bias\": 2048,\n",
      "  \"backbone.0.layers.3.blocks.0.norm1.weight\": 1024,\n",
      "  \"backbone.0.layers.3.blocks.0.norm1.bias\": 1024,\n",
      "  \"backbone.0.layers.3.blocks.0.attn.relative_position_bias_table\": 16928,\n",
      "  \"backbone.0.layers.3.blocks.0.attn.qkv.weight\": 3145728,\n",
      "  \"backbone.0.layers.3.blocks.0.attn.qkv.bias\": 3072,\n",
      "  \"backbone.0.layers.3.blocks.0.attn.proj.weight\": 1048576,\n",
      "  \"backbone.0.layers.3.blocks.0.attn.proj.bias\": 1024,\n",
      "  \"backbone.0.layers.3.blocks.0.norm2.weight\": 1024,\n",
      "  \"backbone.0.layers.3.blocks.0.norm2.bias\": 1024,\n",
      "  \"backbone.0.layers.3.blocks.0.mlp.fc1.weight\": 4194304,\n",
      "  \"backbone.0.layers.3.blocks.0.mlp.fc1.bias\": 4096,\n",
      "  \"backbone.0.layers.3.blocks.0.mlp.fc2.weight\": 4194304,\n",
      "  \"backbone.0.layers.3.blocks.0.mlp.fc2.bias\": 1024,\n",
      "  \"backbone.0.layers.3.blocks.1.norm1.weight\": 1024,\n",
      "  \"backbone.0.layers.3.blocks.1.norm1.bias\": 1024,\n",
      "  \"backbone.0.layers.3.blocks.1.attn.relative_position_bias_table\": 16928,\n",
      "  \"backbone.0.layers.3.blocks.1.attn.qkv.weight\": 3145728,\n",
      "  \"backbone.0.layers.3.blocks.1.attn.qkv.bias\": 3072,\n",
      "  \"backbone.0.layers.3.blocks.1.attn.proj.weight\": 1048576,\n",
      "  \"backbone.0.layers.3.blocks.1.attn.proj.bias\": 1024,\n",
      "  \"backbone.0.layers.3.blocks.1.norm2.weight\": 1024,\n",
      "  \"backbone.0.layers.3.blocks.1.norm2.bias\": 1024,\n",
      "  \"backbone.0.layers.3.blocks.1.mlp.fc1.weight\": 4194304,\n",
      "  \"backbone.0.layers.3.blocks.1.mlp.fc1.bias\": 4096,\n",
      "  \"backbone.0.layers.3.blocks.1.mlp.fc2.weight\": 4194304,\n",
      "  \"backbone.0.layers.3.blocks.1.mlp.fc2.bias\": 1024,\n",
      "  \"backbone.0.norm1.weight\": 256,\n",
      "  \"backbone.0.norm1.bias\": 256,\n",
      "  \"backbone.0.norm2.weight\": 512,\n",
      "  \"backbone.0.norm2.bias\": 512,\n",
      "  \"backbone.0.norm3.weight\": 1024,\n",
      "  \"backbone.0.norm3.bias\": 1024\n",
      "}\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-08 13:19:04,240 | \u001b[34mparams after freezing:\n",
      "{\n",
      "  \"transformer.level_embed\": 1024,\n",
      "  \"transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.0.norm1.weight\": 256,\n",
      "  \"transformer.encoder.layers.0.norm1.bias\": 256,\n",
      "  \"transformer.encoder.layers.0.linear1.weight\": 524288,\n",
      "  \"transformer.encoder.layers.0.linear1.bias\": 2048,\n",
      "  \"transformer.encoder.layers.0.linear2.weight\": 524288,\n",
      "  \"transformer.encoder.layers.0.linear2.bias\": 256,\n",
      "  \"transformer.encoder.layers.0.norm2.weight\": 256,\n",
      "  \"transformer.encoder.layers.0.norm2.bias\": 256,\n",
      "  \"transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.1.norm1.weight\": 256,\n",
      "  \"transformer.encoder.layers.1.norm1.bias\": 256,\n",
      "  \"transformer.encoder.layers.1.linear1.weight\": 524288,\n",
      "  \"transformer.encoder.layers.1.linear1.bias\": 2048,\n",
      "  \"transformer.encoder.layers.1.linear2.weight\": 524288,\n",
      "  \"transformer.encoder.layers.1.linear2.bias\": 256,\n",
      "  \"transformer.encoder.layers.1.norm2.weight\": 256,\n",
      "  \"transformer.encoder.layers.1.norm2.bias\": 256,\n",
      "  \"transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.2.norm1.weight\": 256,\n",
      "  \"transformer.encoder.layers.2.norm1.bias\": 256,\n",
      "  \"transformer.encoder.layers.2.linear1.weight\": 524288,\n",
      "  \"transformer.encoder.layers.2.linear1.bias\": 2048,\n",
      "  \"transformer.encoder.layers.2.linear2.weight\": 524288,\n",
      "  \"transformer.encoder.layers.2.linear2.bias\": 256,\n",
      "  \"transformer.encoder.layers.2.norm2.weight\": 256,\n",
      "  \"transformer.encoder.layers.2.norm2.bias\": 256,\n",
      "  \"transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.3.norm1.weight\": 256,\n",
      "  \"transformer.encoder.layers.3.norm1.bias\": 256,\n",
      "  \"transformer.encoder.layers.3.linear1.weight\": 524288,\n",
      "  \"transformer.encoder.layers.3.linear1.bias\": 2048,\n",
      "  \"transformer.encoder.layers.3.linear2.weight\": 524288,\n",
      "  \"transformer.encoder.layers.3.linear2.bias\": 256,\n",
      "  \"transformer.encoder.layers.3.norm2.weight\": 256,\n",
      "  \"transformer.encoder.layers.3.norm2.bias\": 256,\n",
      "  \"transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.4.norm1.weight\": 256,\n",
      "  \"transformer.encoder.layers.4.norm1.bias\": 256,\n",
      "  \"transformer.encoder.layers.4.linear1.weight\": 524288,\n",
      "  \"transformer.encoder.layers.4.linear1.bias\": 2048,\n",
      "  \"transformer.encoder.layers.4.linear2.weight\": 524288,\n",
      "  \"transformer.encoder.layers.4.linear2.bias\": 256,\n",
      "  \"transformer.encoder.layers.4.norm2.weight\": 256,\n",
      "  \"transformer.encoder.layers.4.norm2.bias\": 256,\n",
      "  \"transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
      "  \"transformer.encoder.layers.5.norm1.weight\": 256,\n",
      "  \"transformer.encoder.layers.5.norm1.bias\": 256,\n",
      "  \"transformer.encoder.layers.5.linear1.weight\": 524288,\n",
      "  \"transformer.encoder.layers.5.linear1.bias\": 2048,\n",
      "  \"transformer.encoder.layers.5.linear2.weight\": 524288,\n",
      "  \"transformer.encoder.layers.5.linear2.bias\": 256,\n",
      "  \"transformer.encoder.layers.5.norm2.weight\": 256,\n",
      "  \"transformer.encoder.layers.5.norm2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
      "  \"transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
      "  \"transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
      "  \"transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
      "  \"transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
      "  \"transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
      "  \"transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
      "  \"transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
      "  \"transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
      "  \"transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
      "  \"transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
      "  \"transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
      "  \"transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
      "  \"transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
      "  \"transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
      "  \"transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
      "  \"transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
      "  \"transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
      "  \"transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
      "  \"transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
      "  \"transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
      "  \"transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
      "  \"transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
      "  \"transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.norm1.weight\": 256,\n",
      "  \"transformer.decoder.layers.0.norm1.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
      "  \"transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.norm2.weight\": 256,\n",
      "  \"transformer.decoder.layers.0.norm2.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.linear1.weight\": 524288,\n",
      "  \"transformer.decoder.layers.0.linear1.bias\": 2048,\n",
      "  \"transformer.decoder.layers.0.linear2.weight\": 524288,\n",
      "  \"transformer.decoder.layers.0.linear2.bias\": 256,\n",
      "  \"transformer.decoder.layers.0.norm3.weight\": 256,\n",
      "  \"transformer.decoder.layers.0.norm3.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.norm1.weight\": 256,\n",
      "  \"transformer.decoder.layers.1.norm1.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
      "  \"transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.norm2.weight\": 256,\n",
      "  \"transformer.decoder.layers.1.norm2.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.linear1.weight\": 524288,\n",
      "  \"transformer.decoder.layers.1.linear1.bias\": 2048,\n",
      "  \"transformer.decoder.layers.1.linear2.weight\": 524288,\n",
      "  \"transformer.decoder.layers.1.linear2.bias\": 256,\n",
      "  \"transformer.decoder.layers.1.norm3.weight\": 256,\n",
      "  \"transformer.decoder.layers.1.norm3.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.norm1.weight\": 256,\n",
      "  \"transformer.decoder.layers.2.norm1.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
      "  \"transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.norm2.weight\": 256,\n",
      "  \"transformer.decoder.layers.2.norm2.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.linear1.weight\": 524288,\n",
      "  \"transformer.decoder.layers.2.linear1.bias\": 2048,\n",
      "  \"transformer.decoder.layers.2.linear2.weight\": 524288,\n",
      "  \"transformer.decoder.layers.2.linear2.bias\": 256,\n",
      "  \"transformer.decoder.layers.2.norm3.weight\": 256,\n",
      "  \"transformer.decoder.layers.2.norm3.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.norm1.weight\": 256,\n",
      "  \"transformer.decoder.layers.3.norm1.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
      "  \"transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.norm2.weight\": 256,\n",
      "  \"transformer.decoder.layers.3.norm2.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.linear1.weight\": 524288,\n",
      "  \"transformer.decoder.layers.3.linear1.bias\": 2048,\n",
      "  \"transformer.decoder.layers.3.linear2.weight\": 524288,\n",
      "  \"transformer.decoder.layers.3.linear2.bias\": 256,\n",
      "  \"transformer.decoder.layers.3.norm3.weight\": 256,\n",
      "  \"transformer.decoder.layers.3.norm3.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.norm1.weight\": 256,\n",
      "  \"transformer.decoder.layers.4.norm1.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
      "  \"transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.norm2.weight\": 256,\n",
      "  \"transformer.decoder.layers.4.norm2.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.linear1.weight\": 524288,\n",
      "  \"transformer.decoder.layers.4.linear1.bias\": 2048,\n",
      "  \"transformer.decoder.layers.4.linear2.weight\": 524288,\n",
      "  \"transformer.decoder.layers.4.linear2.bias\": 256,\n",
      "  \"transformer.decoder.layers.4.norm3.weight\": 256,\n",
      "  \"transformer.decoder.layers.4.norm3.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
      "  \"transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.norm1.weight\": 256,\n",
      "  \"transformer.decoder.layers.5.norm1.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
      "  \"transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.norm2.weight\": 256,\n",
      "  \"transformer.decoder.layers.5.norm2.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.linear1.weight\": 524288,\n",
      "  \"transformer.decoder.layers.5.linear1.bias\": 2048,\n",
      "  \"transformer.decoder.layers.5.linear2.weight\": 524288,\n",
      "  \"transformer.decoder.layers.5.linear2.bias\": 256,\n",
      "  \"transformer.decoder.layers.5.norm3.weight\": 256,\n",
      "  \"transformer.decoder.layers.5.norm3.bias\": 256,\n",
      "  \"transformer.decoder.norm.weight\": 256,\n",
      "  \"transformer.decoder.norm.bias\": 256,\n",
      "  \"transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
      "  \"transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
      "  \"transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
      "  \"transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
      "  \"transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
      "  \"transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
      "  \"transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
      "  \"transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
      "  \"transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
      "  \"transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
      "  \"transformer.tgt_embed.weight\": 230400,\n",
      "  \"transformer.enc_output.weight\": 65536,\n",
      "  \"transformer.enc_output.bias\": 256,\n",
      "  \"transformer.enc_output_norm.weight\": 256,\n",
      "  \"transformer.enc_output_norm.bias\": 256,\n",
      "  \"transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
      "  \"transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
      "  \"transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
      "  \"transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
      "  \"transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
      "  \"transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
      "  \"feature_map_proj.weight\": 458752,\n",
      "  \"feature_map_proj.bias\": 256,\n",
      "  \"feature_map_encoder.layers.0.norm1.weight\": 256,\n",
      "  \"feature_map_encoder.layers.0.norm1.bias\": 256,\n",
      "  \"feature_map_encoder.layers.0.norm2.weight\": 256,\n",
      "  \"feature_map_encoder.layers.0.norm2.bias\": 256,\n",
      "  \"feature_map_encoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"feature_map_encoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"feature_map_encoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"feature_map_encoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"feature_map_encoder.layers.0.mlp.linear1.weight\": 524288,\n",
      "  \"feature_map_encoder.layers.0.mlp.linear1.bias\": 2048,\n",
      "  \"feature_map_encoder.layers.0.mlp.linear2.weight\": 524288,\n",
      "  \"feature_map_encoder.layers.0.mlp.linear2.bias\": 256,\n",
      "  \"feature_map_encoder.layers.1.norm1.weight\": 256,\n",
      "  \"feature_map_encoder.layers.1.norm1.bias\": 256,\n",
      "  \"feature_map_encoder.layers.1.norm2.weight\": 256,\n",
      "  \"feature_map_encoder.layers.1.norm2.bias\": 256,\n",
      "  \"feature_map_encoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"feature_map_encoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"feature_map_encoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"feature_map_encoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"feature_map_encoder.layers.1.mlp.linear1.weight\": 524288,\n",
      "  \"feature_map_encoder.layers.1.mlp.linear1.bias\": 2048,\n",
      "  \"feature_map_encoder.layers.1.mlp.linear2.weight\": 524288,\n",
      "  \"feature_map_encoder.layers.1.mlp.linear2.bias\": 256,\n",
      "  \"feature_map_encoder.layers.2.norm1.weight\": 256,\n",
      "  \"feature_map_encoder.layers.2.norm1.bias\": 256,\n",
      "  \"feature_map_encoder.layers.2.norm2.weight\": 256,\n",
      "  \"feature_map_encoder.layers.2.norm2.bias\": 256,\n",
      "  \"feature_map_encoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"feature_map_encoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"feature_map_encoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"feature_map_encoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"feature_map_encoder.layers.2.mlp.linear1.weight\": 524288,\n",
      "  \"feature_map_encoder.layers.2.mlp.linear1.bias\": 2048,\n",
      "  \"feature_map_encoder.layers.2.mlp.linear2.weight\": 524288,\n",
      "  \"feature_map_encoder.layers.2.mlp.linear2.bias\": 256,\n",
      "  \"feature_map_encoder.norm.weight\": 256,\n",
      "  \"feature_map_encoder.norm.bias\": 256,\n",
      "  \"feat_map.weight\": 196608,\n",
      "  \"feat_map.bias\": 256,\n",
      "  \"input_proj.0.0.weight\": 65536,\n",
      "  \"input_proj.0.0.bias\": 256,\n",
      "  \"input_proj.0.1.weight\": 256,\n",
      "  \"input_proj.0.1.bias\": 256,\n",
      "  \"input_proj.1.0.weight\": 131072,\n",
      "  \"input_proj.1.0.bias\": 256,\n",
      "  \"input_proj.1.1.weight\": 256,\n",
      "  \"input_proj.1.1.bias\": 256,\n",
      "  \"input_proj.2.0.weight\": 262144,\n",
      "  \"input_proj.2.0.bias\": 256,\n",
      "  \"input_proj.2.1.weight\": 256,\n",
      "  \"input_proj.2.1.bias\": 256,\n",
      "  \"input_proj.3.0.weight\": 2359296,\n",
      "  \"input_proj.3.0.bias\": 256,\n",
      "  \"input_proj.3.1.weight\": 256,\n",
      "  \"input_proj.3.1.bias\": 256\n",
      "}\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-08 13:19:04,244 | \u001b[34mbuild dataset ... ...\u001b[0m\n",
      "/home/renaldy_fredyan/PhDResearch/LOCA/Dataset/images_384_VarV2 ./data/fsc147_gdino/fsc147_odvg/fsc147_train_odvg_exemplars.jsonl ./data/fsc147_gdino/fsc147_odvg/train_label_map.json\n",
      "  == total images: 3659\n",
      "  == total labels: 90\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-08 13:19:05,268 | \u001b[34mbuild dataset, done.\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-08 13:19:05,269 | \u001b[34mnumber of training dataset: 1, samples: 3659\u001b[0m\n",
      "/home/renaldy_fredyan/PhDResearch/LOCA/Dataset/images_384_VarV2 ./data/fsc147_gdino/fsc147_coco/coco_val_exemplars.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.58s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-08 13:19:06,833 | \u001b[34mIgnore keys: []\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-08 13:19:07,362 | \u001b[34m_IncompatibleKeys(missing_keys=['feature_map_proj.weight', 'feature_map_proj.bias', 'feature_map_encoder.layers.0.norm1.weight', 'feature_map_encoder.layers.0.norm1.bias', 'feature_map_encoder.layers.0.norm2.weight', 'feature_map_encoder.layers.0.norm2.bias', 'feature_map_encoder.layers.0.self_attn.in_proj_weight', 'feature_map_encoder.layers.0.self_attn.in_proj_bias', 'feature_map_encoder.layers.0.self_attn.out_proj.weight', 'feature_map_encoder.layers.0.self_attn.out_proj.bias', 'feature_map_encoder.layers.0.mlp.linear1.weight', 'feature_map_encoder.layers.0.mlp.linear1.bias', 'feature_map_encoder.layers.0.mlp.linear2.weight', 'feature_map_encoder.layers.0.mlp.linear2.bias', 'feature_map_encoder.layers.1.norm1.weight', 'feature_map_encoder.layers.1.norm1.bias', 'feature_map_encoder.layers.1.norm2.weight', 'feature_map_encoder.layers.1.norm2.bias', 'feature_map_encoder.layers.1.self_attn.in_proj_weight', 'feature_map_encoder.layers.1.self_attn.in_proj_bias', 'feature_map_encoder.layers.1.self_attn.out_proj.weight', 'feature_map_encoder.layers.1.self_attn.out_proj.bias', 'feature_map_encoder.layers.1.mlp.linear1.weight', 'feature_map_encoder.layers.1.mlp.linear1.bias', 'feature_map_encoder.layers.1.mlp.linear2.weight', 'feature_map_encoder.layers.1.mlp.linear2.bias', 'feature_map_encoder.layers.2.norm1.weight', 'feature_map_encoder.layers.2.norm1.bias', 'feature_map_encoder.layers.2.norm2.weight', 'feature_map_encoder.layers.2.norm2.bias', 'feature_map_encoder.layers.2.self_attn.in_proj_weight', 'feature_map_encoder.layers.2.self_attn.in_proj_bias', 'feature_map_encoder.layers.2.self_attn.out_proj.weight', 'feature_map_encoder.layers.2.self_attn.out_proj.bias', 'feature_map_encoder.layers.2.mlp.linear1.weight', 'feature_map_encoder.layers.2.mlp.linear1.bias', 'feature_map_encoder.layers.2.mlp.linear2.weight', 'feature_map_encoder.layers.2.mlp.linear2.bias', 'feature_map_encoder.norm.weight', 'feature_map_encoder.norm.bias'], unexpected_keys=['label_enc.weight'])\u001b[0m\n",
      "Start training\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/transformers/modeling_utils.py:812: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "Epoch: [0]  [   0/1829]  eta: 3:15:57  lr: 0.000100  loss: 163.3837 (163.3837)  loss_ce: 23.2128 (23.2128)  loss_bbox: 0.0296 (0.0296)  loss_giou: 0.0000 (0.0000)  loss_ce_0: 23.5204 (23.5204)  loss_bbox_0: 0.0390 (0.0390)  loss_giou_0: 0.0000 (0.0000)  loss_ce_1: 23.6712 (23.6712)  loss_bbox_1: 0.0529 (0.0529)  loss_giou_1: 0.0000 (0.0000)  loss_ce_2: 23.4829 (23.4829)  loss_bbox_2: 0.0528 (0.0528)  loss_giou_2: 0.0000 (0.0000)  loss_ce_3: 22.8257 (22.8257)  loss_bbox_3: 0.0422 (0.0422)  loss_giou_3: 0.0000 (0.0000)  loss_ce_4: 22.6980 (22.6980)  loss_bbox_4: 0.0305 (0.0305)  loss_giou_4: 0.0000 (0.0000)  loss_ce_interm: 23.6826 (23.6826)  loss_bbox_interm: 0.0431 (0.0431)  loss_giou_interm: 0.0000 (0.0000)  loss_ce_unscaled: 4.6426 (4.6426)  loss_bbox_unscaled: 0.0296 (0.0296)  loss_giou_unscaled: 1.0079 (1.0079)  loss_xy_unscaled: 0.0296 (0.0296)  loss_hw_unscaled: 0.0000 (0.0000)  loss_ce_0_unscaled: 4.7041 (4.7041)  loss_bbox_0_unscaled: 0.0390 (0.0390)  loss_giou_0_unscaled: 1.0551 (1.0551)  loss_xy_0_unscaled: 0.0390 (0.0390)  loss_hw_0_unscaled: 0.0000 (0.0000)  loss_ce_1_unscaled: 4.7342 (4.7342)  loss_bbox_1_unscaled: 0.0529 (0.0529)  loss_giou_1_unscaled: 1.0397 (1.0397)  loss_xy_1_unscaled: 0.0529 (0.0529)  loss_hw_1_unscaled: 0.0000 (0.0000)  loss_ce_2_unscaled: 4.6966 (4.6966)  loss_bbox_2_unscaled: 0.0528 (0.0528)  loss_giou_2_unscaled: 1.0472 (1.0472)  loss_xy_2_unscaled: 0.0528 (0.0528)  loss_hw_2_unscaled: 0.0000 (0.0000)  loss_ce_3_unscaled: 4.5651 (4.5651)  loss_bbox_3_unscaled: 0.0422 (0.0422)  loss_giou_3_unscaled: 1.0244 (1.0244)  loss_xy_3_unscaled: 0.0422 (0.0422)  loss_hw_3_unscaled: 0.0000 (0.0000)  loss_ce_4_unscaled: 4.5396 (4.5396)  loss_bbox_4_unscaled: 0.0305 (0.0305)  loss_giou_4_unscaled: 1.0077 (1.0077)  loss_xy_4_unscaled: 0.0305 (0.0305)  loss_hw_4_unscaled: 0.0000 (0.0000)  loss_ce_interm_unscaled: 4.7365 (4.7365)  loss_bbox_interm_unscaled: 0.0431 (0.0431)  loss_giou_interm_unscaled: 1.0345 (1.0345)  loss_xy_interm_unscaled: 0.0431 (0.0431)  loss_hw_interm_unscaled: 0.0000 (0.0000)  time: 6.4286  data: 1.5496  max mem: 2545\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "Epoch: [0]  [  10/1829]  eta: 2:23:10  lr: 0.000100  loss: 62.8227 (79.2780)  loss_ce: 8.7624 (11.0286)  loss_bbox: 0.0430 (0.0416)  loss_giou: 0.0000 (0.0000)  loss_ce_0: 9.1985 (11.4392)  loss_bbox_0: 0.0557 (0.0561)  loss_giou_0: 0.0000 (0.0000)  loss_ce_1: 9.0461 (11.4490)  loss_bbox_1: 0.0465 (0.0490)  loss_giou_1: 0.0000 (0.0000)  loss_ce_2: 8.8854 (11.2653)  loss_bbox_2: 0.0457 (0.0452)  loss_giou_2: 0.0000 (0.0000)  loss_ce_3: 8.7947 (11.0909)  loss_bbox_3: 0.0427 (0.0451)  loss_giou_3: 0.0000 (0.0000)  loss_ce_4: 8.7136 (11.0737)  loss_bbox_4: 0.0416 (0.0421)  loss_giou_4: 0.0000 (0.0000)  loss_ce_interm: 9.7345 (11.5949)  loss_bbox_interm: 0.0596 (0.0572)  loss_giou_interm: 0.0000 (0.0000)  loss_ce_unscaled: 1.7525 (2.2057)  loss_bbox_unscaled: 0.0430 (0.0416)  loss_giou_unscaled: 1.0024 (1.0289)  loss_xy_unscaled: 0.0430 (0.0416)  loss_hw_unscaled: 0.0000 (0.0000)  loss_ce_0_unscaled: 1.8397 (2.2878)  loss_bbox_0_unscaled: 0.0557 (0.0561)  loss_giou_0_unscaled: 1.0551 (1.0647)  loss_xy_0_unscaled: 0.0557 (0.0561)  loss_hw_0_unscaled: 0.0000 (0.0000)  loss_ce_1_unscaled: 1.8092 (2.2898)  loss_bbox_1_unscaled: 0.0465 (0.0490)  loss_giou_1_unscaled: 1.0193 (1.0475)  loss_xy_1_unscaled: 0.0465 (0.0490)  loss_hw_1_unscaled: 0.0000 (0.0000)  loss_ce_2_unscaled: 1.7771 (2.2531)  loss_bbox_2_unscaled: 0.0457 (0.0452)  loss_giou_2_unscaled: 0.9993 (1.0385)  loss_xy_2_unscaled: 0.0457 (0.0452)  loss_hw_2_unscaled: 0.0000 (0.0000)  loss_ce_3_unscaled: 1.7589 (2.2182)  loss_bbox_3_unscaled: 0.0427 (0.0451)  loss_giou_3_unscaled: 1.0244 (1.0365)  loss_xy_3_unscaled: 0.0427 (0.0451)  loss_hw_3_unscaled: 0.0000 (0.0000)  loss_ce_4_unscaled: 1.7427 (2.2147)  loss_bbox_4_unscaled: 0.0416 (0.0421)  loss_giou_4_unscaled: 1.0077 (1.0304)  loss_xy_4_unscaled: 0.0416 (0.0421)  loss_hw_4_unscaled: 0.0000 (0.0000)  loss_ce_interm_unscaled: 1.9469 (2.3190)  loss_bbox_interm_unscaled: 0.0596 (0.0572)  loss_giou_interm_unscaled: 1.0345 (1.0588)  loss_xy_interm_unscaled: 0.0596 (0.0572)  loss_hw_interm_unscaled: 0.0000 (0.0000)  time: 4.7224  data: 0.1791  max mem: 4103\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n",
      "asserted\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=7 python main.py --output_dir ./gdino_train -c config/cfg_fsc147_vit_b_debug.py --datasets config/datasets_fsc147.json --pretrain_model_path checkpoints/groundingdino_swinb_cogcoor.pth --options text_encoder_type=checkpoints/bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bcba240-0c25-44c1-9c1d-548b4d3403aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "world size: 2, rank: 1, local rank: 1\n",
      "{\n",
      "  \"CUDA_VISIBLE_DEVICES\": \"6,7\",\n",
      "  \"SHELL\": \"/bin/bash\",\n",
      "  \"CONDA_EXE\": \"/opt/miniconda/bin/conda\",\n",
      "  \"_CE_M\": \"\",\n",
      "  \"PWD\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced_CountGD\",\n",
      "  \"LOGNAME\": \"renaldy_fredyan\",\n",
      "  \"CONDA_PREFIX\": \"/opt/miniconda/envs/Rey1\",\n",
      "  \"JPY_SESSION_NAME\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced.ipynb\",\n",
      "  \"_\": \"/opt/miniconda/envs/Rey1/bin/torchrun\",\n",
      "  \"MOTD_SHOWN\": \"pam\",\n",
      "  \"HOME\": \"/home/renaldy_fredyan\",\n",
      "  \"LANG\": \"en_US.UTF-8\",\n",
      "  \"LS_COLORS\": \"rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:\",\n",
      "  \"FORCE_COLOR\": \"1\",\n",
      "  \"CONDA_PROMPT_MODIFIER\": \"(Rey1) \",\n",
      "  \"PYDEVD_USE_FRAME_EVAL\": \"NO\",\n",
      "  \"CLICOLOR\": \"1\",\n",
      "  \"CLICOLOR_FORCE\": \"1\",\n",
      "  \"SSH_CONNECTION\": \"140.118.155.218 49304 140.118.125.208 6809\",\n",
      "  \"JPY_PARENT_PID\": \"28228\",\n",
      "  \"LESSCLOSE\": \"/usr/bin/lesspipe %s %s\",\n",
      "  \"TERM\": \"xterm-color\",\n",
      "  \"_CE_CONDA\": \"\",\n",
      "  \"LESSOPEN\": \"| /usr/bin/lesspipe %s\",\n",
      "  \"USER\": \"renaldy_fredyan\",\n",
      "  \"GIT_PAGER\": \"cat\",\n",
      "  \"CONDA_SHLVL\": \"1\",\n",
      "  \"SHLVL\": \"1\",\n",
      "  \"PAGER\": \"cat\",\n",
      "  \"MPLBACKEND\": \"module://matplotlib_inline.backend_inline\",\n",
      "  \"CONDA_PYTHON_EXE\": \"/opt/miniconda/bin/python\",\n",
      "  \"SSH_CLIENT\": \"140.118.155.218 49304 6809\",\n",
      "  \"CONDA_DEFAULT_ENV\": \"Rey1\",\n",
      "  \"XDG_DATA_DIRS\": \"/usr/local/share:/usr/share:/var/lib/snapd/desktop\",\n",
      "  \"PATH\": \"/opt/miniconda/envs/Rey1/bin:/opt/miniconda/condabin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\",\n",
      "  \"SSH_TTY\": \"/dev/pts/0\",\n",
      "  \"OMP_NUM_THREADS\": \"1\",\n",
      "  \"LOCAL_RANK\": \"1\",\n",
      "  \"RANK\": \"1\",\n",
      "  \"GROUP_RANK\": \"0\",\n",
      "  \"ROLE_RANK\": \"1\",\n",
      "  \"ROLE_NAME\": \"default\",\n",
      "  \"LOCAL_WORLD_SIZE\": \"2\",\n",
      "  \"WORLD_SIZE\": \"2\",\n",
      "  \"GROUP_WORLD_SIZE\": \"1\",\n",
      "  \"ROLE_WORLD_SIZE\": \"2\",\n",
      "  \"MASTER_ADDR\": \"127.0.0.1\",\n",
      "  \"MASTER_PORT\": \"29500\",\n",
      "  \"TORCHELASTIC_RESTART_COUNT\": \"0\",\n",
      "  \"TORCHELASTIC_MAX_RESTARTS\": \"0\",\n",
      "  \"TORCHELASTIC_RUN_ID\": \"none\",\n",
      "  \"TORCHELASTIC_USE_AGENT_STORE\": \"True\",\n",
      "  \"NCCL_ASYNC_ERROR_HANDLING\": \"1\",\n",
      "  \"TORCHELASTIC_ERROR_FILE\": \"/tmp/torchelastic_gwjrzur9/none_l6b5l5dz/attempt_0/1/error.json\",\n",
      "  \"QT_QPA_PLATFORM_PLUGIN_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/plugins\",\n",
      "  \"QT_QPA_FONTDIR\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/fonts\",\n",
      "  \"LD_LIBRARY_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/../../lib64:\"\n",
      "}\n",
      "world size: 2, rank: 0, local rank: 0\n",
      "{\n",
      "  \"CUDA_VISIBLE_DEVICES\": \"6,7\",\n",
      "  \"SHELL\": \"/bin/bash\",\n",
      "  \"CONDA_EXE\": \"/opt/miniconda/bin/conda\",\n",
      "  \"_CE_M\": \"\",\n",
      "  \"PWD\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced_CountGD\",\n",
      "  \"LOGNAME\": \"renaldy_fredyan\",\n",
      "  \"CONDA_PREFIX\": \"/opt/miniconda/envs/Rey1\",\n",
      "  \"JPY_SESSION_NAME\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced.ipynb\",\n",
      "  \"_\": \"/opt/miniconda/envs/Rey1/bin/torchrun\",\n",
      "  \"MOTD_SHOWN\": \"pam\",\n",
      "  \"HOME\": \"/home/renaldy_fredyan\",\n",
      "  \"LANG\": \"en_US.UTF-8\",\n",
      "  \"LS_COLORS\": \"rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:\",\n",
      "  \"FORCE_COLOR\": \"1\",\n",
      "  \"CONDA_PROMPT_MODIFIER\": \"(Rey1) \",\n",
      "  \"PYDEVD_USE_FRAME_EVAL\": \"NO\",\n",
      "  \"CLICOLOR\": \"1\",\n",
      "  \"CLICOLOR_FORCE\": \"1\",\n",
      "  \"SSH_CONNECTION\": \"140.118.155.218 49304 140.118.125.208 6809\",\n",
      "  \"JPY_PARENT_PID\": \"28228\",\n",
      "  \"LESSCLOSE\": \"/usr/bin/lesspipe %s %s\",\n",
      "  \"TERM\": \"xterm-color\",\n",
      "  \"_CE_CONDA\": \"\",\n",
      "  \"LESSOPEN\": \"| /usr/bin/lesspipe %s\",\n",
      "  \"USER\": \"renaldy_fredyan\",\n",
      "  \"GIT_PAGER\": \"cat\",\n",
      "  \"CONDA_SHLVL\": \"1\",\n",
      "  \"SHLVL\": \"1\",\n",
      "  \"PAGER\": \"cat\",\n",
      "  \"MPLBACKEND\": \"module://matplotlib_inline.backend_inline\",\n",
      "  \"CONDA_PYTHON_EXE\": \"/opt/miniconda/bin/python\",\n",
      "  \"SSH_CLIENT\": \"140.118.155.218 49304 6809\",\n",
      "  \"CONDA_DEFAULT_ENV\": \"Rey1\",\n",
      "  \"XDG_DATA_DIRS\": \"/usr/local/share:/usr/share:/var/lib/snapd/desktop\",\n",
      "  \"PATH\": \"/opt/miniconda/envs/Rey1/bin:/opt/miniconda/condabin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\",\n",
      "  \"SSH_TTY\": \"/dev/pts/0\",\n",
      "  \"OMP_NUM_THREADS\": \"1\",\n",
      "  \"LOCAL_RANK\": \"0\",\n",
      "  \"RANK\": \"0\",\n",
      "  \"GROUP_RANK\": \"0\",\n",
      "  \"ROLE_RANK\": \"0\",\n",
      "  \"ROLE_NAME\": \"default\",\n",
      "  \"LOCAL_WORLD_SIZE\": \"2\",\n",
      "  \"WORLD_SIZE\": \"2\",\n",
      "  \"GROUP_WORLD_SIZE\": \"1\",\n",
      "  \"ROLE_WORLD_SIZE\": \"2\",\n",
      "  \"MASTER_ADDR\": \"127.0.0.1\",\n",
      "  \"MASTER_PORT\": \"29500\",\n",
      "  \"TORCHELASTIC_RESTART_COUNT\": \"0\",\n",
      "  \"TORCHELASTIC_MAX_RESTARTS\": \"0\",\n",
      "  \"TORCHELASTIC_RUN_ID\": \"none\",\n",
      "  \"TORCHELASTIC_USE_AGENT_STORE\": \"True\",\n",
      "  \"NCCL_ASYNC_ERROR_HANDLING\": \"1\",\n",
      "  \"TORCHELASTIC_ERROR_FILE\": \"/tmp/torchelastic_gwjrzur9/none_l6b5l5dz/attempt_0/0/error.json\",\n",
      "  \"QT_QPA_PLATFORM_PLUGIN_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/plugins\",\n",
      "  \"QT_QPA_FONTDIR\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/fonts\",\n",
      "  \"LD_LIBRARY_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/../../lib64:\"\n",
      "}\n",
      "  == distributed init (rank 0) done.\n",
      "  == distributed init (rank 1) done.\n",
      "Loading config file from config/cfg_fsc147_vit_b.py\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755849709/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:46:47,799 | \u001b[34mgit:\n",
      "  sha: d3d2539b1c084bb62ba04308a2ace9b4476442ea, status: has uncommited changes, branch: main\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:46:47,801 | \u001b[34mCommand: main.py --output_dir ./gdino_test -c config/cfg_fsc147_vit_b.py --eval --datasets config/datasets_fsc147_val.json --pretrain_model_path ./gdino_train/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:46:47,804 | \u001b[34mFull config saved to ./gdino_test/config_args_all.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:46:47,805 | \u001b[34mworld size: 2\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:46:47,805 | \u001b[34mrank: 0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:46:47,806 | \u001b[34mlocal_rank: 0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:46:47,807 | \u001b[34margs: Namespace(config_file='config/cfg_fsc147_vit_b.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='config/datasets_fsc147_val.json', remove_difficult=False, fix_size=False, output_dir='./gdino_test', note='', device='cuda', seed=42, resume='', pretrain_model_path='./gdino_train/checkpoint_best_regular.pth', finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=2, dist_url='env://', rank=0, local_rank=0, amp=False, gpu=0, distributed=True, dist_backend='nccl', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=30, lr_drop=10, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[10, 20], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=False, label_list=['alcohol bottle', 'baguette roll', 'ball', 'banana', 'bead', 'bee', 'birthday candle', 'biscuit', 'boat', 'bottle', 'bowl', 'box', 'bread roll', 'brick', 'buffalo', 'bun', 'calamari ring', 'can', 'candle', 'cap', 'car', 'cartridge', 'cassette', 'cement bag', 'cereal', 'chewing gum piece', 'chopstick', 'clam', 'coffee bean', 'coin', 'cotton ball', 'cow', 'crane', 'crayon', 'croissant', 'crow', 'cup', 'cupcake', 'cupcake holder', 'fish', 'gemstone', 'go game piece', 'goat', 'goldfish snack', 'goose', 'ice cream', 'ice cream cone', 'instant noodle', 'jade stone', 'jeans', 'kidney bean', 'kitchen towel', 'lighter', 'lipstick', 'm&m piece', 'macaron', 'match', 'meat skewer', 'mini blind', 'mosaic tile', 'naan bread', 'nail', 'nut', 'onion ring', 'orange', 'pearl', 'pen', 'pencil', 'penguin', 'pepper', 'person', 'pigeon', 'plate', 'polka dot tile', 'potato', 'rice bag', 'roof tile', 'screw', 'shoe', 'spoon', 'spring roll', 'stair', 'stapler pin', 'straw', 'supermarket shelf', 'swan', 'tomato', 'watermelon', 'window', 'zebra'], val_label_list=['ant', 'bird', 'book', 'bottle cap', 'bullet', 'camel', 'chair', 'chicken wing', 'donut', 'donut holder', 'flamingo', 'flower', 'flower pot', 'grape', 'horse', 'kiwi', 'milk carton', 'oyster', 'oyster shell', 'package of fresh cut fruit', 'peach', 'pill', 'polka dot', 'prawn cracker', 'sausage', 'seagull', 'shallot', 'shirt', 'skateboard', 'toilet paper roll'])\n",
      "\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-13 13:46:47,808 | \u001b[34mbuild model ... ...\u001b[0m\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755849709/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "final text_encoder_type: checkpoints/bert-base-uncased\n",
      "load tokenizer done.\n",
      "final text_encoder_type: checkpoints/bert-base-uncased\n",
      "load tokenizer done.\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-13 13:46:51,397 | \u001b[34mbuild model, done.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:46:51,483 | \u001b[34mnumber of params:236717952\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:46:51,488 | \u001b[34mparams before freezing:\n",
      "{\n",
      "  \"module.transformer.level_embed\": 1024,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.norm.weight\": 256,\n",
      "  \"module.transformer.decoder.norm.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
      "  \"module.transformer.tgt_embed.weight\": 230400,\n",
      "  \"module.transformer.enc_output.weight\": 65536,\n",
      "  \"module.transformer.enc_output.bias\": 256,\n",
      "  \"module.transformer.enc_output_norm.weight\": 256,\n",
      "  \"module.transformer.enc_output_norm.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
      "  \"module.feature_map_proj.weight\": 458752,\n",
      "  \"module.feature_map_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.norm.weight\": 256,\n",
      "  \"module.feature_map_encoder.norm.bias\": 256,\n",
      "  \"module.bert.embeddings.word_embeddings.weight\": 23440896,\n",
      "  \"module.bert.embeddings.position_embeddings.weight\": 393216,\n",
      "  \"module.bert.embeddings.token_type_embeddings.weight\": 1536,\n",
      "  \"module.bert.embeddings.LayerNorm.weight\": 768,\n",
      "  \"module.bert.embeddings.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.0.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.0.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.0.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.0.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.1.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.1.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.1.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.1.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.2.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.2.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.2.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.2.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.3.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.3.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.3.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.3.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.4.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.4.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.4.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.4.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.5.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.5.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.5.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.5.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.6.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.6.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.6.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.6.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.7.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.7.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.7.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.7.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.8.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.8.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.8.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.8.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.9.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.9.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.9.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.9.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.10.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.10.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.10.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.10.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.11.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.11.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.11.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.11.output.LayerNorm.bias\": 768,\n",
      "  \"module.feat_map.weight\": 196608,\n",
      "  \"module.feat_map.bias\": 256,\n",
      "  \"module.input_proj.0.0.weight\": 65536,\n",
      "  \"module.input_proj.0.0.bias\": 256,\n",
      "  \"module.input_proj.0.1.weight\": 256,\n",
      "  \"module.input_proj.0.1.bias\": 256,\n",
      "  \"module.input_proj.1.0.weight\": 131072,\n",
      "  \"module.input_proj.1.0.bias\": 256,\n",
      "  \"module.input_proj.1.1.weight\": 256,\n",
      "  \"module.input_proj.1.1.bias\": 256,\n",
      "  \"module.input_proj.2.0.weight\": 262144,\n",
      "  \"module.input_proj.2.0.bias\": 256,\n",
      "  \"module.input_proj.2.1.weight\": 256,\n",
      "  \"module.input_proj.2.1.bias\": 256,\n",
      "  \"module.input_proj.3.0.weight\": 2359296,\n",
      "  \"module.input_proj.3.0.bias\": 256,\n",
      "  \"module.input_proj.3.1.weight\": 256,\n",
      "  \"module.input_proj.3.1.bias\": 256,\n",
      "  \"module.backbone.0.patch_embed.proj.weight\": 6144,\n",
      "  \"module.backbone.0.patch_embed.proj.bias\": 128,\n",
      "  \"module.backbone.0.patch_embed.norm.weight\": 128,\n",
      "  \"module.backbone.0.patch_embed.norm.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm1.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm1.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table\": 2116,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.qkv.weight\": 49152,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.qkv.bias\": 384,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.proj.weight\": 16384,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.proj.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm2.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc1.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc1.bias\": 512,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc2.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm1.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm1.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table\": 2116,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.qkv.weight\": 49152,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.qkv.bias\": 384,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.proj.weight\": 16384,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.proj.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm2.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc1.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc1.bias\": 512,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc2.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.downsample.reduction.weight\": 131072,\n",
      "  \"module.backbone.0.layers.0.downsample.norm.weight\": 512,\n",
      "  \"module.backbone.0.layers.0.downsample.norm.bias\": 512,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm1.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm1.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table\": 4232,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.qkv.weight\": 196608,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.qkv.bias\": 768,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.proj.weight\": 65536,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.proj.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm2.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc1.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc2.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm1.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm1.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table\": 4232,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.qkv.weight\": 196608,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.qkv.bias\": 768,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.proj.weight\": 65536,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.proj.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm2.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc1.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc2.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.downsample.reduction.weight\": 524288,\n",
      "  \"module.backbone.0.layers.1.downsample.norm.weight\": 1024,\n",
      "  \"module.backbone.0.layers.1.downsample.norm.bias\": 1024,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.downsample.reduction.weight\": 2097152,\n",
      "  \"module.backbone.0.layers.2.downsample.norm.weight\": 2048,\n",
      "  \"module.backbone.0.layers.2.downsample.norm.bias\": 2048,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm1.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table\": 16928,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.qkv.weight\": 3145728,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.qkv.bias\": 3072,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.proj.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.proj.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm2.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc1.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc1.bias\": 4096,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc2.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm1.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table\": 16928,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.qkv.weight\": 3145728,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.qkv.bias\": 3072,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.proj.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.proj.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm2.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc1.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc1.bias\": 4096,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc2.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc2.bias\": 1024,\n",
      "  \"module.backbone.0.norm1.weight\": 256,\n",
      "  \"module.backbone.0.norm1.bias\": 256,\n",
      "  \"module.backbone.0.norm2.weight\": 512,\n",
      "  \"module.backbone.0.norm2.bias\": 512,\n",
      "  \"module.backbone.0.norm3.weight\": 1024,\n",
      "  \"module.backbone.0.norm3.bias\": 1024\n",
      "}\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:46:51,518 | \u001b[34mparams after freezing:\n",
      "{\n",
      "  \"module.transformer.level_embed\": 1024,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.norm.weight\": 256,\n",
      "  \"module.transformer.decoder.norm.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
      "  \"module.transformer.tgt_embed.weight\": 230400,\n",
      "  \"module.transformer.enc_output.weight\": 65536,\n",
      "  \"module.transformer.enc_output.bias\": 256,\n",
      "  \"module.transformer.enc_output_norm.weight\": 256,\n",
      "  \"module.transformer.enc_output_norm.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
      "  \"module.feature_map_proj.weight\": 458752,\n",
      "  \"module.feature_map_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.norm.weight\": 256,\n",
      "  \"module.feature_map_encoder.norm.bias\": 256,\n",
      "  \"module.feat_map.weight\": 196608,\n",
      "  \"module.feat_map.bias\": 256,\n",
      "  \"module.input_proj.0.0.weight\": 65536,\n",
      "  \"module.input_proj.0.0.bias\": 256,\n",
      "  \"module.input_proj.0.1.weight\": 256,\n",
      "  \"module.input_proj.0.1.bias\": 256,\n",
      "  \"module.input_proj.1.0.weight\": 131072,\n",
      "  \"module.input_proj.1.0.bias\": 256,\n",
      "  \"module.input_proj.1.1.weight\": 256,\n",
      "  \"module.input_proj.1.1.bias\": 256,\n",
      "  \"module.input_proj.2.0.weight\": 262144,\n",
      "  \"module.input_proj.2.0.bias\": 256,\n",
      "  \"module.input_proj.2.1.weight\": 256,\n",
      "  \"module.input_proj.2.1.bias\": 256,\n",
      "  \"module.input_proj.3.0.weight\": 2359296,\n",
      "  \"module.input_proj.3.0.bias\": 256,\n",
      "  \"module.input_proj.3.1.weight\": 256,\n",
      "  \"module.input_proj.3.1.bias\": 256\n",
      "}\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-13 13:46:51,523 | \u001b[34mbuild dataset ... ...\u001b[0m\n",
      "/home/renaldy_fredyan/PhDResearch/LOCA/Dataset/images_384_VarV2 ./data/fsc147_gdino/fsc147_coco/coco_val_exemplars.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.42s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:46:52,799 | \u001b[34mIgnore keys: []\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:46:53,257 | \u001b[34m<All keys matched successfully>\u001b[0m\n",
      "Input text prompt: ant . bird . book . bottle cap . bullet . camel . chair . chicken wing . donut . donut holder . flamingo . flower . flower pot . grape . horse . kiwi . milk carton . oyster . oyster shell . package of fresh cut fruit . peach . pill . polka dot . prawn cracker . sausage . seagull . shallot . shirt . skateboard . toilet paper roll .\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "input_captions: ['seagull .', 'seagull .', 'peach .', 'peach .']\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/transformers/modeling_utils.py:812: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/transformers/modeling_utils.py:812: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 86, GT Count: 77\n",
      "Test:  [  0/161]  eta: 0:14:24    time: 5.3717  data: 4.0236  max mem: 4065\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 64\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 58\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 59, GT Count: 59\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 78\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 24\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 125, GT Count: 126\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 37\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 57, GT Count: 55\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 59, GT Count: 48\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 50\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'oyster .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 81, GT Count: 74\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 19\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 12\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['flamingo .', 'seagull .', 'seagull .', 'seagull .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "Test:  [ 10/161]  eta: 0:03:28    time: 1.3776  data: 0.4189  max mem: 4356\n",
      "input_captions: ['seagull .', 'seagull .', 'seagull .', 'seagull .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 54\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['seagull .', 'seagull .', 'seagull .', 'seagull .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 7\n",
      "input_captions: ['seagull .', 'seagull .', 'seagull .', 'seagull .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 12\n",
      "input_captions: ['seagull .', 'seagull .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 92, GT Count: 44\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 8\n",
      "input_captions: ['bird .', 'bird .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 62, GT Count: 58\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "input_captions: ['bird .', 'bird .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 59, GT Count: 56\n",
      "input_captions: ['bird .', 'book .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 55\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 15\n",
      "input_captions: ['book .', 'book .', 'book .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 179, GT Count: 182\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 40\n",
      "Test:  [ 20/161]  eta: 0:02:51    time: 1.0109  data: 0.0475  max mem: 4356\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 56, GT Count: 53\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 70\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 87\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 117, GT Count: 117\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 54\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 35\n",
      "input_captions: ['book .', 'book .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 452, GT Count: 637\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 174, GT Count: 142\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 21\n",
      "input_captions: ['book .', 'book .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 331, GT Count: 320\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 103, GT Count: 97\n",
      "input_captions: ['book .', 'book .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 82, GT Count: 84\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 251, GT Count: 230\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 8\n",
      "input_captions: ['book .', 'book .', 'skateboard .', 'skateboard .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 146, GT Count: 207\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 9\n",
      "input_captions: ['skateboard .', 'skateboard .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 121, GT Count: 122\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 39\n",
      "input_captions: ['bird .', 'bird .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 62, GT Count: 53\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['bird .', 'bird .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 147, GT Count: 122\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 144, GT Count: 139\n",
      "input_captions: ['bird .', 'bird .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 559, GT Count: 530\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 7, GT Count: 7\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "Test:  [ 30/161]  eta: 0:02:34    time: 1.0737  data: 0.0396  max mem: 4356\n",
      "input_captions: ['bird .', 'bird .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 86, GT Count: 76\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 67, GT Count: 63\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 93, GT Count: 85\n",
      "input_captions: ['bird .', 'bird .', 'pill .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 119, GT Count: 108\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 65, GT Count: 64\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 64, GT Count: 76\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 180, GT Count: 180\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 151, GT Count: 139\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 115, GT Count: 119\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 50\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 121, GT Count: 138\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 29\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 18\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 216, GT Count: 215\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 170, GT Count: 175\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 128, GT Count: 117\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 69\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 214, GT Count: 221\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 150, GT Count: 150\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 68\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 126, GT Count: 111\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "Test:  [ 40/161]  eta: 0:02:19    time: 1.0781  data: 0.0446  max mem: 4356\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 137, GT Count: 132\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 40\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 95\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 161, GT Count: 148\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 96, GT Count: 119\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 48\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 115, GT Count: 83\n",
      "input_captions: ['bottle cap .', 'ant .', 'camel .', 'camel .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 100, GT Count: 100\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 72, GT Count: 72\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19130, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19130, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 11\n",
      "input_captions: ['camel .', 'camel .', 'camel .', 'camel .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19130, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19130, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19130, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19130, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 10\n",
      "input_captions: ['horse .', 'horse .', 'horse .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 256, GT Count: 263\n",
      "input_captions: ['chair .', 'chair .', 'chair .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 49\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 239, GT Count: 252\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 126, GT Count: 136\n",
      "input_captions: ['chair .', 'chair .', 'chair .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 73, GT Count: 58\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 80, GT Count: 62\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 92, GT Count: 89\n",
      "input_captions: ['chair .', 'chair .', 'chair .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 57\n",
      "input_captions: ['chair .', 'chair .', 'chair .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 63, GT Count: 61\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 64, GT Count: 56\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 127, GT Count: 131\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 40\n",
      "Test:  [ 50/161]  eta: 0:02:04    time: 1.0229  data: 0.0426  max mem: 4356\n",
      "input_captions: ['chair .', 'chair .', 'chair .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 148, GT Count: 151\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 23\n",
      "input_captions: ['chair .', 'chair .', 'chair .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 74, GT Count: 60\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 303, GT Count: 301\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 144, GT Count: 158\n",
      "input_captions: ['chair .', 'chair .', 'shirt .', 'shirt .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 193, GT Count: 174\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 9\n",
      "input_captions: ['shirt .', 'bullet .', 'bullet .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 69\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 226, GT Count: 219\n",
      "input_captions: ['polka dot .', 'polka dot .', 'polka dot .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 712, GT Count: 458\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 75, GT Count: 75\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 482, GT Count: 538\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 116, GT Count: 116\n",
      "input_captions: ['polka dot .', 'polka dot .', 'polka dot .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 424, GT Count: 501\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 269, GT Count: 262\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 285, GT Count: 315\n",
      "input_captions: ['polka dot .', 'polka dot .', 'polka dot .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 356\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 92, GT Count: 81\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 447, GT Count: 431\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 64, GT Count: 64\n",
      "input_captions: ['polka dot .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 42\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 29\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 20\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "Test:  [ 60/161]  eta: 0:01:49    time: 0.9531  data: 0.0386  max mem: 4356\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 18\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 19\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "input_captions: ['chicken wing .', 'toilet paper roll .', 'toilet paper roll .', 'toilet paper roll .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 50\n",
      "input_captions: ['toilet paper roll .', 'toilet paper roll .', 'toilet paper roll .', 'toilet paper roll .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 46\n",
      "input_captions: ['toilet paper roll .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['donut .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 10\n",
      "input_captions: ['donut .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 12\n",
      "Test:  [ 70/161]  eta: 0:01:37    time: 0.9343  data: 0.0423  max mem: 4356\n",
      "input_captions: ['donut .', 'donut .', 'donut .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 31\n",
      "input_captions: ['shallot .', 'oyster .', 'bullet .', 'bullet .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 7, GT Count: 7\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['bullet .', 'bullet .', 'oyster shell .', 'oyster shell .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['oyster shell .', 'oyster shell .', 'oyster shell .', 'prawn cracker .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10975, device='cuda:0')\n",
      "tensor(10376, device='cuda:0')\n",
      "tensor(2078, device='cuda:0')\n",
      "tensor(8579, device='cuda:0')\n",
      "tensor(2121, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['sausage .', 'sausage .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 22\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 62, GT Count: 55\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 53, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 136, GT Count: 133\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 136, GT Count: 133\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 37\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 137, GT Count: 141\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 405, GT Count: 402\n",
      "Test:  [ 80/161]  eta: 0:01:25    time: 0.9854  data: 0.0445  max mem: 4356\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 168, GT Count: 165\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "input_captions: ['kiwi .', 'kiwi .', 'kiwi .', 'kiwi .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['kiwi .', 'kiwi .', 'kiwi .', 'kiwi .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 63, GT Count: 64\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 19\n",
      "input_captions: ['kiwi .', 'kiwi .', 'kiwi .', 'kiwi .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "input_captions: ['kiwi .', 'seagull .', 'seagull .', 'seagull .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['seagull .', 'seagull .', 'seagull .', 'seagull .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 26\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "input_captions: ['seagull .', 'seagull .', 'seagull .', 'seagull .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 21\n",
      "input_captions: ['seagull .', 'seagull .', 'seagull .', 'peach .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['peach .', 'peach .', 'peach .', 'peach .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 51, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 8\n",
      "input_captions: ['peach .', 'peach .', 'peach .', 'peach .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 57, GT Count: 55\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 120, GT Count: 133\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 42\n",
      "Test:  [ 90/161]  eta: 0:01:14    time: 1.0059  data: 0.0407  max mem: 4356\n",
      "input_captions: ['peach .', 'peach .', 'peach .', 'peach .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 113, GT Count: 109\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 30\n",
      "input_captions: ['peach .', 'peach .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 59, GT Count: 55\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 182, GT Count: 196\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 63, GT Count: 61\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 34\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 135, GT Count: 120\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 103, GT Count: 112\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 72, GT Count: 67\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 169, GT Count: 144\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 29\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 111, GT Count: 84\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 40\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 128, GT Count: 122\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 106, GT Count: 98\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 69, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 26\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 133, GT Count: 122\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 74, GT Count: 61\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 127, GT Count: 121\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 50\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 22\n",
      "input_captions: ['polka dot .', 'polka dot .', 'polka dot .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 101, GT Count: 100\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 231, GT Count: 215\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 87, GT Count: 98\n",
      "Test:  [100/161]  eta: 0:01:03    time: 0.9679  data: 0.0433  max mem: 4356\n",
      "input_captions: ['polka dot .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 12\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 21\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'toilet paper roll .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 62, GT Count: 57\n",
      "input_captions: ['toilet paper roll .', 'toilet paper roll .', 'toilet paper roll .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['donut .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['donut .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "Test:  [110/161]  eta: 0:00:52    time: 0.9387  data: 0.0461  max mem: 4356\n",
      "input_captions: ['donut .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['donut .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 15\n",
      "input_captions: ['donut .', 'donut .', 'polka dot .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 254, GT Count: 239\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 27\n",
      "input_captions: ['polka dot .', 'polka dot .', 'polka dot .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 95, GT Count: 87\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 43\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 262, GT Count: 322\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 100, GT Count: 100\n",
      "input_captions: ['polka dot .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 65, GT Count: 74\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 171, GT Count: 170\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 798, GT Count: 757\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 58\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 95, GT Count: 81\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 331, GT Count: 267\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 54\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 47\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 135, GT Count: 116\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 135, GT Count: 124\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 224, GT Count: 216\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 44\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 25\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 94, GT Count: 84\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 92, GT Count: 103\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 72, GT Count: 62\n",
      "Test:  [120/161]  eta: 0:00:42    time: 0.9571  data: 0.0447  max mem: 4356\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 55\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 189, GT Count: 209\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 134, GT Count: 113\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 119, GT Count: 116\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 71, GT Count: 62\n",
      "input_captions: ['grape .', 'grape .', 'chair .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 74, GT Count: 63\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 55\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['chair .', 'seagull .', 'seagull .', 'seagull .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 76, GT Count: 48\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['seagull .', 'seagull .', 'seagull .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 368, GT Count: 277\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 30\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "Test:  [130/161]  eta: 0:00:31    time: 0.9988  data: 0.0462  max mem: 4356\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'pill .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 23\n",
      "input_captions: ['pill .', 'pill .', 'pill .', 'pill .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 70\n",
      "input_captions: ['pill .', 'pill .', 'pill .', 'pill .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 9\n",
      "input_captions: ['pill .', 'pill .', 'package of fresh cut fruit .', 'package of fresh cut fruit .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7427, device='cuda:0')\n",
      "tensor(1997, device='cuda:0')\n",
      "tensor(4840, device='cuda:0')\n",
      "tensor(3013, device='cuda:0')\n",
      "tensor(5909, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7427, device='cuda:0')\n",
      "tensor(1997, device='cuda:0')\n",
      "tensor(4840, device='cuda:0')\n",
      "tensor(3013, device='cuda:0')\n",
      "tensor(5909, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 66, GT Count: 63\n",
      "input_captions: ['package of fresh cut fruit .', 'package of fresh cut fruit .', 'package of fresh cut fruit .', 'milk carton .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7427, device='cuda:0')\n",
      "tensor(1997, device='cuda:0')\n",
      "tensor(4840, device='cuda:0')\n",
      "tensor(3013, device='cuda:0')\n",
      "tensor(5909, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 118, GT Count: 119\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7427, device='cuda:0')\n",
      "tensor(1997, device='cuda:0')\n",
      "tensor(4840, device='cuda:0')\n",
      "tensor(3013, device='cuda:0')\n",
      "tensor(5909, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 170, GT Count: 167\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7427, device='cuda:0')\n",
      "tensor(1997, device='cuda:0')\n",
      "tensor(4840, device='cuda:0')\n",
      "tensor(3013, device='cuda:0')\n",
      "tensor(5909, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 51, GT Count: 53\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 66\n",
      "input_captions: ['milk carton .', 'milk carton .', 'milk carton .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 108, GT Count: 110\n",
      "input_captions: ['chair .', 'chair .', 'chair .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 108, GT Count: 106\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 209, GT Count: 211\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 80, GT Count: 79\n",
      "input_captions: ['chair .', 'book .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 57, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 195, GT Count: 199\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['book .', 'book .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 74, GT Count: 52\n",
      "Test:  [140/161]  eta: 0:00:21    time: 1.0133  data: 0.0479  max mem: 4356\n",
      "input_captions: ['book .', 'book .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 149, GT Count: 140\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 132, GT Count: 116\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 17\n",
      "input_captions: ['shirt .', 'shirt .', 'shirt .', 'shirt .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 209, GT Count: 169\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 98, GT Count: 62\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 897, GT Count: 1231\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 36\n",
      "input_captions: ['shirt .', 'shirt .', 'shirt .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 201, GT Count: 186\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 13\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 87, GT Count: 72\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 316, GT Count: 238\n",
      "input_captions: ['horse .', 'horse .', 'horse .', 'horse .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['horse .', 'horse .', 'horse .', 'horse .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 65\n",
      "input_captions: ['bird .', 'bird .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 140, GT Count: 138\n",
      "input_captions: ['bird .', 'bird .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 161, GT Count: 144\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 60\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 26\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 89, GT Count: 83\n",
      "input_captions: ['bird .', 'bird .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 894, GT Count: 949\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 39\n",
      "input_captions: ['bird .', 'camel .', 'skateboard .', 'skateboard .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19130, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 43\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 73, GT Count: 65\n",
      "Test:  [150/161]  eta: 0:00:11    time: 1.1230  data: 0.0458  max mem: 4356\n",
      "input_captions: ['skateboard .', 'skateboard .', 'skateboard .', 'pill .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 81, GT Count: 78\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 53, GT Count: 53\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 26\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 82, GT Count: 76\n",
      "input_captions: ['pill .', 'pill .', 'pill .', 'pill .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 84, GT Count: 83\n",
      "input_captions: ['pill .', 'pill .', 'pill .', 'pill .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 62, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['pill .', 'flower pot .', 'flower .', 'flower pot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 86, GT Count: 68\n",
      "input_captions: ['flower pot .', 'flower pot .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 67, GT Count: 69\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 85, GT Count: 76\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 143, GT Count: 144\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 30\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'flower pot .', 'pill .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 134, GT Count: 138\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 278, GT Count: 274\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 136, GT Count: 135\n",
      "input_captions: ['pill .', 'pill .', 'milk carton .', 'milk carton .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 130, GT Count: 139\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 199, GT Count: 198\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 71\n",
      "input_captions: ['milk carton .', 'pill .', 'pill .', 'pill .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 139, GT Count: 134\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 123, GT Count: 118\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 77, GT Count: 74\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 27\n",
      "input_captions: ['book .', 'book .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 89, GT Count: 80\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 117, GT Count: 116\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 105, GT Count: 100\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 51, GT Count: 49\n",
      "input_captions: ['book .', 'book .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 86, GT Count: 83\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 44\n",
      "Test:  [160/161]  eta: 0:00:01    time: 1.1263  data: 0.0444  max mem: 4356\n",
      "Test: Total time: 0:02:48 (1.0443 s / it)\n",
      "# of Images Tested: 643\n",
      "MAE: 6.329704510108865, RMSE: 24.70604789294184\n",
      "Averaged stats: \n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.76s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.029\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.018\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=6,7 torchrun --nproc_per_node=2 main.py --output_dir ./gdino_test -c config/cfg_fsc147_vit_b.py --eval --datasets config/datasets_fsc147_val.json --pretrain_model_path ./gdino_train/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f44c8e24-447e-4302-b712-6f7f9284d6b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "world size: 2, rank: 1, local rank: 1\n",
      "{\n",
      "  \"CUDA_VISIBLE_DEVICES\": \"6,7\",\n",
      "  \"SHELL\": \"/bin/bash\",\n",
      "  \"CONDA_EXE\": \"/opt/miniconda/bin/conda\",\n",
      "  \"_CE_M\": \"\",\n",
      "  \"PWD\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced_CountGD\",\n",
      "  \"LOGNAME\": \"renaldy_fredyan\",\n",
      "  \"CONDA_PREFIX\": \"/opt/miniconda/envs/Rey1\",\n",
      "  \"JPY_SESSION_NAME\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced.ipynb\",\n",
      "  \"_\": \"/opt/miniconda/envs/Rey1/bin/torchrun\",\n",
      "  \"MOTD_SHOWN\": \"pam\",\n",
      "  \"HOME\": \"/home/renaldy_fredyan\",\n",
      "  \"LANG\": \"en_US.UTF-8\",\n",
      "  \"LS_COLORS\": \"rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:\",\n",
      "  \"FORCE_COLOR\": \"1\",\n",
      "  \"CONDA_PROMPT_MODIFIER\": \"(Rey1) \",\n",
      "  \"PYDEVD_USE_FRAME_EVAL\": \"NO\",\n",
      "  \"CLICOLOR\": \"1\",\n",
      "  \"CLICOLOR_FORCE\": \"1\",\n",
      "  \"SSH_CONNECTION\": \"140.118.155.218 49304 140.118.125.208 6809\",\n",
      "  \"JPY_PARENT_PID\": \"28228\",\n",
      "  \"LESSCLOSE\": \"/usr/bin/lesspipe %s %s\",\n",
      "  \"TERM\": \"xterm-color\",\n",
      "  \"_CE_CONDA\": \"\",\n",
      "  \"LESSOPEN\": \"| /usr/bin/lesspipe %s\",\n",
      "  \"USER\": \"renaldy_fredyan\",\n",
      "  \"GIT_PAGER\": \"cat\",\n",
      "  \"CONDA_SHLVL\": \"1\",\n",
      "  \"SHLVL\": \"1\",\n",
      "  \"PAGER\": \"cat\",\n",
      "  \"MPLBACKEND\": \"module://matplotlib_inline.backend_inline\",\n",
      "  \"CONDA_PYTHON_EXE\": \"/opt/miniconda/bin/python\",\n",
      "  \"SSH_CLIENT\": \"140.118.155.218 49304 6809\",\n",
      "  \"CONDA_DEFAULT_ENV\": \"Rey1\",\n",
      "  \"XDG_DATA_DIRS\": \"/usr/local/share:/usr/share:/var/lib/snapd/desktop\",\n",
      "  \"PATH\": \"/opt/miniconda/envs/Rey1/bin:/opt/miniconda/condabin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\",\n",
      "  \"SSH_TTY\": \"/dev/pts/0\",\n",
      "  \"OMP_NUM_THREADS\": \"1\",\n",
      "  \"LOCAL_RANK\": \"1\",\n",
      "  \"RANK\": \"1\",\n",
      "  \"GROUP_RANK\": \"0\",\n",
      "  \"ROLE_RANK\": \"1\",\n",
      "  \"ROLE_NAME\": \"default\",\n",
      "  \"LOCAL_WORLD_SIZE\": \"2\",\n",
      "  \"WORLD_SIZE\": \"2\",\n",
      "  \"GROUP_WORLD_SIZE\": \"1\",\n",
      "  \"ROLE_WORLD_SIZE\": \"2\",\n",
      "  \"MASTER_ADDR\": \"127.0.0.1\",\n",
      "  \"MASTER_PORT\": \"29500\",\n",
      "  \"TORCHELASTIC_RESTART_COUNT\": \"0\",\n",
      "  \"TORCHELASTIC_MAX_RESTARTS\": \"0\",\n",
      "  \"TORCHELASTIC_RUN_ID\": \"none\",\n",
      "  \"TORCHELASTIC_USE_AGENT_STORE\": \"True\",\n",
      "  \"NCCL_ASYNC_ERROR_HANDLING\": \"1\",\n",
      "  \"TORCHELASTIC_ERROR_FILE\": \"/tmp/torchelastic_5c6ku36u/none_madbsixm/attempt_0/1/error.json\",\n",
      "  \"QT_QPA_PLATFORM_PLUGIN_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/plugins\",\n",
      "  \"QT_QPA_FONTDIR\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/fonts\",\n",
      "  \"LD_LIBRARY_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/../../lib64:\"\n",
      "}\n",
      "world size: 2, rank: 0, local rank: 0\n",
      "{\n",
      "  \"CUDA_VISIBLE_DEVICES\": \"6,7\",\n",
      "  \"SHELL\": \"/bin/bash\",\n",
      "  \"CONDA_EXE\": \"/opt/miniconda/bin/conda\",\n",
      "  \"_CE_M\": \"\",\n",
      "  \"PWD\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced_CountGD\",\n",
      "  \"LOGNAME\": \"renaldy_fredyan\",\n",
      "  \"CONDA_PREFIX\": \"/opt/miniconda/envs/Rey1\",\n",
      "  \"JPY_SESSION_NAME\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced.ipynb\",\n",
      "  \"_\": \"/opt/miniconda/envs/Rey1/bin/torchrun\",\n",
      "  \"MOTD_SHOWN\": \"pam\",\n",
      "  \"HOME\": \"/home/renaldy_fredyan\",\n",
      "  \"LANG\": \"en_US.UTF-8\",\n",
      "  \"LS_COLORS\": \"rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:\",\n",
      "  \"FORCE_COLOR\": \"1\",\n",
      "  \"CONDA_PROMPT_MODIFIER\": \"(Rey1) \",\n",
      "  \"PYDEVD_USE_FRAME_EVAL\": \"NO\",\n",
      "  \"CLICOLOR\": \"1\",\n",
      "  \"CLICOLOR_FORCE\": \"1\",\n",
      "  \"SSH_CONNECTION\": \"140.118.155.218 49304 140.118.125.208 6809\",\n",
      "  \"JPY_PARENT_PID\": \"28228\",\n",
      "  \"LESSCLOSE\": \"/usr/bin/lesspipe %s %s\",\n",
      "  \"TERM\": \"xterm-color\",\n",
      "  \"_CE_CONDA\": \"\",\n",
      "  \"LESSOPEN\": \"| /usr/bin/lesspipe %s\",\n",
      "  \"USER\": \"renaldy_fredyan\",\n",
      "  \"GIT_PAGER\": \"cat\",\n",
      "  \"CONDA_SHLVL\": \"1\",\n",
      "  \"SHLVL\": \"1\",\n",
      "  \"PAGER\": \"cat\",\n",
      "  \"MPLBACKEND\": \"module://matplotlib_inline.backend_inline\",\n",
      "  \"CONDA_PYTHON_EXE\": \"/opt/miniconda/bin/python\",\n",
      "  \"SSH_CLIENT\": \"140.118.155.218 49304 6809\",\n",
      "  \"CONDA_DEFAULT_ENV\": \"Rey1\",\n",
      "  \"XDG_DATA_DIRS\": \"/usr/local/share:/usr/share:/var/lib/snapd/desktop\",\n",
      "  \"PATH\": \"/opt/miniconda/envs/Rey1/bin:/opt/miniconda/condabin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\",\n",
      "  \"SSH_TTY\": \"/dev/pts/0\",\n",
      "  \"OMP_NUM_THREADS\": \"1\",\n",
      "  \"LOCAL_RANK\": \"0\",\n",
      "  \"RANK\": \"0\",\n",
      "  \"GROUP_RANK\": \"0\",\n",
      "  \"ROLE_RANK\": \"0\",\n",
      "  \"ROLE_NAME\": \"default\",\n",
      "  \"LOCAL_WORLD_SIZE\": \"2\",\n",
      "  \"WORLD_SIZE\": \"2\",\n",
      "  \"GROUP_WORLD_SIZE\": \"1\",\n",
      "  \"ROLE_WORLD_SIZE\": \"2\",\n",
      "  \"MASTER_ADDR\": \"127.0.0.1\",\n",
      "  \"MASTER_PORT\": \"29500\",\n",
      "  \"TORCHELASTIC_RESTART_COUNT\": \"0\",\n",
      "  \"TORCHELASTIC_MAX_RESTARTS\": \"0\",\n",
      "  \"TORCHELASTIC_RUN_ID\": \"none\",\n",
      "  \"TORCHELASTIC_USE_AGENT_STORE\": \"True\",\n",
      "  \"NCCL_ASYNC_ERROR_HANDLING\": \"1\",\n",
      "  \"TORCHELASTIC_ERROR_FILE\": \"/tmp/torchelastic_5c6ku36u/none_madbsixm/attempt_0/0/error.json\",\n",
      "  \"QT_QPA_PLATFORM_PLUGIN_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/plugins\",\n",
      "  \"QT_QPA_FONTDIR\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/fonts\",\n",
      "  \"LD_LIBRARY_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/../../lib64:\"\n",
      "}\n",
      "  == distributed init (rank 1) done.\n",
      "  == distributed init (rank 0) done.\n",
      "Loading config file from config/cfg_fsc147_vit_b_test.py\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755849709/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:50:04,546 | \u001b[34mgit:\n",
      "  sha: d3d2539b1c084bb62ba04308a2ace9b4476442ea, status: has uncommited changes, branch: main\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:50:04,548 | \u001b[34mCommand: main.py --output_dir ./gdino_test -c config/cfg_fsc147_vit_b_test.py --eval --datasets config/datasets_fsc147_val.json --pretrain_model_path ./gdino_train/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:50:04,551 | \u001b[34mFull config saved to ./gdino_test/config_args_all.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:50:04,551 | \u001b[34mworld size: 2\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:50:04,552 | \u001b[34mrank: 0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:50:04,552 | \u001b[34mlocal_rank: 0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:50:04,553 | \u001b[34margs: Namespace(config_file='config/cfg_fsc147_vit_b_test.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='config/datasets_fsc147_val.json', remove_difficult=False, fix_size=False, output_dir='./gdino_test', note='', device='cuda', seed=42, resume='', pretrain_model_path='./gdino_train/checkpoint_best_regular.pth', finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=2, dist_url='env://', rank=0, local_rank=0, amp=False, gpu=0, distributed=True, dist_backend='nccl', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=30, lr_drop=10, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[10, 20], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=False, label_list=['alcohol bottle', 'baguette roll', 'ball', 'banana', 'bead', 'bee', 'birthday candle', 'biscuit', 'boat', 'bottle', 'bowl', 'box', 'bread roll', 'brick', 'buffalo', 'bun', 'calamari ring', 'can', 'candle', 'cap', 'car', 'cartridge', 'cassette', 'cement bag', 'cereal', 'chewing gum piece', 'chopstick', 'clam', 'coffee bean', 'coin', 'cotton ball', 'cow', 'crane', 'crayon', 'croissant', 'crow', 'cup', 'cupcake', 'cupcake holder', 'fish', 'gemstone', 'go game piece', 'goat', 'goldfish snack', 'goose', 'ice cream', 'ice cream cone', 'instant noodle', 'jade stone', 'jeans', 'kidney bean', 'kitchen towel', 'lighter', 'lipstick', 'm&m piece', 'macaron', 'match', 'meat skewer', 'mini blind', 'mosaic tile', 'naan bread', 'nail', 'nut', 'onion ring', 'orange', 'pearl', 'pen', 'pencil', 'penguin', 'pepper', 'person', 'pigeon', 'plate', 'polka dot tile', 'potato', 'rice bag', 'roof tile', 'screw', 'shoe', 'spoon', 'spring roll', 'stair', 'stapler pin', 'straw', 'supermarket shelf', 'swan', 'tomato', 'watermelon', 'window', 'zebra'], val_label_list=['apple', 'candy piece', 'carrom board piece', 'cashew nut', 'comic book', 'crab cake', 'deer', 'egg', 'elephant', 'finger food', 'green pea', 'hot air balloon', 'keyboard key', 'lego', 'marble', 'marker', 'nail polish', 'potato chip', 'red bean', 'round dessert', 'sauce bottle', 'sea shell', 'sheep', 'ski', 'stamp', 'sticky note', 'strawberry', 'sunglasses', 'tree log', 'watch'])\n",
      "\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-13 13:50:04,555 | \u001b[34mbuild model ... ...\u001b[0m\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755849709/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "final text_encoder_type: checkpoints/bert-base-uncased\n",
      "load tokenizer done.\n",
      "final text_encoder_type: checkpoints/bert-base-uncased\n",
      "load tokenizer done.\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-13 13:50:08,085 | \u001b[34mbuild model, done.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:50:08,171 | \u001b[34mnumber of params:236717952\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:50:08,176 | \u001b[34mparams before freezing:\n",
      "{\n",
      "  \"module.transformer.level_embed\": 1024,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.norm.weight\": 256,\n",
      "  \"module.transformer.decoder.norm.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
      "  \"module.transformer.tgt_embed.weight\": 230400,\n",
      "  \"module.transformer.enc_output.weight\": 65536,\n",
      "  \"module.transformer.enc_output.bias\": 256,\n",
      "  \"module.transformer.enc_output_norm.weight\": 256,\n",
      "  \"module.transformer.enc_output_norm.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
      "  \"module.feature_map_proj.weight\": 458752,\n",
      "  \"module.feature_map_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.norm.weight\": 256,\n",
      "  \"module.feature_map_encoder.norm.bias\": 256,\n",
      "  \"module.bert.embeddings.word_embeddings.weight\": 23440896,\n",
      "  \"module.bert.embeddings.position_embeddings.weight\": 393216,\n",
      "  \"module.bert.embeddings.token_type_embeddings.weight\": 1536,\n",
      "  \"module.bert.embeddings.LayerNorm.weight\": 768,\n",
      "  \"module.bert.embeddings.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.0.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.0.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.0.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.0.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.1.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.1.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.1.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.1.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.2.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.2.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.2.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.2.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.3.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.3.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.3.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.3.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.4.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.4.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.4.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.4.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.5.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.5.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.5.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.5.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.6.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.6.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.6.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.6.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.7.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.7.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.7.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.7.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.8.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.8.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.8.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.8.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.9.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.9.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.9.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.9.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.10.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.10.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.10.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.10.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.11.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.11.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.11.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.11.output.LayerNorm.bias\": 768,\n",
      "  \"module.feat_map.weight\": 196608,\n",
      "  \"module.feat_map.bias\": 256,\n",
      "  \"module.input_proj.0.0.weight\": 65536,\n",
      "  \"module.input_proj.0.0.bias\": 256,\n",
      "  \"module.input_proj.0.1.weight\": 256,\n",
      "  \"module.input_proj.0.1.bias\": 256,\n",
      "  \"module.input_proj.1.0.weight\": 131072,\n",
      "  \"module.input_proj.1.0.bias\": 256,\n",
      "  \"module.input_proj.1.1.weight\": 256,\n",
      "  \"module.input_proj.1.1.bias\": 256,\n",
      "  \"module.input_proj.2.0.weight\": 262144,\n",
      "  \"module.input_proj.2.0.bias\": 256,\n",
      "  \"module.input_proj.2.1.weight\": 256,\n",
      "  \"module.input_proj.2.1.bias\": 256,\n",
      "  \"module.input_proj.3.0.weight\": 2359296,\n",
      "  \"module.input_proj.3.0.bias\": 256,\n",
      "  \"module.input_proj.3.1.weight\": 256,\n",
      "  \"module.input_proj.3.1.bias\": 256,\n",
      "  \"module.backbone.0.patch_embed.proj.weight\": 6144,\n",
      "  \"module.backbone.0.patch_embed.proj.bias\": 128,\n",
      "  \"module.backbone.0.patch_embed.norm.weight\": 128,\n",
      "  \"module.backbone.0.patch_embed.norm.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm1.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm1.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table\": 2116,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.qkv.weight\": 49152,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.qkv.bias\": 384,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.proj.weight\": 16384,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.proj.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm2.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc1.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc1.bias\": 512,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc2.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm1.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm1.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table\": 2116,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.qkv.weight\": 49152,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.qkv.bias\": 384,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.proj.weight\": 16384,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.proj.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm2.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc1.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc1.bias\": 512,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc2.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.downsample.reduction.weight\": 131072,\n",
      "  \"module.backbone.0.layers.0.downsample.norm.weight\": 512,\n",
      "  \"module.backbone.0.layers.0.downsample.norm.bias\": 512,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm1.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm1.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table\": 4232,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.qkv.weight\": 196608,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.qkv.bias\": 768,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.proj.weight\": 65536,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.proj.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm2.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc1.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc2.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm1.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm1.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table\": 4232,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.qkv.weight\": 196608,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.qkv.bias\": 768,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.proj.weight\": 65536,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.proj.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm2.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc1.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc2.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.downsample.reduction.weight\": 524288,\n",
      "  \"module.backbone.0.layers.1.downsample.norm.weight\": 1024,\n",
      "  \"module.backbone.0.layers.1.downsample.norm.bias\": 1024,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.downsample.reduction.weight\": 2097152,\n",
      "  \"module.backbone.0.layers.2.downsample.norm.weight\": 2048,\n",
      "  \"module.backbone.0.layers.2.downsample.norm.bias\": 2048,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm1.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table\": 16928,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.qkv.weight\": 3145728,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.qkv.bias\": 3072,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.proj.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.proj.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm2.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc1.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc1.bias\": 4096,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc2.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm1.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table\": 16928,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.qkv.weight\": 3145728,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.qkv.bias\": 3072,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.proj.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.proj.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm2.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc1.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc1.bias\": 4096,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc2.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc2.bias\": 1024,\n",
      "  \"module.backbone.0.norm1.weight\": 256,\n",
      "  \"module.backbone.0.norm1.bias\": 256,\n",
      "  \"module.backbone.0.norm2.weight\": 512,\n",
      "  \"module.backbone.0.norm2.bias\": 512,\n",
      "  \"module.backbone.0.norm3.weight\": 1024,\n",
      "  \"module.backbone.0.norm3.bias\": 1024\n",
      "}\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:50:08,204 | \u001b[34mparams after freezing:\n",
      "{\n",
      "  \"module.transformer.level_embed\": 1024,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
      "ion_weights.bias\": 128,ncoder.layers.5.self_attn.attent\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.norm.weight\": 256,\n",
      "  \"module.transformer.decoder.norm.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
      "  \"module.transformer.tgt_embed.weight\": 230400,\n",
      "  \"module.transformer.enc_output.weight\": 65536,\n",
      "  \"module.transformer.enc_output.bias\": 256,\n",
      "  \"module.transformer.enc_output_norm.weight\": 256,\n",
      "  \"module.transformer.enc_output_norm.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
      "  \"module.feature_map_proj.weight\": 458752,\n",
      "  \"module.feature_map_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.norm.weight\": 256,\n",
      "  \"module.feature_map_encoder.norm.bias\": 256,\n",
      "  \"module.feat_map.weight\": 196608,\n",
      "  \"module.feat_map.bias\": 256,\n",
      "  \"module.input_proj.0.0.weight\": 65536,\n",
      "  \"module.input_proj.0.0.bias\": 256,\n",
      "  \"module.input_proj.0.1.weight\": 256,\n",
      "  \"module.input_proj.0.1.bias\": 256,\n",
      "  \"module.input_proj.1.0.weight\": 131072,\n",
      "  \"module.input_proj.1.0.bias\": 256,\n",
      "  \"module.input_proj.1.1.weight\": 256,\n",
      "  \"module.input_proj.1.1.bias\": 256,\n",
      "  \"module.input_proj.2.0.weight\": 262144,\n",
      "  \"module.input_proj.2.0.bias\": 256,\n",
      "  \"module.input_proj.2.1.weight\": 256,\n",
      "  \"module.input_proj.2.1.bias\": 256,\n",
      "  \"module.input_proj.3.0.weight\": 2359296,\n",
      "  \"module.input_proj.3.0.bias\": 256,\n",
      "  \"module.input_proj.3.1.weight\": 256,\n",
      "  \"module.input_proj.3.1.bias\": 256\n",
      "}\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-13 13:50:08,215 | \u001b[34mbuild dataset ... ...\u001b[0m\n",
      "/home/renaldy_fredyan/PhDResearch/LOCA/Dataset/images_384_VarV2 ./data/fsc147_gdino/fsc147_coco/coco_val_exemplars.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.49s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:50:09,321 | \u001b[34mIgnore keys: []\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:50:09,815 | \u001b[34m<All keys matched successfully>\u001b[0m\n",
      "Input text prompt: apple . candy piece . carrom board piece . cashew nut . comic book . crab cake . deer . egg . elephant . finger food . green pea . hot air balloon . keyboard key . lego . marble . marker . nail polish . potato chip . red bean . round dessert . sauce bottle . sea shell . sheep . ski . stamp . sticky note . strawberry . sunglasses . tree log . watch .\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "input_captions: ['sticky note .', 'sticky note .', 'sauce bottle .', 'sauce bottle .']\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/transformers/modeling_utils.py:812: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/transformers/modeling_utils.py:812: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 88, GT Count: 77\n",
      "Test:  [  0/161]  eta: 0:16:32    time: 6.1670  data: 4.8200  max mem: 4065\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 71, GT Count: 64\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 58\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 61, GT Count: 59\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 77, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 79, GT Count: 78\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 24\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 123, GT Count: 126\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 37\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 59, GT Count: 55\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 61, GT Count: 48\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 57, GT Count: 50\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'potato chip .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 81, GT Count: 74\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14557, device='cuda:0')\n",
      "tensor(9090, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 12\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 11\n",
      "input_captions: ['green pea .', 'sticky note .', 'sticky note .', 'sticky note .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "Test:  [ 10/161]  eta: 0:03:37    time: 1.4375  data: 0.4728  max mem: 4356\n",
      "input_captions: ['sticky note .', 'sticky note .', 'sticky note .', 'sticky note .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 54\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 25\n",
      "input_captions: ['sticky note .', 'sticky note .', 'sticky note .', 'sticky note .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 7\n",
      "input_captions: ['sticky note .', 'sticky note .', 'sticky note .', 'sticky note .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 12\n",
      "input_captions: ['sticky note .', 'sticky note .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 95, GT Count: 44\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 8\n",
      "input_captions: ['candy piece .', 'candy piece .', 'candy piece .', 'candy piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 62, GT Count: 58\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "input_captions: ['candy piece .', 'candy piece .', 'candy piece .', 'candy piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 59, GT Count: 56\n",
      "input_captions: ['candy piece .', 'carrom board piece .', 'carrom board piece .', 'carrom board piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 55\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 15\n",
      "input_captions: ['carrom board piece .', 'carrom board piece .', 'carrom board piece .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 180, GT Count: 182\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 40\n",
      "Test:  [ 20/161]  eta: 0:02:58    time: 1.0194  data: 0.0332  max mem: 4356\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 56, GT Count: 53\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 70\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 77, GT Count: 87\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'carrom board piece .', 'carrom board piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 117, GT Count: 117\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 54\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 35\n",
      "input_captions: ['carrom board piece .', 'carrom board piece .', 'carrom board piece .', 'carrom board piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 376, GT Count: 637\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 143, GT Count: 142\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 21\n",
      "input_captions: ['carrom board piece .', 'carrom board piece .', 'carrom board piece .', 'carrom board piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 223, GT Count: 320\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 103, GT Count: 97\n",
      "input_captions: ['carrom board piece .', 'carrom board piece .', 'carrom board piece .', 'carrom board piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 79, GT Count: 84\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 231, GT Count: 230\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 8\n",
      "input_captions: ['carrom board piece .', 'carrom board piece .', 'tree log .', 'tree log .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 207\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 9\n",
      "input_captions: ['tree log .', 'tree log .', 'candy piece .', 'candy piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 121, GT Count: 122\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 39\n",
      "input_captions: ['candy piece .', 'candy piece .', 'candy piece .', 'candy piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 62, GT Count: 53\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['candy piece .', 'candy piece .', 'candy piece .', 'candy piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 147, GT Count: 122\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 142, GT Count: 139\n",
      "input_captions: ['candy piece .', 'candy piece .', 'candy piece .', 'candy piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 577, GT Count: 530\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 7, GT Count: 7\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 18\n",
      "Test:  [ 30/161]  eta: 0:02:44    time: 1.1549  data: 0.0372  max mem: 4356\n",
      "input_captions: ['candy piece .', 'candy piece .', 'candy piece .', 'candy piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 82, GT Count: 76\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 66, GT Count: 63\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 95, GT Count: 85\n",
      "input_captions: ['candy piece .', 'candy piece .', 'sea shell .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 119, GT Count: 108\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 65, GT Count: 64\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 65, GT Count: 76\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 180, GT Count: 180\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 165, GT Count: 139\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 115, GT Count: 119\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 53, GT Count: 50\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 129, GT Count: 138\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 29\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 18\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 214, GT Count: 215\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 175, GT Count: 175\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 138, GT Count: 117\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 79, GT Count: 69\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 218, GT Count: 221\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 150, GT Count: 150\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 68\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 129, GT Count: 111\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "Test:  [ 40/161]  eta: 0:02:26    time: 1.1464  data: 0.0444  max mem: 4356\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 138, GT Count: 132\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 40\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 69, GT Count: 95\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 168, GT Count: 148\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 98, GT Count: 119\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 48\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 105, GT Count: 83\n",
      "input_captions: ['cashew nut .', 'apple .', 'crab cake .', 'crab cake .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 100, GT Count: 100\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 72, GT Count: 72\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18081, device='cuda:0')\n",
      "tensor(9850, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18081, device='cuda:0')\n",
      "tensor(9850, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 11\n",
      "input_captions: ['crab cake .', 'crab cake .', 'crab cake .', 'crab cake .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18081, device='cuda:0')\n",
      "tensor(9850, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18081, device='cuda:0')\n",
      "tensor(9850, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18081, device='cuda:0')\n",
      "tensor(9850, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18081, device='cuda:0')\n",
      "tensor(9850, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 10\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'deer .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 251, GT Count: 263\n",
      "input_captions: ['deer .', 'deer .', 'deer .', 'deer .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 49\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 229, GT Count: 252\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 130, GT Count: 136\n",
      "input_captions: ['deer .', 'deer .', 'deer .', 'deer .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 61, GT Count: 58\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 62\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 88, GT Count: 89\n",
      "input_captions: ['deer .', 'deer .', 'deer .', 'deer .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 57\n",
      "input_captions: ['deer .', 'deer .', 'deer .', 'deer .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 63, GT Count: 61\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 59, GT Count: 56\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 128, GT Count: 131\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 40\n",
      "Test:  [ 50/161]  eta: 0:02:09    time: 1.0335  data: 0.0436  max mem: 4356\n",
      "input_captions: ['deer .', 'deer .', 'deer .', 'deer .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 148, GT Count: 151\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 23\n",
      "input_captions: ['deer .', 'deer .', 'deer .', 'deer .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 60\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 296, GT Count: 301\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 136, GT Count: 158\n",
      "input_captions: ['deer .', 'deer .', 'sunglasses .', 'sunglasses .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 190, GT Count: 174\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 9\n",
      "input_captions: ['sunglasses .', 'comic book .', 'comic book .', 'sheep .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 69\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 130, GT Count: 219\n",
      "input_captions: ['sheep .', 'sheep .', 'sheep .', 'sheep .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 695, GT Count: 458\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 75, GT Count: 75\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 435, GT Count: 538\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 110, GT Count: 116\n",
      "input_captions: ['sheep .', 'sheep .', 'sheep .', 'sheep .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 386, GT Count: 501\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 259, GT Count: 262\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 250, GT Count: 315\n",
      "input_captions: ['sheep .', 'sheep .', 'sheep .', 'sheep .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 356\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 88, GT Count: 81\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 380, GT Count: 431\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 64, GT Count: 64\n",
      "input_captions: ['sheep .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 42\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 29\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 20\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "Test:  [ 60/161]  eta: 0:01:53    time: 0.9680  data: 0.0544  max mem: 4356\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 18\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 19\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "input_captions: ['egg .', 'watch .', 'watch .', 'watch .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 50\n",
      "input_captions: ['watch .', 'watch .', 'watch .', 'watch .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 59, GT Count: 46\n",
      "input_captions: ['watch .', 'elephant .', 'elephant .', 'elephant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['elephant .', 'elephant .', 'elephant .', 'elephant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 10\n",
      "input_captions: ['elephant .', 'elephant .', 'elephant .', 'elephant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 12\n",
      "Test:  [ 70/161]  eta: 0:01:40    time: 0.9387  data: 0.0562  max mem: 4356\n",
      "input_captions: ['elephant .', 'elephant .', 'elephant .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 31\n",
      "input_captions: ['strawberry .', 'potato chip .', 'comic book .', 'comic book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 7, GT Count: 7\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14557, device='cuda:0')\n",
      "tensor(9090, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['comic book .', 'comic book .', 'red bean .', 'red bean .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2417, device='cuda:0')\n",
      "tensor(14068, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2417, device='cuda:0')\n",
      "tensor(14068, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['red bean .', 'red bean .', 'red bean .', 'ski .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2417, device='cuda:0')\n",
      "tensor(14068, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2417, device='cuda:0')\n",
      "tensor(14068, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2417, device='cuda:0')\n",
      "tensor(14068, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8301, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['stamp .', 'stamp .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 22\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 61, GT Count: 55\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 53, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 67, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 136, GT Count: 133\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 134, GT Count: 133\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 37\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 138, GT Count: 141\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 407, GT Count: 402\n",
      "Test:  [ 80/161]  eta: 0:01:28    time: 0.9782  data: 0.0440  max mem: 4356\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 164, GT Count: 165\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "input_captions: ['marker .', 'marker .', 'marker .', 'marker .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['marker .', 'marker .', 'marker .', 'marker .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 63, GT Count: 64\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 19\n",
      "input_captions: ['marker .', 'marker .', 'marker .', 'marker .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "input_captions: ['marker .', 'sticky note .', 'sticky note .', 'sticky note .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['sticky note .', 'sticky note .', 'sticky note .', 'sticky note .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 26\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "input_captions: ['sticky note .', 'sticky note .', 'sticky note .', 'sticky note .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 21\n",
      "input_captions: ['sticky note .', 'sticky note .', 'sticky note .', 'sauce bottle .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['sauce bottle .', 'sauce bottle .', 'sauce bottle .', 'sauce bottle .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 8\n",
      "input_captions: ['sauce bottle .', 'sauce bottle .', 'sauce bottle .', 'sauce bottle .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 57, GT Count: 55\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 118, GT Count: 133\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 42\n",
      "Test:  [ 90/161]  eta: 0:01:16    time: 1.0076  data: 0.0444  max mem: 4356\n",
      "input_captions: ['sauce bottle .', 'sauce bottle .', 'sauce bottle .', 'sauce bottle .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 112, GT Count: 109\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 30\n",
      "input_captions: ['sauce bottle .', 'sauce bottle .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 55\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 179, GT Count: 196\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 61, GT Count: 61\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 34\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 141, GT Count: 120\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 103, GT Count: 112\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 69, GT Count: 67\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 170, GT Count: 144\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 29\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 111, GT Count: 84\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 40\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 127, GT Count: 122\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 107, GT Count: 98\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 26\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 132, GT Count: 122\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 73, GT Count: 61\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 132, GT Count: 121\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 50\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 22\n",
      "input_captions: ['sheep .', 'sheep .', 'sheep .', 'sheep .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 90, GT Count: 100\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 156, GT Count: 215\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 87, GT Count: 98\n",
      "Test:  [100/161]  eta: 0:01:05    time: 0.9764  data: 0.0461  max mem: 4356\n",
      "input_captions: ['sheep .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 12\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 21\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'watch .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 57\n",
      "input_captions: ['watch .', 'watch .', 'watch .', 'elephant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['elephant .', 'elephant .', 'elephant .', 'elephant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['elephant .', 'elephant .', 'elephant .', 'elephant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "Test:  [110/161]  eta: 0:00:53    time: 0.9388  data: 0.0395  max mem: 4356\n",
      "input_captions: ['elephant .', 'elephant .', 'elephant .', 'elephant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['elephant .', 'elephant .', 'elephant .', 'elephant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['elephant .', 'elephant .', 'elephant .', 'elephant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 15\n",
      "input_captions: ['elephant .', 'elephant .', 'sheep .', 'sheep .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 235, GT Count: 239\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 27\n",
      "input_captions: ['sheep .', 'sheep .', 'sheep .', 'sheep .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 94, GT Count: 87\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 43\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 250, GT Count: 322\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 94, GT Count: 100\n",
      "input_captions: ['sheep .', 'lego .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 63, GT Count: 74\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 172, GT Count: 170\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 797, GT Count: 757\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 58\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 96, GT Count: 81\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 332, GT Count: 267\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 54\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 47\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 132, GT Count: 116\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 135, GT Count: 124\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 229, GT Count: 216\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 44\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 25\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 91, GT Count: 84\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 95, GT Count: 103\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 72, GT Count: 62\n",
      "Test:  [120/161]  eta: 0:00:43    time: 0.9553  data: 0.0407  max mem: 4356\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 55\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 193, GT Count: 209\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 132, GT Count: 113\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 119, GT Count: 116\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 69, GT Count: 62\n",
      "input_captions: ['lego .', 'lego .', 'deer .', 'deer .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 72, GT Count: 63\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 62, GT Count: 55\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 8\n",
      "input_captions: ['deer .', 'sticky note .', 'sticky note .', 'sticky note .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 65, GT Count: 48\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['sticky note .', 'sticky note .', 'sticky note .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 10\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 366, GT Count: 277\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 30\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "Test:  [130/161]  eta: 0:00:32    time: 0.9881  data: 0.0462  max mem: 4356\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'sea shell .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 23\n",
      "input_captions: ['sea shell .', 'sea shell .', 'sea shell .', 'sea shell .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 70\n",
      "input_captions: ['sea shell .', 'sea shell .', 'sea shell .', 'sea shell .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 9\n",
      "input_captions: ['sea shell .', 'sea shell .', 'round dessert .', 'round dessert .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2461, device='cuda:0')\n",
      "tensor(18064, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2461, device='cuda:0')\n",
      "tensor(18064, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 72, GT Count: 63\n",
      "input_captions: ['round dessert .', 'round dessert .', 'round dessert .', 'nail polish .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2461, device='cuda:0')\n",
      "tensor(18064, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 122, GT Count: 119\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2461, device='cuda:0')\n",
      "tensor(18064, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 172, GT Count: 167\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2461, device='cuda:0')\n",
      "tensor(18064, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 51, GT Count: 53\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 66\n",
      "input_captions: ['nail polish .', 'nail polish .', 'nail polish .', 'deer .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 109, GT Count: 110\n",
      "input_captions: ['deer .', 'deer .', 'deer .', 'deer .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 108, GT Count: 106\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 71, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 209, GT Count: 211\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 79, GT Count: 79\n",
      "input_captions: ['deer .', 'carrom board piece .', 'carrom board piece .', 'carrom board piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 202, GT Count: 199\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['carrom board piece .', 'carrom board piece .', 'carrom board piece .', 'carrom board piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 118, GT Count: 52\n",
      "Test:  [140/161]  eta: 0:00:21    time: 1.0177  data: 0.0470  max mem: 4356\n",
      "input_captions: ['carrom board piece .', 'carrom board piece .', 'carrom board piece .', 'carrom board piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 145, GT Count: 140\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 132, GT Count: 116\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 17\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'sunglasses .', 'sunglasses .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 218, GT Count: 169\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 100, GT Count: 62\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 896, GT Count: 1231\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 36\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'sunglasses .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 208, GT Count: 186\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 13\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 84, GT Count: 72\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 312, GT Count: 238\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'marble .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 12\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'marble .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 71, GT Count: 65\n",
      "input_captions: ['candy piece .', 'candy piece .', 'candy piece .', 'candy piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 142, GT Count: 138\n",
      "input_captions: ['candy piece .', 'candy piece .', 'candy piece .', 'candy piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 159, GT Count: 144\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 63, GT Count: 60\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 26\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 87, GT Count: 83\n",
      "input_captions: ['candy piece .', 'candy piece .', 'candy piece .', 'candy piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 892, GT Count: 949\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 39\n",
      "input_captions: ['candy piece .', 'crab cake .', 'tree log .', 'tree log .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18081, device='cuda:0')\n",
      "tensor(9850, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 43\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 71, GT Count: 65\n",
      "Test:  [150/161]  eta: 0:00:11    time: 1.1339  data: 0.0445  max mem: 4356\n",
      "input_captions: ['tree log .', 'tree log .', 'tree log .', 'sea shell .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 80, GT Count: 78\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 53\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 26\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 84, GT Count: 76\n",
      "input_captions: ['sea shell .', 'sea shell .', 'sea shell .', 'sea shell .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 84, GT Count: 83\n",
      "input_captions: ['sea shell .', 'sea shell .', 'sea shell .', 'sea shell .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 61, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['sea shell .', 'keyboard key .', 'hot air balloon .', 'keyboard key .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 95, GT Count: 68\n",
      "input_captions: ['keyboard key .', 'keyboard key .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 67, GT Count: 69\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 86, GT Count: 76\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 144, GT Count: 144\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 30\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'keyboard key .', 'sea shell .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 134, GT Count: 138\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 277, GT Count: 274\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 135, GT Count: 135\n",
      "input_captions: ['sea shell .', 'sea shell .', 'nail polish .', 'nail polish .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 131, GT Count: 139\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 198, GT Count: 198\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 71\n",
      "input_captions: ['nail polish .', 'sea shell .', 'sea shell .', 'sea shell .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 136, GT Count: 134\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 123, GT Count: 118\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 77, GT Count: 74\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 27\n",
      "input_captions: ['carrom board piece .', 'carrom board piece .', 'carrom board piece .', 'carrom board piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 81, GT Count: 80\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 113, GT Count: 116\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 83, GT Count: 100\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 49\n",
      "input_captions: ['carrom board piece .', 'carrom board piece .', 'candy piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 85, GT Count: 83\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 44\n",
      "Test:  [160/161]  eta: 0:00:01    time: 1.1490  data: 0.0409  max mem: 4356\n",
      "Test: Total time: 0:02:51 (1.0628 s / it)\n",
      "# of Images Tested: 643\n",
      "MAE: 7.432348367029549, RMSE: 27.847311967689386\n",
      "Averaged stats: \n",
      "Accumulating evaluation results...\n",
      "DONE (t=4.06s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=6,7 torchrun --nproc_per_node=2 main.py --output_dir ./gdino_test -c config/cfg_fsc147_vit_b_test.py --eval --datasets config/datasets_fsc147_val.json --pretrain_model_path ./gdino_train/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bdd89f7-bdd7-4899-bf0b-4c316e3cfb91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "world size: 2, rank: 0, local rank: 0world size: 2, rank: 1, local rank: 1\n",
      "\n",
      "{\n",
      "  \"CUDA_VISIBLE_DEVICES\": \"6,7\",\n",
      "  \"SHELL\": \"/bin/bash\",\n",
      "  \"CONDA_EXE\": \"/opt/miniconda/bin/conda\",\n",
      "  \"_CE_M\": \"\",\n",
      "  \"PWD\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced_CountGD\",\n",
      "  \"LOGNAME\": \"renaldy_fredyan\",\n",
      "  \"CONDA_PREFIX\": \"/opt/miniconda/envs/Rey1\",\n",
      "  \"JPY_SESSION_NAME\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced.ipynb\",\n",
      "  \"_\": \"/opt/miniconda/envs/Rey1/bin/torchrun\",\n",
      "  \"MOTD_SHOWN\": \"pam\",\n",
      "  \"HOME\": \"/home/renaldy_fredyan\",\n",
      "  \"LANG\": \"en_US.UTF-8\",\n",
      "  \"LS_COLORS\": \"rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:\",\n",
      "  \"FORCE_COLOR\": \"1\",\n",
      "  \"CONDA_PROMPT_MODIFIER\": \"(Rey1) \",\n",
      "  \"PYDEVD_USE_FRAME_EVAL\": \"NO\",\n",
      "  \"CLICOLOR\": \"1\",\n",
      "  \"CLICOLOR_FORCE\": \"1\",\n",
      "  \"SSH_CONNECTION\": \"140.118.155.218 49304 140.118.125.208 6809\",\n",
      "  \"JPY_PARENT_PID\": \"28228\",\n",
      "  \"LESSCLOSE\": \"/usr/bin/lesspipe %s %s\",\n",
      "  \"TERM\": \"xterm-color\",\n",
      "  \"_CE_CONDA\": \"\",\n",
      "  \"LESSOPEN\": \"| /usr/bin/lesspipe %s\",\n",
      "  \"USER\": \"renaldy_fredyan\",\n",
      "  \"GIT_PAGER\": \"cat\",\n",
      "  \"CONDA_SHLVL\": \"1\",\n",
      "  \"SHLVL\": \"1\",\n",
      "  \"PAGER\": \"cat\",\n",
      "  \"MPLBACKEND\": \"module://matplotlib_inline.backend_inline\",\n",
      "  \"CONDA_PYTHON_EXE\": \"/opt/miniconda/bin/python\",\n",
      "  \"SSH_CLIENT\": \"140.118.155.218 49304 6809\",\n",
      "  \"CONDA_DEFAULT_ENV\": \"Rey1\",\n",
      "  \"XDG_DATA_DIRS\": \"/usr/local/share:/usr/share:/var/lib/snapd/desktop\",\n",
      "  \"PATH\": \"/opt/miniconda/envs/Rey1/bin:/opt/miniconda/condabin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\",\n",
      "  \"SSH_TTY\": \"/dev/pts/0\",\n",
      "  \"OMP_NUM_THREADS\": \"1\",\n",
      "  \"LOCAL_RANK\": \"0\",\n",
      "  \"RANK\": \"0\",\n",
      "  \"GROUP_RANK\": \"0\",\n",
      "  \"ROLE_RANK\": \"0\",\n",
      "  \"ROLE_NAME\": \"default\",\n",
      "  \"LOCAL_WORLD_SIZE\": \"2\",\n",
      "  \"WORLD_SIZE\": \"2\",\n",
      "  \"GROUP_WORLD_SIZE\": \"1\",\n",
      "  \"ROLE_WORLD_SIZE\": \"2\",\n",
      "  \"MASTER_ADDR\": \"127.0.0.1\",\n",
      "  \"MASTER_PORT\": \"29500\",\n",
      "  \"TORCHELASTIC_RESTART_COUNT\": \"0\",\n",
      "  \"TORCHELASTIC_MAX_RESTARTS\": \"0\",\n",
      "  \"TORCHELASTIC_RUN_ID\": \"none\",\n",
      "  \"TORCHELASTIC_USE_AGENT_STORE\": \"True\",\n",
      "  \"NCCL_ASYNC_ERROR_HANDLING\": \"1\",\n",
      "  \"TORCHELASTIC_ERROR_FILE\": \"/tmp/torchelastic_q1k0oi3c/none_dozs0z8c/attempt_0/0/error.json\",\n",
      "  \"QT_QPA_PLATFORM_PLUGIN_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/plugins\",\n",
      "  \"QT_QPA_FONTDIR\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/fonts\",\n",
      "  \"LD_LIBRARY_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/../../lib64:\"\n",
      "}{\n",
      "  \"CUDA_VISIBLE_DEVICES\": \"6,7\",\n",
      "  \"SHELL\": \"/bin/bash\",\n",
      "  \"CONDA_EXE\": \"/opt/miniconda/bin/conda\",\n",
      "  \"_CE_M\": \"\",\n",
      "  \"PWD\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced_CountGD\",\n",
      "  \"LOGNAME\": \"renaldy_fredyan\",\n",
      "  \"CONDA_PREFIX\": \"/opt/miniconda/envs/Rey1\",\n",
      "  \"JPY_SESSION_NAME\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced.ipynb\",\n",
      "  \"_\": \"/opt/miniconda/envs/Rey1/bin/torchrun\",\n",
      "  \"MOTD_SHOWN\": \"pam\",\n",
      "  \"HOME\": \"/home/renaldy_fredyan\",\n",
      "  \"LANG\": \"en_US.UTF-8\",\n",
      "  \"LS_COLORS\": \"rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:\",\n",
      "  \"FORCE_COLOR\": \"1\",\n",
      "  \"CONDA_PROMPT_MODIFIER\": \"(Rey1) \",\n",
      "  \"PYDEVD_USE_FRAME_EVAL\": \"NO\",\n",
      "  \"CLICOLOR\": \"1\",\n",
      "  \"CLICOLOR_FORCE\": \"1\",\n",
      "  \"SSH_CONNECTION\": \"140.118.155.218 49304 140.118.125.208 6809\",\n",
      "  \"JPY_PARENT_PID\": \"28228\",\n",
      "  \"LESSCLOSE\": \"/usr/bin/lesspipe %s %s\",\n",
      "  \"TERM\": \"xterm-color\",\n",
      "  \"_CE_CONDA\": \"\",\n",
      "  \"LESSOPEN\": \"| /usr/bin/lesspipe %s\",\n",
      "  \"USER\": \"renaldy_fredyan\",\n",
      "  \"GIT_PAGER\": \"cat\",\n",
      "  \"CONDA_SHLVL\": \"1\",\n",
      "  \"SHLVL\": \"1\",\n",
      "  \"PAGER\": \"cat\",\n",
      "  \"MPLBACKEND\": \"module://matplotlib_inline.backend_inline\",\n",
      "  \"CONDA_PYTHON_EXE\": \"/opt/miniconda/bin/python\",\n",
      "  \"SSH_CLIENT\": \"140.118.155.218 49304 6809\",\n",
      "  \"CONDA_DEFAULT_ENV\": \"Rey1\",\n",
      "  \"XDG_DATA_DIRS\": \"/usr/local/share:/usr/share:/var/lib/snapd/desktop\",\n",
      "  \"PATH\": \"/opt/miniconda/envs/Rey1/bin:/opt/miniconda/condabin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\",\n",
      "  \"SSH_TTY\": \"/dev/pts/0\",\n",
      "  \"OMP_NUM_THREADS\": \"1\",\n",
      "  \"LOCAL_RANK\": \"1\",\n",
      "  \"RANK\": \"1\",\n",
      "  \"GROUP_RANK\": \"0\",\n",
      "  \"ROLE_RANK\": \"1\",\n",
      "  \"ROLE_NAME\": \"default\",\n",
      "  \"LOCAL_WORLD_SIZE\": \"2\",\n",
      "  \"WORLD_SIZE\": \"2\",\n",
      "  \"GROUP_WORLD_SIZE\": \"1\",\n",
      "  \"ROLE_WORLD_SIZE\": \"2\",\n",
      "  \"MASTER_ADDR\": \"127.0.0.1\",\n",
      "  \"MASTER_PORT\": \"29500\",\n",
      "  \"TORCHELASTIC_RESTART_COUNT\": \"0\",\n",
      "  \"TORCHELASTIC_MAX_RESTARTS\": \"0\",\n",
      "  \"TORCHELASTIC_RUN_ID\": \"none\",\n",
      "  \"TORCHELASTIC_USE_AGENT_STORE\": \"True\",\n",
      "  \"NCCL_ASYNC_ERROR_HANDLING\": \"1\",\n",
      "  \"TORCHELASTIC_ERROR_FILE\": \"/tmp/torchelastic_q1k0oi3c/none_dozs0z8c/attempt_0/1/error.json\",\n",
      "  \"QT_QPA_PLATFORM_PLUGIN_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/plugins\",\n",
      "  \"QT_QPA_FONTDIR\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/fonts\",\n",
      "  \"LD_LIBRARY_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/../../lib64:\"\n",
      "}\n",
      "\n",
      "  == distributed init (rank 0) done.\n",
      "Loading config file from config/cfg_fsc147_vit_b.py\n",
      "  == distributed init (rank 1) done.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:56:39,282 | \u001b[34mgit:\n",
      "  sha: d3d2539b1c084bb62ba04308a2ace9b4476442ea, status: has uncommited changes, branch: main\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:56:39,284 | \u001b[34mCommand: main.py --output_dir ./gdino_test -c config/cfg_fsc147_vit_b.py --eval --datasets config/datasets_fsc147_test.json --pretrain_model_path ./gdino_train/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:56:39,286 | \u001b[34mFull config saved to ./gdino_test/config_args_all.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:56:39,287 | \u001b[34mworld size: 2\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:56:39,288 | \u001b[34mrank: 0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:56:39,288 | \u001b[34mlocal_rank: 0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:56:39,289 | \u001b[34margs: Namespace(config_file='config/cfg_fsc147_vit_b.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='config/datasets_fsc147_test.json', remove_difficult=False, fix_size=False, output_dir='./gdino_test', note='', device='cuda', seed=42, resume='', pretrain_model_path='./gdino_train/checkpoint_best_regular.pth', finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=2, dist_url='env://', rank=0, local_rank=0, amp=False, gpu=0, distributed=True, dist_backend='nccl', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=30, lr_drop=10, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[10, 20], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=False, label_list=['alcohol bottle', 'baguette roll', 'ball', 'banana', 'bead', 'bee', 'birthday candle', 'biscuit', 'boat', 'bottle', 'bowl', 'box', 'bread roll', 'brick', 'buffalo', 'bun', 'calamari ring', 'can', 'candle', 'cap', 'car', 'cartridge', 'cassette', 'cement bag', 'cereal', 'chewing gum piece', 'chopstick', 'clam', 'coffee bean', 'coin', 'cotton ball', 'cow', 'crane', 'crayon', 'croissant', 'crow', 'cup', 'cupcake', 'cupcake holder', 'fish', 'gemstone', 'go game piece', 'goat', 'goldfish snack', 'goose', 'ice cream', 'ice cream cone', 'instant noodle', 'jade stone', 'jeans', 'kidney bean', 'kitchen towel', 'lighter', 'lipstick', 'm&m piece', 'macaron', 'match', 'meat skewer', 'mini blind', 'mosaic tile', 'naan bread', 'nail', 'nut', 'onion ring', 'orange', 'pearl', 'pen', 'pencil', 'penguin', 'pepper', 'person', 'pigeon', 'plate', 'polka dot tile', 'potato', 'rice bag', 'roof tile', 'screw', 'shoe', 'spoon', 'spring roll', 'stair', 'stapler pin', 'straw', 'supermarket shelf', 'swan', 'tomato', 'watermelon', 'window', 'zebra'], val_label_list=['ant', 'bird', 'book', 'bottle cap', 'bullet', 'camel', 'chair', 'chicken wing', 'donut', 'donut holder', 'flamingo', 'flower', 'flower pot', 'grape', 'horse', 'kiwi', 'milk carton', 'oyster', 'oyster shell', 'package of fresh cut fruit', 'peach', 'pill', 'polka dot', 'prawn cracker', 'sausage', 'seagull', 'shallot', 'shirt', 'skateboard', 'toilet paper roll'])\n",
      "\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-13 13:56:39,291 | \u001b[34mbuild model ... ...\u001b[0m\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755849709/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755849709/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "final text_encoder_type: checkpoints/bert-base-uncased\n",
      "load tokenizer done.\n",
      "final text_encoder_type: checkpoints/bert-base-uncased\n",
      "load tokenizer done.\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-13 13:56:43,148 | \u001b[34mbuild model, done.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:56:43,237 | \u001b[34mnumber of params:236717952\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:56:43,241 | \u001b[34mparams before freezing:\n",
      "{\n",
      "  \"module.transformer.level_embed\": 1024,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.norm.weight\": 256,\n",
      "  \"module.transformer.decoder.norm.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
      "  \"module.transformer.tgt_embed.weight\": 230400,\n",
      "  \"module.transformer.enc_output.weight\": 65536,\n",
      "  \"module.transformer.enc_output.bias\": 256,\n",
      "  \"module.transformer.enc_output_norm.weight\": 256,\n",
      "  \"module.transformer.enc_output_norm.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
      "  \"module.feature_map_proj.weight\": 458752,\n",
      "  \"module.feature_map_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.norm.weight\": 256,\n",
      "  \"module.feature_map_encoder.norm.bias\": 256,\n",
      "  \"module.bert.embeddings.word_embeddings.weight\": 23440896,\n",
      "  \"module.bert.embeddings.position_embeddings.weight\": 393216,\n",
      "  \"module.bert.embeddings.token_type_embeddings.weight\": 1536,\n",
      "  \"module.bert.embeddings.LayerNorm.weight\": 768,\n",
      "  \"module.bert.embeddings.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.0.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.0.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.0.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.0.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.1.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.1.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.1.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.1.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.2.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.2.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.2.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.2.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.3.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.3.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.3.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.3.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.4.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.4.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.4.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.4.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.5.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.5.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.5.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.5.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.6.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.6.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.6.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.6.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.7.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.7.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.7.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.7.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.8.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.8.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.8.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.8.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.9.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.9.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.9.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.9.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.10.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.10.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.10.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.10.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.11.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.11.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.11.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.11.output.LayerNorm.bias\": 768,\n",
      "  \"module.feat_map.weight\": 196608,\n",
      "  \"module.feat_map.bias\": 256,\n",
      "  \"module.input_proj.0.0.weight\": 65536,\n",
      "  \"module.input_proj.0.0.bias\": 256,\n",
      "  \"module.input_proj.0.1.weight\": 256,\n",
      "  \"module.input_proj.0.1.bias\": 256,\n",
      "  \"module.input_proj.1.0.weight\": 131072,\n",
      "  \"module.input_proj.1.0.bias\": 256,\n",
      "  \"module.input_proj.1.1.weight\": 256,\n",
      "  \"module.input_proj.1.1.bias\": 256,\n",
      "  \"module.input_proj.2.0.weight\": 262144,\n",
      "  \"module.input_proj.2.0.bias\": 256,\n",
      "  \"module.input_proj.2.1.weight\": 256,\n",
      "  \"module.input_proj.2.1.bias\": 256,\n",
      "  \"module.input_proj.3.0.weight\": 2359296,\n",
      "  \"module.input_proj.3.0.bias\": 256,\n",
      "  \"module.input_proj.3.1.weight\": 256,\n",
      "  \"module.input_proj.3.1.bias\": 256,\n",
      "  \"module.backbone.0.patch_embed.proj.weight\": 6144,\n",
      "  \"module.backbone.0.patch_embed.proj.bias\": 128,\n",
      "  \"module.backbone.0.patch_embed.norm.weight\": 128,\n",
      "  \"module.backbone.0.patch_embed.norm.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm1.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm1.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table\": 2116,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.qkv.weight\": 49152,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.qkv.bias\": 384,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.proj.weight\": 16384,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.proj.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm2.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc1.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc1.bias\": 512,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc2.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm1.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm1.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table\": 2116,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.qkv.weight\": 49152,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.qkv.bias\": 384,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.proj.weight\": 16384,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.proj.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm2.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc1.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc1.bias\": 512,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc2.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.downsample.reduction.weight\": 131072,\n",
      "  \"module.backbone.0.layers.0.downsample.norm.weight\": 512,\n",
      "  \"module.backbone.0.layers.0.downsample.norm.bias\": 512,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm1.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm1.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table\": 4232,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.qkv.weight\": 196608,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.qkv.bias\": 768,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.proj.weight\": 65536,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.proj.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm2.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc1.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc2.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm1.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm1.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table\": 4232,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.qkv.weight\": 196608,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.qkv.bias\": 768,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.proj.weight\": 65536,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.proj.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm2.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc1.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc2.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.downsample.reduction.weight\": 524288,\n",
      "  \"module.backbone.0.layers.1.downsample.norm.weight\": 1024,\n",
      "  \"module.backbone.0.layers.1.downsample.norm.bias\": 1024,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.downsample.reduction.weight\": 2097152,\n",
      "  \"module.backbone.0.layers.2.downsample.norm.weight\": 2048,\n",
      "  \"module.backbone.0.layers.2.downsample.norm.bias\": 2048,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm1.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table\": 16928,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.qkv.weight\": 3145728,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.qkv.bias\": 3072,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.proj.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.proj.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm2.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc1.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc1.bias\": 4096,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc2.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm1.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table\": 16928,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.qkv.weight\": 3145728,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.qkv.bias\": 3072,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.proj.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.proj.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm2.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc1.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc1.bias\": 4096,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc2.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc2.bias\": 1024,\n",
      "  \"module.backbone.0.norm1.weight\": 256,\n",
      "  \"module.backbone.0.norm1.bias\": 256,\n",
      "  \"module.backbone.0.norm2.weight\": 512,\n",
      "  \"module.backbone.0.norm2.bias\": 512,\n",
      "  \"module.backbone.0.norm3.weight\": 1024,\n",
      "  \"module.backbone.0.norm3.bias\": 1024\n",
      "}\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:56:43,267 | \u001b[34mparams after freezing:\n",
      "{\n",
      "  \"module.transformer.level_embed\": 1024,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.norm.weight\": 256,\n",
      "  \"module.transformer.decoder.norm.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
      "  \"module.transformer.tgt_embed.weight\": 230400,\n",
      "  \"module.transformer.enc_output.weight\": 65536,\n",
      "  \"module.transformer.enc_output.bias\": 256,\n",
      "  \"module.transformer.enc_output_norm.weight\": 256,\n",
      "  \"module.transformer.enc_output_norm.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
      "  \"module.feature_map_proj.weight\": 458752,\n",
      "  \"module.feature_map_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.norm.weight\": 256,\n",
      "  \"module.feature_map_encoder.norm.bias\": 256,\n",
      "  \"module.feat_map.weight\": 196608,\n",
      "  \"module.feat_map.bias\": 256,\n",
      "  \"module.input_proj.0.0.weight\": 65536,\n",
      "  \"module.input_proj.0.0.bias\": 256,\n",
      "  \"module.input_proj.0.1.weight\": 256,\n",
      "  \"module.input_proj.0.1.bias\": 256,\n",
      "  \"module.input_proj.1.0.weight\": 131072,\n",
      "  \"module.input_proj.1.0.bias\": 256,\n",
      "  \"module.input_proj.1.1.weight\": 256,\n",
      "  \"module.input_proj.1.1.bias\": 256,\n",
      "  \"module.input_proj.2.0.weight\": 262144,\n",
      "  \"module.input_proj.2.0.bias\": 256,\n",
      "  \"module.input_proj.2.1.weight\": 256,\n",
      "  \"module.input_proj.2.1.bias\": 256,\n",
      "  \"module.input_proj.3.0.weight\": 2359296,\n",
      "  \"module.input_proj.3.0.bias\": 256,\n",
      "  \"module.input_proj.3.1.weight\": 256,\n",
      "  \"module.input_proj.3.1.bias\": 256\n",
      "}\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-13 13:56:43,271 | \u001b[34mbuild dataset ... ...\u001b[0m\n",
      "/home/renaldy_fredyan/PhDResearch/LOCA/Dataset/images_384_VarV2 ./data/fsc147_gdino/fsc147_coco/coco_test_exemplars.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.38s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:56:44,496 | \u001b[34mIgnore keys: []\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:56:45,142 | \u001b[34m<All keys matched successfully>\u001b[0m\n",
      "Input text prompt: ant . bird . book . bottle cap . bullet . camel . chair . chicken wing . donut . donut holder . flamingo . flower . flower pot . grape . horse . kiwi . milk carton . oyster . oyster shell . package of fresh cut fruit . peach . pill . polka dot . prawn cracker . sausage . seagull . shallot . shirt . skateboard . toilet paper roll .\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "input_captions: ['pill .', 'flower .', 'flower .', 'shallot .']\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/transformers/modeling_utils.py:812: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/transformers/modeling_utils.py:812: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "Test:  [  0/149]  eta: 0:15:16    time: 6.1516  data: 4.6964  max mem: 4327\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 26\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 124, GT Count: 124\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 20\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 100, GT Count: 113\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 55\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 39\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 61, GT Count: 63\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 43\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['shallot .', 'shallot .', 'sausage .', 'toilet paper roll .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 14\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 65, GT Count: 63\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 90, GT Count: 80\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 52\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 60\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 46\n",
      "Test:  [ 10/149]  eta: 0:03:27    time: 1.4938  data: 0.4463  max mem: 4356\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 69, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 101, GT Count: 100\n",
      "input_captions: ['ant .', 'ant .', 'bullet .', 'bullet .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 194, GT Count: 182\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 29\n",
      "input_captions: ['bullet .', 'toilet paper roll .', 'toilet paper roll .', 'toilet paper roll .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 89, GT Count: 53\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 69\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 105, GT Count: 93\n",
      "input_captions: ['toilet paper roll .', 'toilet paper roll .', 'polka dot .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 133, GT Count: 136\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 22\n",
      "input_captions: ['kiwi .', 'flower pot .', 'flower pot .', 'flower pot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 897, GT Count: 3701\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 63, GT Count: 63\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 172, GT Count: 162\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 403, GT Count: 409\n",
      "input_captions: ['flower pot .', 'flower pot .', 'flower pot .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 62, GT Count: 59\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 50\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 25\n",
      "input_captions: ['donut .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['shirt .', 'shirt .', 'shirt .', 'shirt .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 400, GT Count: 226\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 155, GT Count: 108\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 376, GT Count: 198\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 145, GT Count: 79\n",
      "input_captions: ['shirt .', 'shirt .', 'shirt .', 'shirt .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 127, GT Count: 49\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 140, GT Count: 104\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 14\n",
      "input_captions: ['shirt .', 'shirt .', 'shirt .', 'shirt .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 64, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 29\n",
      "Test:  [ 20/149]  eta: 0:02:44    time: 1.0343  data: 0.0219  max mem: 4356\n",
      "input_captions: ['shirt .', 'shirt .', 'shirt .', 'shirt .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 163, GT Count: 134\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 84, GT Count: 81\n",
      "input_captions: ['shirt .', 'shirt .', 'shirt .', 'shirt .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 175, GT Count: 88\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 128, GT Count: 90\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 30\n",
      "input_captions: ['shirt .', 'shirt .', 'shirt .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 144, GT Count: 79\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 109, GT Count: 63\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 56, GT Count: 61\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 116, GT Count: 116\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 34\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 111, GT Count: 119\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 144, GT Count: 147\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 94, GT Count: 86\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 73\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 231, GT Count: 223\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 32\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 100, GT Count: 99\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 49\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 57, GT Count: 55\n",
      "Test:  [ 30/149]  eta: 0:02:29    time: 1.1219  data: 0.0238  max mem: 4357\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 465, GT Count: 356\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 63, GT Count: 47\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 91, GT Count: 111\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 80, GT Count: 64\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 20\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 37\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 53, GT Count: 53\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 222, GT Count: 174\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 146, GT Count: 174\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 11\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 153, GT Count: 165\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 49\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 170, GT Count: 157\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 48\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 219, GT Count: 195\n",
      "input_captions: ['chair .', 'chair .', 'chair .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 41\n",
      "input_captions: ['sausage .', 'sausage .', 'sausage .', 'sausage .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 59, GT Count: 61\n",
      "input_captions: ['sausage .', 'sausage .', 'sausage .', 'sausage .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 54\n",
      "Test:  [ 40/149]  eta: 0:02:16    time: 1.2335  data: 0.0248  max mem: 4357\n",
      "input_captions: ['sausage .', 'sausage .', 'sausage .', 'sausage .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 60\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['sausage .', 'sausage .', 'sausage .', 'sausage .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 56\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['sausage .', 'sausage .', 'sausage .', 'sausage .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 29\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['sausage .', 'sausage .', 'sausage .', 'camel .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19130, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 10\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 58\n",
      "input_captions: ['donut holder .', 'donut holder .', 'donut holder .', 'donut holder .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['donut holder .', 'donut holder .', 'donut holder .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 174, GT Count: 153\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 129, GT Count: 136\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 99, GT Count: 92\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 51, GT Count: 43\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 74, GT Count: 68\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 151, GT Count: 49\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 122, GT Count: 122\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 109, GT Count: 99\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 64, GT Count: 57\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 66\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 157, GT Count: 146\n",
      "Test:  [ 50/149]  eta: 0:01:58    time: 1.1014  data: 0.0247  max mem: 4357\n",
      "input_captions: ['flamingo .', 'flamingo .', 'pill .', 'camel .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 89, GT Count: 72\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 273, GT Count: 258\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19130, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['oyster shell .', 'oyster shell .', 'oyster shell .', 'oyster shell .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 107, GT Count: 103\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 100, GT Count: 96\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['oyster shell .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 74, GT Count: 70\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 35\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 24\n",
      "input_captions: ['bottle cap .', 'bird .', 'package of fresh cut fruit .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7427, device='cuda:0')\n",
      "tensor(1997, device='cuda:0')\n",
      "tensor(4840, device='cuda:0')\n",
      "tensor(3013, device='cuda:0')\n",
      "tensor(5909, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 115, GT Count: 111\n",
      "input_captions: ['horse .', 'horse .', 'horse .', 'horse .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 292, GT Count: 275\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 149, GT Count: 119\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['horse .', 'horse .', 'horse .', 'horse .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 77, GT Count: 76\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 58\n",
      "input_captions: ['horse .', 'horse .', 'horse .', 'horse .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 54\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 90, GT Count: 94\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 88, GT Count: 86\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 119, GT Count: 118\n",
      "input_captions: ['horse .', 'donut holder .', 'donut holder .', 'donut holder .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 59\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['donut holder .', 'donut holder .', 'donut holder .', 'oyster .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 34\n",
      "Test:  [ 60/149]  eta: 0:01:43    time: 0.9780  data: 0.0259  max mem: 4357\n",
      "input_captions: ['oyster .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 81, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 120, GT Count: 115\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 27\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 43\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 359, GT Count: 323\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 208, GT Count: 221\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 32\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 51, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 201, GT Count: 191\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 82, GT Count: 77\n",
      "input_captions: ['flower .', 'flower .', 'flower .', 'flower .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 11\n",
      "input_captions: ['flower .', 'flower .', 'flower .', 'flower .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['prawn cracker .', 'prawn cracker .', 'prawn cracker .', 'prawn cracker .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10975, device='cuda:0')\n",
      "tensor(10376, device='cuda:0')\n",
      "tensor(2078, device='cuda:0')\n",
      "tensor(8579, device='cuda:0')\n",
      "tensor(2121, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10975, device='cuda:0')\n",
      "tensor(10376, device='cuda:0')\n",
      "tensor(2078, device='cuda:0')\n",
      "tensor(8579, device='cuda:0')\n",
      "tensor(2121, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10975, device='cuda:0')\n",
      "tensor(10376, device='cuda:0')\n",
      "tensor(2078, device='cuda:0')\n",
      "tensor(8579, device='cuda:0')\n",
      "tensor(2121, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10975, device='cuda:0')\n",
      "tensor(10376, device='cuda:0')\n",
      "tensor(2078, device='cuda:0')\n",
      "tensor(8579, device='cuda:0')\n",
      "tensor(2121, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['prawn cracker .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10975, device='cuda:0')\n",
      "tensor(10376, device='cuda:0')\n",
      "tensor(2078, device='cuda:0')\n",
      "tensor(8579, device='cuda:0')\n",
      "tensor(2121, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 72, GT Count: 68\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 131, GT Count: 126\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 94, GT Count: 101\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 37\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 71, GT Count: 64\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 50\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 88, GT Count: 83\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "Test:  [ 70/149]  eta: 0:01:29    time: 0.9860  data: 0.0269  max mem: 4357\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 79, GT Count: 78\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 101, GT Count: 91\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 95, GT Count: 95\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 63, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 66, GT Count: 74\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'skateboard .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 57, GT Count: 56\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['skateboard .', 'skateboard .', 'skateboard .', 'skateboard .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 177, GT Count: 175\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 224, GT Count: 205\n",
      "input_captions: ['skateboard .', 'skateboard .', 'skateboard .', 'skateboard .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 110, GT Count: 95\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 179, GT Count: 166\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 56, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 146, GT Count: 145\n",
      "input_captions: ['skateboard .', 'skateboard .', 'skateboard .', 'skateboard .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 114, GT Count: 93\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 385, GT Count: 363\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 223, GT Count: 218\n",
      "input_captions: ['skateboard .', 'skateboard .', 'skateboard .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 53, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 182, GT Count: 193\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'horse .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 77, GT Count: 87\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 113, GT Count: 111\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['horse .', 'horse .', 'horse .', 'horse .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "Test:  [ 80/149]  eta: 0:01:16    time: 0.9554  data: 0.0283  max mem: 4357\n",
      "input_captions: ['horse .', 'horse .', 'horse .', 'donut holder .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 150, GT Count: 150\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 26\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['donut holder .', 'donut holder .', 'donut holder .', 'donut holder .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['donut holder .', 'donut holder .', 'donut holder .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 25\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 139, GT Count: 131\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 139, GT Count: 131\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 101, GT Count: 89\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 264, GT Count: 262\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 147, GT Count: 155\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 91, GT Count: 89\n",
      "input_captions: ['donut holder .', 'donut holder .', 'donut holder .', 'donut holder .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(9111, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['horse .', 'horse .', 'horse .', 'horse .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 100, GT Count: 90\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "input_captions: ['horse .', 'horse .', 'horse .', 'horse .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['horse .', 'horse .', 'horse .', 'horse .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 94, GT Count: 93\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 40\n",
      "input_captions: ['horse .', 'horse .', 'horse .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 161, GT Count: 149\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 21\n",
      "Test:  [ 90/149]  eta: 0:01:04    time: 0.9565  data: 0.0285  max mem: 4357\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 77, GT Count: 71\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 43\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 63, GT Count: 53\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 97, GT Count: 90\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 51, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 98, GT Count: 101\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 56\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 131, GT Count: 128\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 24\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 125, GT Count: 122\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 99, GT Count: 113\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 112, GT Count: 111\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 52\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 64, GT Count: 75\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 21\n",
      "input_captions: ['shallot .', 'shallot .', 'shallot .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 81, GT Count: 78\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 53, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 35\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 66, GT Count: 58\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "Test:  [100/149]  eta: 0:00:53    time: 0.9742  data: 0.0253  max mem: 4357\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 31\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'flower pot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 103, GT Count: 102\n",
      "input_captions: ['flower pot .', 'flower pot .', 'flower pot .', 'flower pot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 176, GT Count: 185\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 88, GT Count: 82\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 86, GT Count: 84\n",
      "input_captions: ['flower pot .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 108, GT Count: 108\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 90, GT Count: 73\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 39\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 83, GT Count: 82\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 89, GT Count: 89\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 69, GT Count: 76\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 79, GT Count: 74\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 96, GT Count: 92\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 132, GT Count: 118\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 36\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 72, GT Count: 66\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 94, GT Count: 89\n",
      "input_captions: ['shirt .', 'shirt .', 'kiwi .', 'kiwi .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 132, GT Count: 72\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 36\n",
      "Test:  [110/149]  eta: 0:00:42    time: 1.0727  data: 0.0231  max mem: 4357\n",
      "input_captions: ['kiwi .', 'kiwi .', 'kiwi .', 'kiwi .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 209, GT Count: 199\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 102, GT Count: 108\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 316, GT Count: 309\n",
      "input_captions: ['kiwi .', 'kiwi .', 'kiwi .', 'kiwi .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 218, GT Count: 240\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 125, GT Count: 123\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 350, GT Count: 371\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 36\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 61, GT Count: 52\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 305, GT Count: 289\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'peach .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 75, GT Count: 70\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 73, GT Count: 81\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 17\n",
      "input_captions: ['peach .', 'peach .', 'peach .', 'peach .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 48\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 34\n",
      "input_captions: ['peach .', 'peach .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 68\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 26\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 49\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 92, GT Count: 89\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 89, GT Count: 58\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 24\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 125, GT Count: 113\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 76, GT Count: 68\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'sausage .', 'sausage .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 60\n",
      "Test:  [120/149]  eta: 0:00:31    time: 1.1162  data: 0.0234  max mem: 4357\n",
      "input_captions: ['sausage .', 'sausage .', 'sausage .', 'sausage .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 54\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 43\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 55\n",
      "input_captions: ['sausage .', 'sausage .', 'kiwi .', 'kiwi .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 77, GT Count: 73\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 298, GT Count: 292\n",
      "input_captions: ['kiwi .', 'bullet .', 'bullet .', 'bullet .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 381, GT Count: 370\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 71, GT Count: 70\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 21\n",
      "input_captions: ['bullet .', 'bullet .', 'bullet .', 'bullet .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 66, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 60\n",
      "input_captions: ['bullet .', 'bullet .', 'bullet .', 'seagull .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 95, GT Count: 113\n",
      "input_captions: ['seagull .', 'seagull .', 'seagull .', 'seagull .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 60\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 85, GT Count: 121\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 75\n",
      "input_captions: ['seagull .', 'milk carton .', 'milk carton .', 'milk carton .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 84, GT Count: 94\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 330, GT Count: 272\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 44\n",
      "input_captions: ['milk carton .', 'milk carton .', 'milk carton .', 'milk carton .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 164, GT Count: 158\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 60\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 129, GT Count: 146\n",
      "input_captions: ['milk carton .', 'milk carton .', 'milk carton .', 'shirt .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 551, GT Count: 508\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 188, GT Count: 141\n",
      "input_captions: ['shirt .', 'shirt .', 'shirt .', 'shirt .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 202, GT Count: 90\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 162, GT Count: 90\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 87, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 141, GT Count: 73\n",
      "Test:  [130/149]  eta: 0:00:20    time: 1.0231  data: 0.0248  max mem: 4357\n",
      "input_captions: ['toilet paper roll .', 'toilet paper roll .', 'toilet paper roll .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 67, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 44\n",
      "input_captions: ['polka dot .', 'polka dot .', 'polka dot .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 135, GT Count: 128\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 90, GT Count: 122\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 177, GT Count: 180\n",
      "input_captions: ['polka dot .', 'polka dot .', 'polka dot .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 81, GT Count: 81\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 217, GT Count: 209\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 76, GT Count: 75\n",
      "input_captions: ['chair .', 'chair .', 'chair .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 77\n",
      "input_captions: ['chair .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['donut .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 38\n",
      "input_captions: ['donut .', 'donut .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 344, GT Count: 384\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 503, GT Count: 512\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 97, GT Count: 96\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 101, GT Count: 100\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 19\n",
      "input_captions: ['book .', 'book .', 'book .', 'flower pot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 87, GT Count: 87\n",
      "input_captions: ['flower pot .', 'flower pot .', 'flower pot .', 'flower pot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 85, GT Count: 84\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 106, GT Count: 104\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 80, GT Count: 79\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 105, GT Count: 104\n",
      "Test:  [140/149]  eta: 0:00:09    time: 0.9735  data: 0.0254  max mem: 4357\n",
      "input_captions: ['shirt .', 'shirt .', 'bullet .', 'kiwi .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 66, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 110, GT Count: 64\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 253, GT Count: 233\n",
      "input_captions: ['kiwi .', 'kiwi .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 222, GT Count: 217\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 125, GT Count: 110\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 24\n",
      "input_captions: ['ant .', 'ant .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 167, GT Count: 159\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 185, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 900, GT Count: 2560\n",
      "input_captions: ['flower pot .', 'flower pot .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 109, GT Count: 108\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 122, GT Count: 124\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 93, GT Count: 92\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['ant .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 28\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'bullet .', 'bullet .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 33\n",
      "input_captions: ['bullet .', 'milk carton .', 'milk carton .', 'milk carton .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 147, GT Count: 143\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 105, GT Count: 103\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 214, GT Count: 211\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "input_captions: ['milk carton .', 'polka dot .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 98, GT Count: 98\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 204, GT Count: 181\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 36\n",
      "Test:  [148/149]  eta: 0:00:01    time: 1.0038  data: 0.0258  max mem: 4357\n",
      "Test: Total time: 0:02:40 (1.0756 s / it)\n",
      "# of Images Tested: 595\n",
      "MAE: 14.61344537815126, RMSE: 134.92397485842403\n",
      "Averaged stats: \n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.97s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.043\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.036\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=6,7 torchrun --nproc_per_node=2 main.py --output_dir ./gdino_test -c config/cfg_fsc147_vit_b.py --eval --datasets config/datasets_fsc147_test.json --pretrain_model_path ./gdino_train/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d8e892e-36ea-482e-8ee0-cff36883e3a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "world size: 2, rank: 0, local rank: 0\n",
      "{\n",
      "  \"CUDA_VISIBLE_DEVICES\": \"6,7\",\n",
      "  \"SHELL\": \"/bin/bash\",\n",
      "  \"CONDA_EXE\": \"/opt/miniconda/bin/conda\",\n",
      "  \"_CE_M\": \"\",\n",
      "  \"PWD\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced_CountGD\",\n",
      "  \"LOGNAME\": \"renaldy_fredyan\",\n",
      "  \"CONDA_PREFIX\": \"/opt/miniconda/envs/Rey1\",\n",
      "  \"JPY_SESSION_NAME\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced.ipynb\",\n",
      "  \"_\": \"/opt/miniconda/envs/Rey1/bin/torchrun\",\n",
      "  \"MOTD_SHOWN\": \"pam\",\n",
      "  \"HOME\": \"/home/renaldy_fredyan\",\n",
      "  \"LANG\": \"en_US.UTF-8\",\n",
      "  \"LS_COLORS\": \"rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:\",\n",
      "  \"FORCE_COLOR\": \"1\",\n",
      "  \"CONDA_PROMPT_MODIFIER\": \"(Rey1) \",\n",
      "  \"PYDEVD_USE_FRAME_EVAL\": \"NO\",\n",
      "  \"CLICOLOR\": \"1\",\n",
      "  \"CLICOLOR_FORCE\": \"1\",\n",
      "  \"SSH_CONNECTION\": \"140.118.155.218 49304 140.118.125.208 6809\",\n",
      "  \"JPY_PARENT_PID\": \"28228\",\n",
      "  \"LESSCLOSE\": \"/usr/bin/lesspipe %s %s\",\n",
      "  \"TERM\": \"xterm-color\",\n",
      "  \"_CE_CONDA\": \"\",\n",
      "  \"LESSOPEN\": \"| /usr/bin/lesspipe %s\",\n",
      "  \"USER\": \"renaldy_fredyan\",\n",
      "  \"GIT_PAGER\": \"cat\",\n",
      "  \"CONDA_SHLVL\": \"1\",\n",
      "  \"SHLVL\": \"1\",\n",
      "  \"PAGER\": \"cat\",\n",
      "  \"MPLBACKEND\": \"module://matplotlib_inline.backend_inline\",\n",
      "  \"CONDA_PYTHON_EXE\": \"/opt/miniconda/bin/python\",\n",
      "  \"SSH_CLIENT\": \"140.118.155.218 49304 6809\",\n",
      "  \"CONDA_DEFAULT_ENV\": \"Rey1\",\n",
      "  \"XDG_DATA_DIRS\": \"/usr/local/share:/usr/share:/var/lib/snapd/desktop\",\n",
      "  \"PATH\": \"/opt/miniconda/envs/Rey1/bin:/opt/miniconda/condabin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\",\n",
      "  \"SSH_TTY\": \"/dev/pts/0\",\n",
      "  \"OMP_NUM_THREADS\": \"1\",\n",
      "  \"LOCAL_RANK\": \"0\",\n",
      "  \"RANK\": \"0\",\n",
      "  \"GROUP_RANK\": \"0\",\n",
      "  \"ROLE_RANK\": \"0\",\n",
      "  \"ROLE_NAME\": \"default\",\n",
      "  \"LOCAL_WORLD_SIZE\": \"2\",\n",
      "  \"WORLD_SIZE\": \"2\",\n",
      "  \"GROUP_WORLD_SIZE\": \"1\",\n",
      "  \"ROLE_WORLD_SIZE\": \"2\",\n",
      "  \"MASTER_ADDR\": \"127.0.0.1\",\n",
      "  \"MASTER_PORT\": \"29500\",\n",
      "  \"TORCHELASTIC_RESTART_COUNT\": \"0\",\n",
      "  \"TORCHELASTIC_MAX_RESTARTS\": \"0\",\n",
      "  \"TORCHELASTIC_RUN_ID\": \"none\",\n",
      "  \"TORCHELASTIC_USE_AGENT_STORE\": \"True\",\n",
      "  \"NCCL_ASYNC_ERROR_HANDLING\": \"1\",\n",
      "  \"TORCHELASTIC_ERROR_FILE\": \"/tmp/torchelastic_it8hl095/none_9quk7f7l/attempt_0/0/error.json\",\n",
      "  \"QT_QPA_PLATFORM_PLUGIN_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/plugins\",\n",
      "  \"QT_QPA_FONTDIR\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/fonts\",\n",
      "  \"LD_LIBRARY_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/../../lib64:\"\n",
      "}\n",
      "world size: 2, rank: 1, local rank: 1\n",
      "{\n",
      "  \"CUDA_VISIBLE_DEVICES\": \"6,7\",\n",
      "  \"SHELL\": \"/bin/bash\",\n",
      "  \"CONDA_EXE\": \"/opt/miniconda/bin/conda\",\n",
      "  \"_CE_M\": \"\",\n",
      "  \"PWD\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced_CountGD\",\n",
      "  \"LOGNAME\": \"renaldy_fredyan\",\n",
      "  \"CONDA_PREFIX\": \"/opt/miniconda/envs/Rey1\",\n",
      "  \"JPY_SESSION_NAME\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced.ipynb\",\n",
      "  \"_\": \"/opt/miniconda/envs/Rey1/bin/torchrun\",\n",
      "  \"MOTD_SHOWN\": \"pam\",\n",
      "  \"HOME\": \"/home/renaldy_fredyan\",\n",
      "  \"LANG\": \"en_US.UTF-8\",\n",
      "  \"LS_COLORS\": \"rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:\",\n",
      "  \"FORCE_COLOR\": \"1\",\n",
      "  \"CONDA_PROMPT_MODIFIER\": \"(Rey1) \",\n",
      "  \"PYDEVD_USE_FRAME_EVAL\": \"NO\",\n",
      "  \"CLICOLOR\": \"1\",\n",
      "  \"CLICOLOR_FORCE\": \"1\",\n",
      "  \"SSH_CONNECTION\": \"140.118.155.218 49304 140.118.125.208 6809\",\n",
      "  \"JPY_PARENT_PID\": \"28228\",\n",
      "  \"LESSCLOSE\": \"/usr/bin/lesspipe %s %s\",\n",
      "  \"TERM\": \"xterm-color\",\n",
      "  \"_CE_CONDA\": \"\",\n",
      "  \"LESSOPEN\": \"| /usr/bin/lesspipe %s\",\n",
      "  \"USER\": \"renaldy_fredyan\",\n",
      "  \"GIT_PAGER\": \"cat\",\n",
      "  \"CONDA_SHLVL\": \"1\",\n",
      "  \"SHLVL\": \"1\",\n",
      "  \"PAGER\": \"cat\",\n",
      "  \"MPLBACKEND\": \"module://matplotlib_inline.backend_inline\",\n",
      "  \"CONDA_PYTHON_EXE\": \"/opt/miniconda/bin/python\",\n",
      "  \"SSH_CLIENT\": \"140.118.155.218 49304 6809\",\n",
      "  \"CONDA_DEFAULT_ENV\": \"Rey1\",\n",
      "  \"XDG_DATA_DIRS\": \"/usr/local/share:/usr/share:/var/lib/snapd/desktop\",\n",
      "  \"PATH\": \"/opt/miniconda/envs/Rey1/bin:/opt/miniconda/condabin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\",\n",
      "  \"SSH_TTY\": \"/dev/pts/0\",\n",
      "  \"OMP_NUM_THREADS\": \"1\",\n",
      "  \"LOCAL_RANK\": \"1\",\n",
      "  \"RANK\": \"1\",\n",
      "  \"GROUP_RANK\": \"0\",\n",
      "  \"ROLE_RANK\": \"1\",\n",
      "  \"ROLE_NAME\": \"default\",\n",
      "  \"LOCAL_WORLD_SIZE\": \"2\",\n",
      "  \"WORLD_SIZE\": \"2\",\n",
      "  \"GROUP_WORLD_SIZE\": \"1\",\n",
      "  \"ROLE_WORLD_SIZE\": \"2\",\n",
      "  \"MASTER_ADDR\": \"127.0.0.1\",\n",
      "  \"MASTER_PORT\": \"29500\",\n",
      "  \"TORCHELASTIC_RESTART_COUNT\": \"0\",\n",
      "  \"TORCHELASTIC_MAX_RESTARTS\": \"0\",\n",
      "  \"TORCHELASTIC_RUN_ID\": \"none\",\n",
      "  \"TORCHELASTIC_USE_AGENT_STORE\": \"True\",\n",
      "  \"NCCL_ASYNC_ERROR_HANDLING\": \"1\",\n",
      "  \"TORCHELASTIC_ERROR_FILE\": \"/tmp/torchelastic_it8hl095/none_9quk7f7l/attempt_0/1/error.json\",\n",
      "  \"QT_QPA_PLATFORM_PLUGIN_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/plugins\",\n",
      "  \"QT_QPA_FONTDIR\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/fonts\",\n",
      "  \"LD_LIBRARY_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/../../lib64:\"\n",
      "}\n",
      "  == distributed init (rank 1) done.\n",
      "  == distributed init (rank 0) done.\n",
      "Loading config file from config/cfg_fsc147_vit_b_test.py\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:59:58,154 | \u001b[34mgit:\n",
      "  sha: d3d2539b1c084bb62ba04308a2ace9b4476442ea, status: has uncommited changes, branch: main\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:59:58,155 | \u001b[34mCommand: main.py --output_dir ./gdino_test -c config/cfg_fsc147_vit_b_test.py --eval --datasets config/datasets_fsc147_test.json --pretrain_model_path ./gdino_train/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:59:58,157 | \u001b[34mFull config saved to ./gdino_test/config_args_all.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:59:58,158 | \u001b[34mworld size: 2\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:59:58,158 | \u001b[34mrank: 0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:59:58,158 | \u001b[34mlocal_rank: 0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 13:59:58,159 | \u001b[34margs: Namespace(config_file='config/cfg_fsc147_vit_b_test.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='config/datasets_fsc147_test.json', remove_difficult=False, fix_size=False, output_dir='./gdino_test', note='', device='cuda', seed=42, resume='', pretrain_model_path='./gdino_train/checkpoint_best_regular.pth', finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=2, dist_url='env://', rank=0, local_rank=0, amp=False, gpu=0, distributed=True, dist_backend='nccl', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=30, lr_drop=10, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[10, 20], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=False, label_list=['alcohol bottle', 'baguette roll', 'ball', 'banana', 'bead', 'bee', 'birthday candle', 'biscuit', 'boat', 'bottle', 'bowl', 'box', 'bread roll', 'brick', 'buffalo', 'bun', 'calamari ring', 'can', 'candle', 'cap', 'car', 'cartridge', 'cassette', 'cement bag', 'cereal', 'chewing gum piece', 'chopstick', 'clam', 'coffee bean', 'coin', 'cotton ball', 'cow', 'crane', 'crayon', 'croissant', 'crow', 'cup', 'cupcake', 'cupcake holder', 'fish', 'gemstone', 'go game piece', 'goat', 'goldfish snack', 'goose', 'ice cream', 'ice cream cone', 'instant noodle', 'jade stone', 'jeans', 'kidney bean', 'kitchen towel', 'lighter', 'lipstick', 'm&m piece', 'macaron', 'match', 'meat skewer', 'mini blind', 'mosaic tile', 'naan bread', 'nail', 'nut', 'onion ring', 'orange', 'pearl', 'pen', 'pencil', 'penguin', 'pepper', 'person', 'pigeon', 'plate', 'polka dot tile', 'potato', 'rice bag', 'roof tile', 'screw', 'shoe', 'spoon', 'spring roll', 'stair', 'stapler pin', 'straw', 'supermarket shelf', 'swan', 'tomato', 'watermelon', 'window', 'zebra'], val_label_list=['apple', 'candy piece', 'carrom board piece', 'cashew nut', 'comic book', 'crab cake', 'deer', 'egg', 'elephant', 'finger food', 'green pea', 'hot air balloon', 'keyboard key', 'lego', 'marble', 'marker', 'nail polish', 'potato chip', 'red bean', 'round dessert', 'sauce bottle', 'sea shell', 'sheep', 'ski', 'stamp', 'sticky note', 'strawberry', 'sunglasses', 'tree log', 'watch'])\n",
      "\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-13 13:59:58,160 | \u001b[34mbuild model ... ...\u001b[0m\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755849709/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755849709/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "final text_encoder_type: checkpoints/bert-base-uncased\n",
      "load tokenizer done.\n",
      "final text_encoder_type: checkpoints/bert-base-uncased\n",
      "load tokenizer done.\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-13 14:00:02,859 | \u001b[34mbuild model, done.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 14:00:02,943 | \u001b[34mnumber of params:236717952\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 14:00:02,947 | \u001b[34mparams before freezing:\n",
      "{\n",
      "  \"module.transformer.level_embed\": 1024,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.norm.weight\": 256,\n",
      "  \"module.transformer.decoder.norm.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
      "  \"module.transformer.tgt_embed.weight\": 230400,\n",
      "  \"module.transformer.enc_output.weight\": 65536,\n",
      "  \"module.transformer.enc_output.bias\": 256,\n",
      "  \"module.transformer.enc_output_norm.weight\": 256,\n",
      "  \"module.transformer.enc_output_norm.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
      "  \"module.feature_map_proj.weight\": 458752,\n",
      "  \"module.feature_map_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.norm.weight\": 256,\n",
      "  \"module.feature_map_encoder.norm.bias\": 256,\n",
      "  \"module.bert.embeddings.word_embeddings.weight\": 23440896,\n",
      "  \"module.bert.embeddings.position_embeddings.weight\": 393216,\n",
      "  \"module.bert.embeddings.token_type_embeddings.weight\": 1536,\n",
      "  \"module.bert.embeddings.LayerNorm.weight\": 768,\n",
      "  \"module.bert.embeddings.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.0.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.0.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.0.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.0.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.1.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.1.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.1.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.1.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.2.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.2.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.2.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.2.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.3.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.3.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.3.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.3.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.4.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.4.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.4.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.4.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.5.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.5.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.5.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.5.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.6.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.6.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.6.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.6.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.7.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.7.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.7.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.7.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.8.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.8.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.8.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.8.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.9.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.9.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.9.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.9.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.10.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.10.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.10.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.10.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.11.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.11.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.11.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.11.output.LayerNorm.bias\": 768,\n",
      "  \"module.feat_map.weight\": 196608,\n",
      "  \"module.feat_map.bias\": 256,\n",
      "  \"module.input_proj.0.0.weight\": 65536,\n",
      "  \"module.input_proj.0.0.bias\": 256,\n",
      "  \"module.input_proj.0.1.weight\": 256,\n",
      "  \"module.input_proj.0.1.bias\": 256,\n",
      "  \"module.input_proj.1.0.weight\": 131072,\n",
      "  \"module.input_proj.1.0.bias\": 256,\n",
      "  \"module.input_proj.1.1.weight\": 256,\n",
      "  \"module.input_proj.1.1.bias\": 256,\n",
      "  \"module.input_proj.2.0.weight\": 262144,\n",
      "  \"module.input_proj.2.0.bias\": 256,\n",
      "  \"module.input_proj.2.1.weight\": 256,\n",
      "  \"module.input_proj.2.1.bias\": 256,\n",
      "  \"module.input_proj.3.0.weight\": 2359296,\n",
      "  \"module.input_proj.3.0.bias\": 256,\n",
      "  \"module.input_proj.3.1.weight\": 256,\n",
      "  \"module.input_proj.3.1.bias\": 256,\n",
      "  \"module.backbone.0.patch_embed.proj.weight\": 6144,\n",
      "  \"module.backbone.0.patch_embed.proj.bias\": 128,\n",
      "  \"module.backbone.0.patch_embed.norm.weight\": 128,\n",
      "  \"module.backbone.0.patch_embed.norm.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm1.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm1.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table\": 2116,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.qkv.weight\": 49152,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.qkv.bias\": 384,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.proj.weight\": 16384,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.proj.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm2.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc1.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc1.bias\": 512,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc2.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm1.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm1.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table\": 2116,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.qkv.weight\": 49152,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.qkv.bias\": 384,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.proj.weight\": 16384,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.proj.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm2.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc1.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc1.bias\": 512,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc2.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.downsample.reduction.weight\": 131072,\n",
      "  \"module.backbone.0.layers.0.downsample.norm.weight\": 512,\n",
      "  \"module.backbone.0.layers.0.downsample.norm.bias\": 512,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm1.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm1.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table\": 4232,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.qkv.weight\": 196608,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.qkv.bias\": 768,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.proj.weight\": 65536,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.proj.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm2.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc1.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc2.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm1.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm1.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table\": 4232,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.qkv.weight\": 196608,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.qkv.bias\": 768,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.proj.weight\": 65536,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.proj.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm2.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc1.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc2.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.downsample.reduction.weight\": 524288,\n",
      "  \"module.backbone.0.layers.1.downsample.norm.weight\": 1024,\n",
      "  \"module.backbone.0.layers.1.downsample.norm.bias\": 1024,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.downsample.reduction.weight\": 2097152,\n",
      "  \"module.backbone.0.layers.2.downsample.norm.weight\": 2048,\n",
      "  \"module.backbone.0.layers.2.downsample.norm.bias\": 2048,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm1.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table\": 16928,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.qkv.weight\": 3145728,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.qkv.bias\": 3072,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.proj.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.proj.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm2.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc1.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc1.bias\": 4096,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc2.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm1.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table\": 16928,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.qkv.weight\": 3145728,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.qkv.bias\": 3072,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.proj.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.proj.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm2.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc1.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc1.bias\": 4096,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc2.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc2.bias\": 1024,\n",
      "  \"module.backbone.0.norm1.weight\": 256,\n",
      "  \"module.backbone.0.norm1.bias\": 256,\n",
      "  \"module.backbone.0.norm2.weight\": 512,\n",
      "  \"module.backbone.0.norm2.bias\": 512,\n",
      "  \"module.backbone.0.norm3.weight\": 1024,\n",
      "  \"module.backbone.0.norm3.bias\": 1024\n",
      "}\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 14:00:02,974 | \u001b[34mparams after freezing:\n",
      "{\n",
      "  \"module.transformer.level_embed\": 1024,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.norm.weight\": 256,\n",
      "  \"module.transformer.decoder.norm.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
      "  \"module.transformer.tgt_embed.weight\": 230400,\n",
      "  \"module.transformer.enc_output.weight\": 65536,\n",
      "  \"module.transformer.enc_output.bias\": 256,\n",
      "  \"module.transformer.enc_output_norm.weight\": 256,\n",
      "  \"module.transformer.enc_output_norm.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
      "  \"module.feature_map_proj.weight\": 458752,\n",
      "  \"module.feature_map_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.norm.weight\": 256,\n",
      "  \"module.feature_map_encoder.norm.bias\": 256,\n",
      "  \"module.feat_map.weight\": 196608,\n",
      "  \"module.feat_map.bias\": 256,\n",
      "  \"module.input_proj.0.0.weight\": 65536,\n",
      "  \"module.input_proj.0.0.bias\": 256,\n",
      "  \"module.input_proj.0.1.weight\": 256,\n",
      "  \"module.input_proj.0.1.bias\": 256,\n",
      "  \"module.input_proj.1.0.weight\": 131072,\n",
      "  \"module.input_proj.1.0.bias\": 256,\n",
      "  \"module.input_proj.1.1.weight\": 256,\n",
      "  \"module.input_proj.1.1.bias\": 256,\n",
      "  \"module.input_proj.2.0.weight\": 262144,\n",
      "  \"module.input_proj.2.0.bias\": 256,\n",
      "  \"module.input_proj.2.1.weight\": 256,\n",
      "  \"module.input_proj.2.1.bias\": 256,\n",
      "  \"module.input_proj.3.0.weight\": 2359296,\n",
      "  \"module.input_proj.3.0.bias\": 256,\n",
      "  \"module.input_proj.3.1.weight\": 256,\n",
      "  \"module.input_proj.3.1.bias\": 256\n",
      "}\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-13 14:00:02,980 | \u001b[34mbuild dataset ... ...\u001b[0m\n",
      "/home/renaldy_fredyan/PhDResearch/LOCA/Dataset/images_384_VarV2 ./data/fsc147_gdino/fsc147_coco/coco_test_exemplars.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.41s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 14:00:04,164 | \u001b[34mIgnore keys: []\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 14:00:04,667 | \u001b[34m<All keys matched successfully>\u001b[0m\n",
      "Input text prompt: apple . candy piece . carrom board piece . cashew nut . comic book . crab cake . deer . egg . elephant . finger food . green pea . hot air balloon . keyboard key . lego . marble . marker . nail polish . potato chip . red bean . round dessert . sauce bottle . sea shell . sheep . ski . stamp . sticky note . strawberry . sunglasses . tree log . watch .\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "input_captions: ['sea shell .', 'hot air balloon .', 'hot air balloon .', 'strawberry .']\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/transformers/modeling_utils.py:812: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/transformers/modeling_utils.py:812: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "Test:  [  0/149]  eta: 0:16:49    time: 6.7734  data: 5.3834  max mem: 4327\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 26\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 126, GT Count: 124\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 20\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 100, GT Count: 113\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 55\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 39\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 63\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 43\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['strawberry .', 'strawberry .', 'stamp .', 'watch .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 14\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 66, GT Count: 63\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 94, GT Count: 80\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 53, GT Count: 52\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 77, GT Count: 60\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 46\n",
      "Test:  [ 10/149]  eta: 0:03:40    time: 1.5834  data: 0.5267  max mem: 4356\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 102, GT Count: 100\n",
      "input_captions: ['apple .', 'apple .', 'comic book .', 'comic book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 198, GT Count: 182\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 29\n",
      "input_captions: ['comic book .', 'watch .', 'watch .', 'watch .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 81, GT Count: 53\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 69, GT Count: 69\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 104, GT Count: 93\n",
      "input_captions: ['watch .', 'watch .', 'sheep .', 'sheep .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 133, GT Count: 136\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 22\n",
      "input_captions: ['marker .', 'keyboard key .', 'keyboard key .', 'keyboard key .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 896, GT Count: 3701\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 64, GT Count: 63\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 177, GT Count: 162\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 428, GT Count: 409\n",
      "input_captions: ['keyboard key .', 'keyboard key .', 'keyboard key .', 'carrom board piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 59\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 50\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 25\n",
      "input_captions: ['elephant .', 'elephant .', 'elephant .', 'elephant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'sunglasses .', 'sunglasses .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 409, GT Count: 226\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 156, GT Count: 108\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 375, GT Count: 198\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 146, GT Count: 79\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'sunglasses .', 'sunglasses .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 129, GT Count: 49\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 142, GT Count: 104\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 14\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'sunglasses .', 'sunglasses .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 29\n",
      "Test:  [ 20/149]  eta: 0:02:52    time: 1.0648  data: 0.0353  max mem: 4356\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'sunglasses .', 'sunglasses .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 168, GT Count: 134\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 133, GT Count: 81\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'sunglasses .', 'sunglasses .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 176, GT Count: 88\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 125, GT Count: 90\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 30\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'sunglasses .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 145, GT Count: 79\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 111, GT Count: 63\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 56, GT Count: 61\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 119, GT Count: 116\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 34\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 107, GT Count: 119\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 148, GT Count: 147\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 102, GT Count: 86\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 73\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 231, GT Count: 223\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 32\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 102, GT Count: 99\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 51, GT Count: 49\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 55\n",
      "Test:  [ 30/149]  eta: 0:02:37    time: 1.1828  data: 0.0383  max mem: 4357\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 483, GT Count: 356\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 64, GT Count: 47\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 93, GT Count: 111\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 82, GT Count: 64\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 20\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 37\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 53, GT Count: 53\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 227, GT Count: 174\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 157, GT Count: 174\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 11\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 155, GT Count: 165\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 49\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 186, GT Count: 157\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 48\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 226, GT Count: 195\n",
      "input_captions: ['deer .', 'deer .', 'deer .', 'deer .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 41\n",
      "input_captions: ['stamp .', 'stamp .', 'stamp .', 'stamp .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 61\n",
      "input_captions: ['stamp .', 'stamp .', 'stamp .', 'stamp .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 54\n",
      "Test:  [ 40/149]  eta: 0:02:24    time: 1.3128  data: 0.0439  max mem: 4357\n",
      "input_captions: ['stamp .', 'stamp .', 'stamp .', 'stamp .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 60\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['stamp .', 'stamp .', 'stamp .', 'stamp .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 56\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['stamp .', 'stamp .', 'stamp .', 'stamp .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 29\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['stamp .', 'stamp .', 'stamp .', 'crab cake .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 67, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18081, device='cuda:0')\n",
      "tensor(9850, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 10\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 76, GT Count: 58\n",
      "input_captions: ['finger food .', 'finger food .', 'finger food .', 'finger food .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['finger food .', 'finger food .', 'finger food .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 182, GT Count: 153\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 129, GT Count: 136\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 98, GT Count: 92\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 43\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 83, GT Count: 68\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 49\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 121, GT Count: 122\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 104, GT Count: 99\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 65, GT Count: 57\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 88, GT Count: 66\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 151, GT Count: 146\n",
      "Test:  [ 50/149]  eta: 0:02:04    time: 1.1416  data: 0.0422  max mem: 4357\n",
      "input_captions: ['green pea .', 'green pea .', 'sea shell .', 'crab cake .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 88, GT Count: 72\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 275, GT Count: 258\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18081, device='cuda:0')\n",
      "tensor(9850, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['red bean .', 'red bean .', 'red bean .', 'red bean .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2417, device='cuda:0')\n",
      "tensor(14068, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2417, device='cuda:0')\n",
      "tensor(14068, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 106, GT Count: 103\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2417, device='cuda:0')\n",
      "tensor(14068, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 101, GT Count: 96\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2417, device='cuda:0')\n",
      "tensor(14068, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['red bean .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2417, device='cuda:0')\n",
      "tensor(14068, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 73, GT Count: 70\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 35\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 24\n",
      "input_captions: ['cashew nut .', 'candy piece .', 'round dessert .', 'candy piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2461, device='cuda:0')\n",
      "tensor(18064, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 115, GT Count: 111\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'marble .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 295, GT Count: 275\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 150, GT Count: 119\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'marble .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 76\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 58\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'marble .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 54\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 91, GT Count: 94\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 89, GT Count: 86\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 120, GT Count: 118\n",
      "input_captions: ['marble .', 'finger food .', 'finger food .', 'finger food .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 59\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 8\n",
      "input_captions: ['finger food .', 'finger food .', 'finger food .', 'potato chip .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14557, device='cuda:0')\n",
      "tensor(9090, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 34\n",
      "Test:  [ 60/149]  eta: 0:01:48    time: 1.0031  data: 0.0454  max mem: 4357\n",
      "input_captions: ['potato chip .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14557, device='cuda:0')\n",
      "tensor(9090, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 79, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 116, GT Count: 115\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 27\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 43\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 328, GT Count: 323\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 208, GT Count: 221\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 32\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 51, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 210, GT Count: 191\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 82, GT Count: 77\n",
      "input_captions: ['hot air balloon .', 'hot air balloon .', 'hot air balloon .', 'hot air balloon .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['hot air balloon .', 'hot air balloon .', 'hot air balloon .', 'hot air balloon .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['ski .', 'ski .', 'ski .', 'ski .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8301, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8301, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8301, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8301, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 10\n",
      "input_captions: ['ski .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8301, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 71, GT Count: 68\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 133, GT Count: 126\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 93, GT Count: 101\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 37\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 69, GT Count: 64\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 50\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 88, GT Count: 83\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "Test:  [ 70/149]  eta: 0:01:33    time: 1.0135  data: 0.0460  max mem: 4357\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 79, GT Count: 78\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 99, GT Count: 91\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 91, GT Count: 95\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 62, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 71, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 74\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'tree log .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 57, GT Count: 56\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['tree log .', 'tree log .', 'tree log .', 'tree log .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 177, GT Count: 175\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 222, GT Count: 205\n",
      "input_captions: ['tree log .', 'tree log .', 'tree log .', 'tree log .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 113, GT Count: 95\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 175, GT Count: 166\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 56, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 146, GT Count: 145\n",
      "input_captions: ['tree log .', 'tree log .', 'tree log .', 'tree log .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 117, GT Count: 93\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 402, GT Count: 363\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 223, GT Count: 218\n",
      "input_captions: ['tree log .', 'tree log .', 'tree log .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 194, GT Count: 193\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'marble .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 79, GT Count: 87\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 111, GT Count: 111\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'marble .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "Test:  [ 80/149]  eta: 0:01:20    time: 0.9803  data: 0.0441  max mem: 4357\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'finger food .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 151, GT Count: 150\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 26\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['finger food .', 'finger food .', 'finger food .', 'finger food .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['finger food .', 'finger food .', 'finger food .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 139, GT Count: 131\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 140, GT Count: 131\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 111, GT Count: 89\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 269, GT Count: 262\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 144, GT Count: 155\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 90, GT Count: 89\n",
      "input_captions: ['finger food .', 'finger food .', 'finger food .', 'finger food .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'marble .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 102, GT Count: 90\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'marble .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 51, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'marble .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 94, GT Count: 93\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 40\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 157, GT Count: 149\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 21\n",
      "Test:  [ 90/149]  eta: 0:01:07    time: 0.9939  data: 0.0429  max mem: 4357\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 77, GT Count: 71\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 43\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 64, GT Count: 53\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 95, GT Count: 90\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 53, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 102, GT Count: 101\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 56\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 132, GT Count: 128\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 24\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 130, GT Count: 122\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 99, GT Count: 113\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 113, GT Count: 111\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 52\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 65, GT Count: 75\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 79, GT Count: 78\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 53, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 35\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 66, GT Count: 58\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "Test:  [100/149]  eta: 0:00:55    time: 1.0215  data: 0.0457  max mem: 4357\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 31\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'keyboard key .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 102, GT Count: 102\n",
      "input_captions: ['keyboard key .', 'keyboard key .', 'keyboard key .', 'keyboard key .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 188, GT Count: 185\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 94, GT Count: 82\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 86, GT Count: 84\n",
      "input_captions: ['keyboard key .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 109, GT Count: 108\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 90, GT Count: 73\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 39\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 84, GT Count: 82\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 90, GT Count: 89\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 67, GT Count: 76\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 80, GT Count: 74\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 99, GT Count: 92\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 133, GT Count: 118\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 36\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 71, GT Count: 66\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 94, GT Count: 89\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'marker .', 'marker .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 134, GT Count: 72\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 36\n",
      "Test:  [110/149]  eta: 0:00:44    time: 1.1219  data: 0.0487  max mem: 4357\n",
      "input_captions: ['marker .', 'marker .', 'marker .', 'marker .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 208, GT Count: 199\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 100, GT Count: 108\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 314, GT Count: 309\n",
      "input_captions: ['marker .', 'marker .', 'marker .', 'marker .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 233, GT Count: 240\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 126, GT Count: 123\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 368, GT Count: 371\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 36\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 62, GT Count: 52\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 308, GT Count: 289\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'sauce bottle .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 75, GT Count: 70\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 75, GT Count: 81\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 17\n",
      "input_captions: ['sauce bottle .', 'sauce bottle .', 'sauce bottle .', 'sauce bottle .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 48\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 34\n",
      "input_captions: ['sauce bottle .', 'sauce bottle .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 67, GT Count: 68\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 26\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 49\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 93, GT Count: 89\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 77, GT Count: 58\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 24\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 123, GT Count: 113\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 76, GT Count: 68\n",
      "input_captions: ['egg .', 'egg .', 'stamp .', 'stamp .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 60\n",
      "Test:  [120/149]  eta: 0:00:33    time: 1.1691  data: 0.0476  max mem: 4357\n",
      "input_captions: ['stamp .', 'stamp .', 'stamp .', 'stamp .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 54\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 43\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 55\n",
      "input_captions: ['stamp .', 'stamp .', 'marker .', 'marker .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 76, GT Count: 73\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 298, GT Count: 292\n",
      "input_captions: ['marker .', 'comic book .', 'comic book .', 'comic book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 388, GT Count: 370\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 71, GT Count: 70\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['comic book .', 'comic book .', 'comic book .', 'comic book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 63, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 60\n",
      "input_captions: ['comic book .', 'comic book .', 'comic book .', 'sticky note .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 102, GT Count: 113\n",
      "input_captions: ['sticky note .', 'sticky note .', 'sticky note .', 'sticky note .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 60\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 116, GT Count: 121\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 75, GT Count: 75\n",
      "input_captions: ['sticky note .', 'nail polish .', 'nail polish .', 'nail polish .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 94, GT Count: 94\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 340, GT Count: 272\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 44\n",
      "input_captions: ['nail polish .', 'nail polish .', 'nail polish .', 'nail polish .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 161, GT Count: 158\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 60\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 133, GT Count: 146\n",
      "input_captions: ['nail polish .', 'nail polish .', 'nail polish .', 'sunglasses .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 559, GT Count: 508\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 210, GT Count: 141\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'sunglasses .', 'sunglasses .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 196, GT Count: 90\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 166, GT Count: 90\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 87, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 144, GT Count: 73\n",
      "Test:  [130/149]  eta: 0:00:21    time: 1.0791  data: 0.0566  max mem: 4357\n",
      "input_captions: ['watch .', 'watch .', 'watch .', 'sheep .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 67, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 44\n",
      "input_captions: ['sheep .', 'sheep .', 'sheep .', 'sheep .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 137, GT Count: 128\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 91, GT Count: 122\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 178, GT Count: 180\n",
      "input_captions: ['sheep .', 'sheep .', 'sheep .', 'sheep .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 80, GT Count: 81\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 211, GT Count: 209\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 77, GT Count: 75\n",
      "input_captions: ['deer .', 'deer .', 'deer .', 'deer .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 80, GT Count: 77\n",
      "input_captions: ['deer .', 'elephant .', 'elephant .', 'elephant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['elephant .', 'elephant .', 'elephant .', 'elephant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 38\n",
      "input_captions: ['elephant .', 'elephant .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 358, GT Count: 384\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 492, GT Count: 512\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'carrom board piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 98, GT Count: 96\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 101, GT Count: 100\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 19\n",
      "input_captions: ['carrom board piece .', 'carrom board piece .', 'carrom board piece .', 'keyboard key .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 87, GT Count: 87\n",
      "input_captions: ['keyboard key .', 'keyboard key .', 'keyboard key .', 'keyboard key .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 87, GT Count: 84\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 105, GT Count: 104\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 79, GT Count: 79\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 103, GT Count: 104\n",
      "Test:  [140/149]  eta: 0:00:10    time: 1.0262  data: 0.0534  max mem: 4357\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'comic book .', 'marker .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 69, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 112, GT Count: 64\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 254, GT Count: 233\n",
      "input_captions: ['marker .', 'marker .', 'carrom board piece .', 'carrom board piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 220, GT Count: 217\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 125, GT Count: 110\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 24\n",
      "input_captions: ['apple .', 'apple .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 166, GT Count: 159\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 189, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 900, GT Count: 2560\n",
      "input_captions: ['keyboard key .', 'keyboard key .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 108, GT Count: 108\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 111, GT Count: 124\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 92, GT Count: 92\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['apple .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 28\n",
      "input_captions: ['egg .', 'egg .', 'comic book .', 'comic book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 33\n",
      "input_captions: ['comic book .', 'nail polish .', 'nail polish .', 'nail polish .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 142, GT Count: 143\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 105, GT Count: 103\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 214, GT Count: 211\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "input_captions: ['nail polish .', 'sheep .', 'sheep .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 100, GT Count: 98\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 202, GT Count: 181\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 36\n",
      "Test:  [148/149]  eta: 0:00:01    time: 1.0455  data: 0.0422  max mem: 4357\n",
      "Test: Total time: 0:02:47 (1.1232 s / it)\n",
      "# of Images Tested: 595\n",
      "MAE: 14.502521008403361, RMSE: 134.97609498902906\n",
      "Averaged stats: \n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.94s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.053\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.050\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=6,7 torchrun --nproc_per_node=2 main.py --output_dir ./gdino_test -c config/cfg_fsc147_vit_b_test.py --eval --datasets config/datasets_fsc147_test.json --pretrain_model_path ./gdino_train/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d1fe3-2bf4-4751-a546-240c04aaba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying like repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "220695c3-54b4-45c4-bb23-38ad86cf313a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "world size: 2, rank: 1, local rank: 1\n",
      "{\n",
      "  \"CUDA_VISIBLE_DEVICES\": \"6,7\",\n",
      "  \"SHELL\": \"/bin/bash\",\n",
      "  \"CONDA_EXE\": \"/opt/miniconda/bin/conda\",\n",
      "  \"_CE_M\": \"\",\n",
      "  \"PWD\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced_CountGD\",\n",
      "  \"LOGNAME\": \"renaldy_fredyan\",\n",
      "  \"CONDA_PREFIX\": \"/opt/miniconda/envs/Rey1\",\n",
      "  \"JPY_SESSION_NAME\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced.ipynb\",\n",
      "  \"_\": \"/opt/miniconda/envs/Rey1/bin/torchrun\",\n",
      "  \"MOTD_SHOWN\": \"pam\",\n",
      "  \"HOME\": \"/home/renaldy_fredyan\",\n",
      "  \"LANG\": \"en_US.UTF-8\",\n",
      "  \"LS_COLORS\": \"rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:\",\n",
      "  \"FORCE_COLOR\": \"1\",\n",
      "  \"CONDA_PROMPT_MODIFIER\": \"(Rey1) \",\n",
      "  \"PYDEVD_USE_FRAME_EVAL\": \"NO\",\n",
      "  \"CLICOLOR\": \"1\",\n",
      "  \"CLICOLOR_FORCE\": \"1\",\n",
      "  \"SSH_CONNECTION\": \"140.118.155.218 50459 140.118.125.208 6809\",\n",
      "  \"JPY_PARENT_PID\": \"4757\",\n",
      "  \"LESSCLOSE\": \"/usr/bin/lesspipe %s %s\",\n",
      "  \"TERM\": \"xterm-color\",\n",
      "  \"_CE_CONDA\": \"\",\n",
      "  \"LESSOPEN\": \"| /usr/bin/lesspipe %s\",\n",
      "  \"USER\": \"renaldy_fredyan\",\n",
      "  \"GIT_PAGER\": \"cat\",\n",
      "  \"CONDA_SHLVL\": \"1\",\n",
      "  \"SHLVL\": \"1\",\n",
      "  \"PAGER\": \"cat\",\n",
      "  \"MPLBACKEND\": \"module://matplotlib_inline.backend_inline\",\n",
      "  \"CONDA_PYTHON_EXE\": \"/opt/miniconda/bin/python\",\n",
      "  \"SSH_CLIENT\": \"140.118.155.218 50459 6809\",\n",
      "  \"CONDA_DEFAULT_ENV\": \"Rey1\",\n",
      "  \"XDG_DATA_DIRS\": \"/usr/local/share:/usr/share:/var/lib/snapd/desktop\",\n",
      "  \"PATH\": \"/opt/miniconda/envs/Rey1/bin:/opt/miniconda/condabin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\",\n",
      "  \"SSH_TTY\": \"/dev/pts/0\",\n",
      "  \"OMP_NUM_THREADS\": \"1\",\n",
      "  \"LOCAL_RANK\": \"1\",\n",
      "  \"RANK\": \"1\",\n",
      "  \"GROUP_RANK\": \"0\",\n",
      "  \"ROLE_RANK\": \"1\",\n",
      "  \"ROLE_NAME\": \"default\",\n",
      "  \"LOCAL_WORLD_SIZE\": \"2\",\n",
      "  \"WORLD_SIZE\": \"2\",\n",
      "  \"GROUP_WORLD_SIZE\": \"1\",\n",
      "  \"ROLE_WORLD_SIZE\": \"2\",\n",
      "  \"MASTER_ADDR\": \"127.0.0.1\",\n",
      "  \"MASTER_PORT\": \"29500\",\n",
      "  \"TORCHELASTIC_RESTART_COUNT\": \"0\",\n",
      "  \"TORCHELASTIC_MAX_RESTARTS\": \"0\",\n",
      "  \"TORCHELASTIC_RUN_ID\": \"none\",\n",
      "  \"TORCHELASTIC_USE_AGENT_STORE\": \"True\",\n",
      "  \"NCCL_ASYNC_ERROR_HANDLING\": \"1\",\n",
      "  \"TORCHELASTIC_ERROR_FILE\": \"/tmp/torchelastic_4_mflhzb/none_knl2qta3/attempt_0/1/error.json\",\n",
      "  \"QT_QPA_PLATFORM_PLUGIN_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/plugins\",\n",
      "  \"QT_QPA_FONTDIR\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/fonts\",\n",
      "  \"LD_LIBRARY_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/../../lib64:\"\n",
      "}\n",
      "world size: 2, rank: 0, local rank: 0\n",
      "{\n",
      "  \"CUDA_VISIBLE_DEVICES\": \"6,7\",\n",
      "  \"SHELL\": \"/bin/bash\",\n",
      "  \"CONDA_EXE\": \"/opt/miniconda/bin/conda\",\n",
      "  \"_CE_M\": \"\",\n",
      "  \"PWD\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced_CountGD\",\n",
      "  \"LOGNAME\": \"renaldy_fredyan\",\n",
      "  \"CONDA_PREFIX\": \"/opt/miniconda/envs/Rey1\",\n",
      "  \"JPY_SESSION_NAME\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced.ipynb\",\n",
      "  \"_\": \"/opt/miniconda/envs/Rey1/bin/torchrun\",\n",
      "  \"MOTD_SHOWN\": \"pam\",\n",
      "  \"HOME\": \"/home/renaldy_fredyan\",\n",
      "  \"LANG\": \"en_US.UTF-8\",\n",
      "  \"LS_COLORS\": \"rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:\",\n",
      "  \"FORCE_COLOR\": \"1\",\n",
      "  \"CONDA_PROMPT_MODIFIER\": \"(Rey1) \",\n",
      "  \"PYDEVD_USE_FRAME_EVAL\": \"NO\",\n",
      "  \"CLICOLOR\": \"1\",\n",
      "  \"CLICOLOR_FORCE\": \"1\",\n",
      "  \"SSH_CONNECTION\": \"140.118.155.218 50459 140.118.125.208 6809\",\n",
      "  \"JPY_PARENT_PID\": \"4757\",\n",
      "  \"LESSCLOSE\": \"/usr/bin/lesspipe %s %s\",\n",
      "  \"TERM\": \"xterm-color\",\n",
      "  \"_CE_CONDA\": \"\",\n",
      "  \"LESSOPEN\": \"| /usr/bin/lesspipe %s\",\n",
      "  \"USER\": \"renaldy_fredyan\",\n",
      "  \"GIT_PAGER\": \"cat\",\n",
      "  \"CONDA_SHLVL\": \"1\",\n",
      "  \"SHLVL\": \"1\",\n",
      "  \"PAGER\": \"cat\",\n",
      "  \"MPLBACKEND\": \"module://matplotlib_inline.backend_inline\",\n",
      "  \"CONDA_PYTHON_EXE\": \"/opt/miniconda/bin/python\",\n",
      "  \"SSH_CLIENT\": \"140.118.155.218 50459 6809\",\n",
      "  \"CONDA_DEFAULT_ENV\": \"Rey1\",\n",
      "  \"XDG_DATA_DIRS\": \"/usr/local/share:/usr/share:/var/lib/snapd/desktop\",\n",
      "  \"PATH\": \"/opt/miniconda/envs/Rey1/bin:/opt/miniconda/condabin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\",\n",
      "  \"SSH_TTY\": \"/dev/pts/0\",\n",
      "  \"OMP_NUM_THREADS\": \"1\",\n",
      "  \"LOCAL_RANK\": \"0\",\n",
      "  \"RANK\": \"0\",\n",
      "  \"GROUP_RANK\": \"0\",\n",
      "  \"ROLE_RANK\": \"0\",\n",
      "  \"ROLE_NAME\": \"default\",\n",
      "  \"LOCAL_WORLD_SIZE\": \"2\",\n",
      "  \"WORLD_SIZE\": \"2\",\n",
      "  \"GROUP_WORLD_SIZE\": \"1\",\n",
      "  \"ROLE_WORLD_SIZE\": \"2\",\n",
      "  \"MASTER_ADDR\": \"127.0.0.1\",\n",
      "  \"MASTER_PORT\": \"29500\",\n",
      "  \"TORCHELASTIC_RESTART_COUNT\": \"0\",\n",
      "  \"TORCHELASTIC_MAX_RESTARTS\": \"0\",\n",
      "  \"TORCHELASTIC_RUN_ID\": \"none\",\n",
      "  \"TORCHELASTIC_USE_AGENT_STORE\": \"True\",\n",
      "  \"NCCL_ASYNC_ERROR_HANDLING\": \"1\",\n",
      "  \"TORCHELASTIC_ERROR_FILE\": \"/tmp/torchelastic_4_mflhzb/none_knl2qta3/attempt_0/0/error.json\",\n",
      "  \"QT_QPA_PLATFORM_PLUGIN_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/plugins\",\n",
      "  \"QT_QPA_FONTDIR\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/fonts\",\n",
      "  \"LD_LIBRARY_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/../../lib64:\"\n",
      "}\n",
      "  == distributed init (rank 0) done.\n",
      "Loading config file from config/cfg_fsc147_val.py\n",
      "  == distributed init (rank 1) done.\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755849709/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-15 10:31:51,894 | \u001b[34mgit:\n",
      "  sha: d3d2539b1c084bb62ba04308a2ace9b4476442ea, status: has uncommited changes, branch: main\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-15 10:31:51,896 | \u001b[34mCommand: main.py --output_dir ./gdino_val -c config/cfg_fsc147_val.py --eval --datasets config/datasets_fsc147_val.json --pretrain_model_path ./gdino_train/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-15 10:31:51,898 | \u001b[34mFull config saved to ./gdino_val/config_args_all.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-15 10:31:51,899 | \u001b[34mworld size: 2\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-15 10:31:51,900 | \u001b[34mrank: 0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-15 10:31:51,900 | \u001b[34mlocal_rank: 0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-15 10:31:51,901 | \u001b[34margs: Namespace(config_file='config/cfg_fsc147_val.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='config/datasets_fsc147_val.json', remove_difficult=False, fix_size=False, output_dir='./gdino_val', note='', device='cuda', seed=42, resume='', pretrain_model_path='./gdino_train/checkpoint_best_regular.pth', finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=2, dist_url='env://', rank=0, local_rank=0, amp=False, gpu=0, distributed=True, dist_backend='nccl', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=30, lr_drop=10, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[10, 20], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=False, label_list=['alcohol bottle', 'baguette roll', 'ball', 'banana', 'bead', 'bee', 'birthday candle', 'biscuit', 'boat', 'bottle', 'bowl', 'box', 'bread roll', 'brick', 'buffalo', 'bun', 'calamari ring', 'can', 'candle', 'cap', 'car', 'cartridge', 'cassette', 'cement bag', 'cereal', 'chewing gum piece', 'chopstick', 'clam', 'coffee bean', 'coin', 'cotton ball', 'cow', 'crane', 'crayon', 'croissant', 'crow', 'cup', 'cupcake', 'cupcake holder', 'fish', 'gemstone', 'go game piece', 'goat', 'goldfish snack', 'goose', 'ice cream', 'ice cream cone', 'instant noodle', 'jade stone', 'jeans', 'kidney bean', 'kitchen towel', 'lighter', 'lipstick', 'm&m piece', 'macaron', 'match', 'meat skewer', 'mini blind', 'mosaic tile', 'naan bread', 'nail', 'nut', 'onion ring', 'orange', 'pearl', 'pen', 'pencil', 'penguin', 'pepper', 'person', 'pigeon', 'plate', 'polka dot tile', 'potato', 'rice bag', 'roof tile', 'screw', 'shoe', 'spoon', 'spring roll', 'stair', 'stapler pin', 'straw', 'supermarket shelf', 'swan', 'tomato', 'watermelon', 'window', 'zebra'], val_label_list=['ant', 'bird', 'book', 'bottle cap', 'bullet', 'camel', 'chair', 'chicken wing', 'donut', 'donut holder', 'flamingo', 'flower', 'flower pot', 'grape', 'horse', 'kiwi', 'milk carton', 'oyster', 'oyster shell', 'package of fresh cut fruit', 'peach', 'pill', 'polka dot', 'prawn cracker', 'sausage', 'seagull', 'shallot', 'shirt', 'skateboard', 'toilet paper roll'])\n",
      "\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-15 10:31:51,902 | \u001b[34mbuild model ... ...\u001b[0m\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755849709/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "final text_encoder_type: checkpoints/bert-base-uncased\n",
      "load tokenizer done.\n",
      "final text_encoder_type: checkpoints/bert-base-uncased\n",
      "load tokenizer done.\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-15 10:31:56,276 | \u001b[34mbuild model, done.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-15 10:31:56,364 | \u001b[34mnumber of params:236717952\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-15 10:31:56,369 | \u001b[34mparams before freezing:\n",
      "{\n",
      "  \"module.transformer.level_embed\": 1024,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.norm.weight\": 256,\n",
      "  \"module.transformer.decoder.norm.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
      "  \"module.transformer.tgt_embed.weight\": 230400,\n",
      "  \"module.transformer.enc_output.weight\": 65536,\n",
      "  \"module.transformer.enc_output.bias\": 256,\n",
      "  \"module.transformer.enc_output_norm.weight\": 256,\n",
      "  \"module.transformer.enc_output_norm.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
      "  \"module.feature_map_proj.weight\": 458752,\n",
      "  \"module.feature_map_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.norm.weight\": 256,\n",
      "  \"module.feature_map_encoder.norm.bias\": 256,\n",
      "  \"module.bert.embeddings.word_embeddings.weight\": 23440896,\n",
      "  \"module.bert.embeddings.position_embeddings.weight\": 393216,\n",
      "  \"module.bert.embeddings.token_type_embeddings.weight\": 1536,\n",
      "  \"module.bert.embeddings.LayerNorm.weight\": 768,\n",
      "  \"module.bert.embeddings.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.0.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.0.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.0.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.0.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.1.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.1.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.1.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.1.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.2.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.2.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.2.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.2.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.3.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.3.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.3.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.3.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.4.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.4.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.4.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.4.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.5.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.5.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.5.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.5.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.6.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.6.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.6.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.6.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.7.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.7.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.7.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.7.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.8.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.8.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.8.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.8.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.output.dense.bias\": 768,\n",
      "m.weight\": 768,encoder.layer.9.attention.output.LayerNor\n",
      "  \"module.bert.encoder.layer.9.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.9.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.9.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.9.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.9.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.10.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.10.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.10.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.10.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.11.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.11.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.11.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.11.output.LayerNorm.bias\": 768,\n",
      "  \"module.feat_map.weight\": 196608,\n",
      "  \"module.feat_map.bias\": 256,\n",
      "  \"module.input_proj.0.0.weight\": 65536,\n",
      "  \"module.input_proj.0.0.bias\": 256,\n",
      "  \"module.input_proj.0.1.weight\": 256,\n",
      "  \"module.input_proj.0.1.bias\": 256,\n",
      "  \"module.input_proj.1.0.weight\": 131072,\n",
      "  \"module.input_proj.1.0.bias\": 256,\n",
      "  \"module.input_proj.1.1.weight\": 256,\n",
      "  \"module.input_proj.1.1.bias\": 256,\n",
      "  \"module.input_proj.2.0.weight\": 262144,\n",
      "  \"module.input_proj.2.0.bias\": 256,\n",
      "  \"module.input_proj.2.1.weight\": 256,\n",
      "  \"module.input_proj.2.1.bias\": 256,\n",
      "  \"module.input_proj.3.0.weight\": 2359296,\n",
      "  \"module.input_proj.3.0.bias\": 256,\n",
      "  \"module.input_proj.3.1.weight\": 256,\n",
      "  \"module.input_proj.3.1.bias\": 256,\n",
      "  \"module.backbone.0.patch_embed.proj.weight\": 6144,\n",
      "  \"module.backbone.0.patch_embed.proj.bias\": 128,\n",
      "  \"module.backbone.0.patch_embed.norm.weight\": 128,\n",
      "  \"module.backbone.0.patch_embed.norm.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm1.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm1.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table\": 2116,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.qkv.weight\": 49152,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.qkv.bias\": 384,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.proj.weight\": 16384,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.proj.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm2.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc1.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc1.bias\": 512,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc2.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm1.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm1.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table\": 2116,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.qkv.weight\": 49152,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.qkv.bias\": 384,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.proj.weight\": 16384,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.proj.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm2.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc1.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc1.bias\": 512,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc2.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.downsample.reduction.weight\": 131072,\n",
      "  \"module.backbone.0.layers.0.downsample.norm.weight\": 512,\n",
      "  \"module.backbone.0.layers.0.downsample.norm.bias\": 512,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm1.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm1.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table\": 4232,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.qkv.weight\": 196608,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.qkv.bias\": 768,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.proj.weight\": 65536,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.proj.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm2.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc1.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc2.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm1.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm1.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table\": 4232,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.qkv.weight\": 196608,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.qkv.bias\": 768,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.proj.weight\": 65536,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.proj.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm2.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc1.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc2.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.downsample.reduction.weight\": 524288,\n",
      "  \"module.backbone.0.layers.1.downsample.norm.weight\": 1024,\n",
      "  \"module.backbone.0.layers.1.downsample.norm.bias\": 1024,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.downsample.reduction.weight\": 2097152,\n",
      "  \"module.backbone.0.layers.2.downsample.norm.weight\": 2048,\n",
      "  \"module.backbone.0.layers.2.downsample.norm.bias\": 2048,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm1.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table\": 16928,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.qkv.weight\": 3145728,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.qkv.bias\": 3072,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.proj.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.proj.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm2.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc1.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc1.bias\": 4096,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc2.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm1.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table\": 16928,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.qkv.weight\": 3145728,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.qkv.bias\": 3072,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.proj.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.proj.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm2.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc1.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc1.bias\": 4096,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc2.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc2.bias\": 1024,\n",
      "  \"module.backbone.0.norm1.weight\": 256,\n",
      "  \"module.backbone.0.norm1.bias\": 256,\n",
      "  \"module.backbone.0.norm2.weight\": 512,\n",
      "  \"module.backbone.0.norm2.bias\": 512,\n",
      "  \"module.backbone.0.norm3.weight\": 1024,\n",
      "  \"module.backbone.0.norm3.bias\": 1024\n",
      "}\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-15 10:31:56,404 | \u001b[34mparams after freezing:\n",
      "{\n",
      "  \"module.transformer.level_embed\": 1024,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.norm.weight\": 256,\n",
      "  \"module.transformer.decoder.norm.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
      "  \"module.transformer.tgt_embed.weight\": 230400,\n",
      "  \"module.transformer.enc_output.weight\": 65536,\n",
      "  \"module.transformer.enc_output.bias\": 256,\n",
      "  \"module.transformer.enc_output_norm.weight\": 256,\n",
      "  \"module.transformer.enc_output_norm.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
      "  \"module.feature_map_proj.weight\": 458752,\n",
      "  \"module.feature_map_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.norm.weight\": 256,\n",
      "  \"module.feature_map_encoder.norm.bias\": 256,\n",
      "  \"module.feat_map.weight\": 196608,\n",
      "  \"module.feat_map.bias\": 256,\n",
      "  \"module.input_proj.0.0.weight\": 65536,\n",
      "  \"module.input_proj.0.0.bias\": 256,\n",
      "  \"module.input_proj.0.1.weight\": 256,\n",
      "  \"module.input_proj.0.1.bias\": 256,\n",
      "  \"module.input_proj.1.0.weight\": 131072,\n",
      "  \"module.input_proj.1.0.bias\": 256,\n",
      "  \"module.input_proj.1.1.weight\": 256,\n",
      "  \"module.input_proj.1.1.bias\": 256,\n",
      "  \"module.input_proj.2.0.weight\": 262144,\n",
      "  \"module.input_proj.2.0.bias\": 256,\n",
      "  \"module.input_proj.2.1.weight\": 256,\n",
      "  \"module.input_proj.2.1.bias\": 256,\n",
      "  \"module.input_proj.3.0.weight\": 2359296,\n",
      "  \"module.input_proj.3.0.bias\": 256,\n",
      "  \"module.input_proj.3.1.weight\": 256,\n",
      "  \"module.input_proj.3.1.bias\": 256\n",
      "}\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-15 10:31:56,409 | \u001b[34mbuild dataset ... ...\u001b[0m\n",
      "/home/renaldy_fredyan/PhDResearch/LOCA/Dataset/images_384_VarV2 ./data/fsc147_gdino/fsc147_coco/coco_val_exemplars.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.50s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-15 10:31:58,296 | \u001b[34mIgnore keys: []\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-15 10:31:58,768 | \u001b[34m<All keys matched successfully>\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Input text prompt: ant . bird . book . bottle cap . bullet . camel . chair . chicken wing . donut . donut holder . flamingo . flower . flower pot . grape . horse . kiwi . milk carton . oyster . oyster shell . package of fresh cut fruit . peach . pill . polka dot . prawn cracker . sausage . seagull . shallot . shirt . skateboard . toilet paper roll .\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "input_captions: ['seagull .', 'seagull .', 'peach .', 'peach .']\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/transformers/modeling_utils.py:812: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/transformers/modeling_utils.py:812: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 86, GT Count: 77\n",
      "Test:  [  0/161]  eta: 0:13:49    time: 5.1546  data: 3.8590  max mem: 4065\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 64\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 58\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 59, GT Count: 59\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 78\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 24\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 125, GT Count: 126\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 37\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 57, GT Count: 55\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 59, GT Count: 48\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 50\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'oyster .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 81, GT Count: 74\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 19\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 12\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['flamingo .', 'seagull .', 'seagull .', 'seagull .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "Test:  [ 10/161]  eta: 0:03:19    time: 1.3186  data: 0.3780  max mem: 4356\n",
      "input_captions: ['seagull .', 'seagull .', 'seagull .', 'seagull .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 54\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['seagull .', 'seagull .', 'seagull .', 'seagull .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 7\n",
      "input_captions: ['seagull .', 'seagull .', 'seagull .', 'seagull .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 12\n",
      "input_captions: ['seagull .', 'seagull .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 92, GT Count: 44\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 8\n",
      "input_captions: ['bird .', 'bird .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 62, GT Count: 58\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "input_captions: ['bird .', 'bird .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 59, GT Count: 56\n",
      "input_captions: ['bird .', 'book .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 55\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 15\n",
      "input_captions: ['book .', 'book .', 'book .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 179, GT Count: 182\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 40\n",
      "Test:  [ 20/161]  eta: 0:02:46    time: 0.9835  data: 0.0313  max mem: 4356\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 56, GT Count: 53\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 70\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 87\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 117, GT Count: 117\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 54\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 35\n",
      "input_captions: ['book .', 'book .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 452, GT Count: 637\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 174, GT Count: 142\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 21\n",
      "input_captions: ['book .', 'book .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 331, GT Count: 320\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 103, GT Count: 97\n",
      "input_captions: ['book .', 'book .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 82, GT Count: 84\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 251, GT Count: 230\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 8\n",
      "input_captions: ['book .', 'book .', 'skateboard .', 'skateboard .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 146, GT Count: 207\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 9\n",
      "input_captions: ['skateboard .', 'skateboard .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 121, GT Count: 122\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 39\n",
      "input_captions: ['bird .', 'bird .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 62, GT Count: 53\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['bird .', 'bird .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 147, GT Count: 122\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 144, GT Count: 139\n",
      "input_captions: ['bird .', 'bird .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 559, GT Count: 530\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 7, GT Count: 7\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "Test:  [ 30/161]  eta: 0:02:31    time: 1.0669  data: 0.0383  max mem: 4356\n",
      "input_captions: ['bird .', 'bird .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 86, GT Count: 76\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 67, GT Count: 63\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 93, GT Count: 85\n",
      "input_captions: ['bird .', 'bird .', 'pill .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 119, GT Count: 108\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 65, GT Count: 64\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 64, GT Count: 76\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 180, GT Count: 180\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 151, GT Count: 139\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 115, GT Count: 119\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 50\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 121, GT Count: 138\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 29\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 18\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 216, GT Count: 215\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 170, GT Count: 175\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 128, GT Count: 117\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 69\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 214, GT Count: 221\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 150, GT Count: 150\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 68\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 126, GT Count: 111\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "Test:  [ 40/161]  eta: 0:02:16    time: 1.0719  data: 0.0435  max mem: 4356\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 137, GT Count: 132\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 40\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 95\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 161, GT Count: 148\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 96, GT Count: 119\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 48\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 115, GT Count: 83\n",
      "input_captions: ['bottle cap .', 'ant .', 'camel .', 'camel .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 100, GT Count: 100\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 72, GT Count: 72\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19130, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19130, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 11\n",
      "input_captions: ['camel .', 'camel .', 'camel .', 'camel .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19130, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19130, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19130, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19130, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 10\n",
      "input_captions: ['horse .', 'horse .', 'horse .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 256, GT Count: 263\n",
      "input_captions: ['chair .', 'chair .', 'chair .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 49\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 239, GT Count: 252\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 126, GT Count: 136\n",
      "input_captions: ['chair .', 'chair .', 'chair .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 73, GT Count: 58\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 80, GT Count: 62\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 92, GT Count: 89\n",
      "input_captions: ['chair .', 'chair .', 'chair .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 57\n",
      "input_captions: ['chair .', 'chair .', 'chair .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 63, GT Count: 61\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 64, GT Count: 56\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 127, GT Count: 131\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 40\n",
      "Test:  [ 50/161]  eta: 0:02:02    time: 1.0171  data: 0.0435  max mem: 4356\n",
      "input_captions: ['chair .', 'chair .', 'chair .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 148, GT Count: 151\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 23\n",
      "input_captions: ['chair .', 'chair .', 'chair .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 74, GT Count: 60\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 303, GT Count: 301\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 144, GT Count: 158\n",
      "input_captions: ['chair .', 'chair .', 'shirt .', 'shirt .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 193, GT Count: 174\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 9\n",
      "input_captions: ['shirt .', 'bullet .', 'bullet .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 69\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 226, GT Count: 219\n",
      "input_captions: ['polka dot .', 'polka dot .', 'polka dot .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 712, GT Count: 458\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 75, GT Count: 75\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 482, GT Count: 538\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 116, GT Count: 116\n",
      "input_captions: ['polka dot .', 'polka dot .', 'polka dot .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 424, GT Count: 501\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 269, GT Count: 262\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 285, GT Count: 315\n",
      "input_captions: ['polka dot .', 'polka dot .', 'polka dot .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 356\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 92, GT Count: 81\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 447, GT Count: 431\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 64, GT Count: 64\n",
      "input_captions: ['polka dot .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 42\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 29\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 20\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "Test:  [ 60/161]  eta: 0:01:47    time: 0.9430  data: 0.0422  max mem: 4356\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 18\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 19\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "input_captions: ['chicken wing .', 'toilet paper roll .', 'toilet paper roll .', 'toilet paper roll .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 50\n",
      "input_captions: ['toilet paper roll .', 'toilet paper roll .', 'toilet paper roll .', 'toilet paper roll .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 46\n",
      "input_captions: ['toilet paper roll .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['donut .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 10\n",
      "input_captions: ['donut .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 12\n",
      "Test:  [ 70/161]  eta: 0:01:35    time: 0.9170  data: 0.0408  max mem: 4356\n",
      "input_captions: ['donut .', 'donut .', 'donut .', 'shallot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 31\n",
      "input_captions: ['shallot .', 'oyster .', 'bullet .', 'bullet .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4618, device='cuda:0')\n",
      "tensor(4140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 7, GT Count: 7\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['bullet .', 'bullet .', 'oyster shell .', 'oyster shell .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7960, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['oyster shell .', 'oyster shell .', 'oyster shell .', 'prawn cracker .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(21480, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10975, device='cuda:0')\n",
      "tensor(10376, device='cuda:0')\n",
      "tensor(2078, device='cuda:0')\n",
      "tensor(8579, device='cuda:0')\n",
      "tensor(2121, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['sausage .', 'sausage .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(24165, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 22\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 62, GT Count: 55\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 53, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 136, GT Count: 133\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 136, GT Count: 133\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 37\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 137, GT Count: 141\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 405, GT Count: 402\n",
      "Test:  [ 80/161]  eta: 0:01:24    time: 0.9714  data: 0.0421  max mem: 4356\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 168, GT Count: 165\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "input_captions: ['kiwi .', 'kiwi .', 'kiwi .', 'kiwi .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['kiwi .', 'kiwi .', 'kiwi .', 'kiwi .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 63, GT Count: 64\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 19\n",
      "input_captions: ['kiwi .', 'kiwi .', 'kiwi .', 'kiwi .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "input_captions: ['kiwi .', 'seagull .', 'seagull .', 'seagull .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11382, device='cuda:0')\n",
      "tensor(9148, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['seagull .', 'seagull .', 'seagull .', 'seagull .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 26\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "input_captions: ['seagull .', 'seagull .', 'seagull .', 'seagull .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 21\n",
      "input_captions: ['seagull .', 'seagull .', 'seagull .', 'peach .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['peach .', 'peach .', 'peach .', 'peach .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 51, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 8\n",
      "input_captions: ['peach .', 'peach .', 'peach .', 'peach .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 57, GT Count: 55\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 120, GT Count: 133\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 42\n",
      "Test:  [ 90/161]  eta: 0:01:13    time: 0.9994  data: 0.0420  max mem: 4356\n",
      "input_captions: ['peach .', 'peach .', 'peach .', 'peach .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 113, GT Count: 109\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 30\n",
      "input_captions: ['peach .', 'peach .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18237, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 59, GT Count: 55\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 182, GT Count: 196\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 63, GT Count: 61\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 34\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 135, GT Count: 120\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 103, GT Count: 112\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 72, GT Count: 67\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 169, GT Count: 144\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 29\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 111, GT Count: 84\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 40\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 128, GT Count: 122\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 106, GT Count: 98\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 69, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 26\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 133, GT Count: 122\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 74, GT Count: 61\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 127, GT Count: 121\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 50\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 22\n",
      "input_captions: ['polka dot .', 'polka dot .', 'polka dot .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 101, GT Count: 100\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 231, GT Count: 215\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 87, GT Count: 98\n",
      "Test:  [100/161]  eta: 0:01:02    time: 0.9603  data: 0.0415  max mem: 4356\n",
      "input_captions: ['polka dot .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 12\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 21\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'toilet paper roll .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 62, GT Count: 57\n",
      "input_captions: ['toilet paper roll .', 'toilet paper roll .', 'toilet paper roll .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11848, device='cuda:0')\n",
      "tensor(3259, device='cuda:0')\n",
      "tensor(4897, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['donut .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['donut .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "Test:  [110/161]  eta: 0:00:51    time: 0.9233  data: 0.0381  max mem: 4356\n",
      "input_captions: ['donut .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['donut .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .', 'donut .', 'donut .', 'donut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 15\n",
      "input_captions: ['donut .', 'donut .', 'polka dot .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2123, device='cuda:0')\n",
      "tensor(4904, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 254, GT Count: 239\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 27\n",
      "input_captions: ['polka dot .', 'polka dot .', 'polka dot .', 'polka dot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 95, GT Count: 87\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 43\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 262, GT Count: 322\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 100, GT Count: 100\n",
      "input_captions: ['polka dot .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(29499, device='cuda:0')\n",
      "tensor(11089, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 65, GT Count: 74\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 171, GT Count: 170\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 798, GT Count: 757\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 58\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 95, GT Count: 81\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 331, GT Count: 267\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 54\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 47\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 135, GT Count: 116\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 135, GT Count: 124\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 224, GT Count: 216\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 44\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 25\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 94, GT Count: 84\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 92, GT Count: 103\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 72, GT Count: 62\n",
      "Test:  [120/161]  eta: 0:00:41    time: 0.9417  data: 0.0369  max mem: 4356\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 55\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 189, GT Count: 209\n",
      "input_captions: ['grape .', 'grape .', 'grape .', 'grape .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 134, GT Count: 113\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 119, GT Count: 116\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 71, GT Count: 62\n",
      "input_captions: ['grape .', 'grape .', 'chair .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14722, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 74, GT Count: 63\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 55\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['chair .', 'seagull .', 'seagull .', 'seagull .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 76, GT Count: 48\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['seagull .', 'seagull .', 'seagull .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(24848, device='cuda:0')\n",
      "tensor(2140, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'flamingo .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['flamingo .', 'flamingo .', 'flamingo .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 368, GT Count: 277\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19091, device='cuda:0')\n",
      "tensor(2080, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 30\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "Test:  [130/161]  eta: 0:00:31    time: 0.9875  data: 0.0405  max mem: 4356\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'chicken wing .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['chicken wing .', 'chicken wing .', 'chicken wing .', 'pill .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7975, device='cuda:0')\n",
      "tensor(3358, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 23\n",
      "input_captions: ['pill .', 'pill .', 'pill .', 'pill .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 70\n",
      "input_captions: ['pill .', 'pill .', 'pill .', 'pill .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 9\n",
      "input_captions: ['pill .', 'pill .', 'package of fresh cut fruit .', 'package of fresh cut fruit .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7427, device='cuda:0')\n",
      "tensor(1997, device='cuda:0')\n",
      "tensor(4840, device='cuda:0')\n",
      "tensor(3013, device='cuda:0')\n",
      "tensor(5909, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7427, device='cuda:0')\n",
      "tensor(1997, device='cuda:0')\n",
      "tensor(4840, device='cuda:0')\n",
      "tensor(3013, device='cuda:0')\n",
      "tensor(5909, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 66, GT Count: 63\n",
      "input_captions: ['package of fresh cut fruit .', 'package of fresh cut fruit .', 'package of fresh cut fruit .', 'milk carton .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7427, device='cuda:0')\n",
      "tensor(1997, device='cuda:0')\n",
      "tensor(4840, device='cuda:0')\n",
      "tensor(3013, device='cuda:0')\n",
      "tensor(5909, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 118, GT Count: 119\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7427, device='cuda:0')\n",
      "tensor(1997, device='cuda:0')\n",
      "tensor(4840, device='cuda:0')\n",
      "tensor(3013, device='cuda:0')\n",
      "tensor(5909, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 170, GT Count: 167\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7427, device='cuda:0')\n",
      "tensor(1997, device='cuda:0')\n",
      "tensor(4840, device='cuda:0')\n",
      "tensor(3013, device='cuda:0')\n",
      "tensor(5909, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 51, GT Count: 53\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 66\n",
      "input_captions: ['milk carton .', 'milk carton .', 'milk carton .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 108, GT Count: 110\n",
      "input_captions: ['chair .', 'chair .', 'chair .', 'chair .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 108, GT Count: 106\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 209, GT Count: 211\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 80, GT Count: 79\n",
      "input_captions: ['chair .', 'book .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3242, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 57, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 195, GT Count: 199\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['book .', 'book .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 74, GT Count: 52\n",
      "Test:  [140/161]  eta: 0:00:21    time: 0.9935  data: 0.0344  max mem: 4356\n",
      "input_captions: ['book .', 'book .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 149, GT Count: 140\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 132, GT Count: 116\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 17\n",
      "input_captions: ['shirt .', 'shirt .', 'shirt .', 'shirt .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 209, GT Count: 169\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 98, GT Count: 62\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 897, GT Count: 1231\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 36\n",
      "input_captions: ['shirt .', 'shirt .', 'shirt .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 201, GT Count: 186\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3797, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 13\n",
      "input_captions: ['ant .', 'ant .', 'ant .', 'ant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 87, GT Count: 72\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14405, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 316, GT Count: 238\n",
      "input_captions: ['horse .', 'horse .', 'horse .', 'horse .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['horse .', 'horse .', 'horse .', 'horse .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3586, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 65\n",
      "input_captions: ['bird .', 'bird .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 140, GT Count: 138\n",
      "input_captions: ['bird .', 'bird .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 161, GT Count: 144\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 60\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 26\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 89, GT Count: 83\n",
      "input_captions: ['bird .', 'bird .', 'bird .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 894, GT Count: 949\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 39\n",
      "input_captions: ['bird .', 'camel .', 'skateboard .', 'skateboard .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(19130, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 43\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 73, GT Count: 65\n",
      "Test:  [150/161]  eta: 0:00:11    time: 1.0763  data: 0.0244  max mem: 4356\n",
      "input_captions: ['skateboard .', 'skateboard .', 'skateboard .', 'pill .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 81, GT Count: 78\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 53, GT Count: 53\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17260, device='cuda:0')\n",
      "tensor(6277, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 26\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 82, GT Count: 76\n",
      "input_captions: ['pill .', 'pill .', 'pill .', 'pill .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 84, GT Count: 83\n",
      "input_captions: ['pill .', 'pill .', 'pill .', 'pill .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 62, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['pill .', 'flower pot .', 'flower .', 'flower pot .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 86, GT Count: 68\n",
      "input_captions: ['flower pot .', 'flower pot .', 'bottle cap .', 'bottle cap .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 67, GT Count: 69\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 85, GT Count: 76\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 143, GT Count: 144\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 30\n",
      "input_captions: ['bottle cap .', 'bottle cap .', 'flower pot .', 'pill .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 134, GT Count: 138\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(6178, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 278, GT Count: 274\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6546, device='cuda:0')\n",
      "tensor(8962, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 136, GT Count: 135\n",
      "input_captions: ['pill .', 'pill .', 'milk carton .', 'milk carton .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 130, GT Count: 139\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 199, GT Count: 198\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 71\n",
      "input_captions: ['milk carton .', 'pill .', 'pill .', 'pill .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6501, device='cuda:0')\n",
      "tensor(11122, device='cuda:0')\n",
      "tensor(2239, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 139, GT Count: 134\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 123, GT Count: 118\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 77, GT Count: 74\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17357, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 27\n",
      "input_captions: ['book .', 'book .', 'book .', 'book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 89, GT Count: 80\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 117, GT Count: 116\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 105, GT Count: 100\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 51, GT Count: 49\n",
      "input_captions: ['book .', 'book .', 'bird .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 86, GT Count: 83\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4743, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 44\n",
      "Test:  [160/161]  eta: 0:00:01    time: 1.0679  data: 0.0218  max mem: 4356\n",
      "Test: Total time: 0:02:44 (1.0196 s / it)\n",
      "# of Images Tested: 643\n",
      "MAE: 6.329704510108865, RMSE: 24.70604789294184\n",
      "Averaged stats: \n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.53s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.029\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.018\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=6,7 torchrun --nproc_per_node=2 main.py --output_dir ./gdino_val -c config/cfg_fsc147_val.py --eval --datasets config/datasets_fsc147_val.json --pretrain_model_path ./gdino_train/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91fddbdd-d925-40c7-8fb8-9359585658bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "world size: 2, rank: 0, local rank: 0\n",
      "world size: 2, rank: 1, local rank: 1\n",
      "{\n",
      "  \"CUDA_VISIBLE_DEVICES\": \"6,7\",\n",
      "  \"SHELL\": \"/bin/bash\",\n",
      "  \"CONDA_EXE\": \"/opt/miniconda/bin/conda\",\n",
      "  \"_CE_M\": \"\",\n",
      "  \"PWD\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced_CountGD\",\n",
      "  \"LOGNAME\": \"renaldy_fredyan\",\n",
      "  \"CONDA_PREFIX\": \"/opt/miniconda/envs/Rey1\",\n",
      "  \"JPY_SESSION_NAME\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced.ipynb\",\n",
      "  \"_\": \"/opt/miniconda/envs/Rey1/bin/torchrun\",\n",
      "  \"MOTD_SHOWN\": \"pam\",\n",
      "  \"HOME\": \"/home/renaldy_fredyan\",\n",
      "  \"LANG\": \"en_US.UTF-8\",\n",
      "  \"LS_COLORS\": \"rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:\",\n",
      "  \"FORCE_COLOR\": \"1\",\n",
      "  \"CONDA_PROMPT_MODIFIER\": \"(Rey1) \",\n",
      "  \"PYDEVD_USE_FRAME_EVAL\": \"NO\",\n",
      "  \"CLICOLOR\": \"1\",\n",
      "  \"CLICOLOR_FORCE\": \"1\",\n",
      "  \"SSH_CONNECTION\": \"140.118.155.218 49304 140.118.125.208 6809\",\n",
      "  \"JPY_PARENT_PID\": \"28228\",\n",
      "  \"LESSCLOSE\": \"/usr/bin/lesspipe %s %s\",\n",
      "  \"TERM\": \"xterm-color\",\n",
      "  \"_CE_CONDA\": \"\",\n",
      "  \"LESSOPEN\": \"| /usr/bin/lesspipe %s\",\n",
      "  \"USER\": \"renaldy_fredyan\",\n",
      "  \"GIT_PAGER\": \"cat\",\n",
      "  \"CONDA_SHLVL\": \"1\",\n",
      "  \"SHLVL\": \"1\",\n",
      "  \"PAGER\": \"cat\",\n",
      "  \"MPLBACKEND\": \"module://matplotlib_inline.backend_inline\",\n",
      "  \"CONDA_PYTHON_EXE\": \"/opt/miniconda/bin/python\",\n",
      "  \"SSH_CLIENT\": \"140.118.155.218 49304 6809\",\n",
      "  \"CONDA_DEFAULT_ENV\": \"Rey1\",\n",
      "  \"XDG_DATA_DIRS\": \"/usr/local/share:/usr/share:/var/lib/snapd/desktop\",\n",
      "  \"PATH\": \"/opt/miniconda/envs/Rey1/bin:/opt/miniconda/condabin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\",\n",
      "  \"SSH_TTY\": \"/dev/pts/0\",\n",
      "  \"OMP_NUM_THREADS\": \"1\",\n",
      "  \"LOCAL_RANK\": \"0\",\n",
      "  \"RANK\": \"0\",\n",
      "  \"GROUP_RANK\": \"0\",\n",
      "  \"ROLE_RANK\": \"0\",\n",
      "  \"ROLE_NAME\": \"default\",\n",
      "  \"LOCAL_WORLD_SIZE\": \"2\",\n",
      "  \"WORLD_SIZE\": \"2\",\n",
      "  \"GROUP_WORLD_SIZE\": \"1\",\n",
      "  \"ROLE_WORLD_SIZE\": \"2\",\n",
      "  \"MASTER_ADDR\": \"127.0.0.1\",\n",
      "  \"MASTER_PORT\": \"29500\",\n",
      "  \"TORCHELASTIC_RESTART_COUNT\": \"0\",\n",
      "  \"TORCHELASTIC_MAX_RESTARTS\": \"0\",\n",
      "  \"TORCHELASTIC_RUN_ID\": \"none\",\n",
      "  \"TORCHELASTIC_USE_AGENT_STORE\": \"True\",\n",
      "  \"NCCL_ASYNC_ERROR_HANDLING\": \"1\",\n",
      "  \"TORCHELASTIC_ERROR_FILE\": \"/tmp/torchelastic_3emuv5af/none_wn0j7xt0/attempt_0/0/error.json\",\n",
      "  \"QT_QPA_PLATFORM_PLUGIN_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/plugins\",\n",
      "  \"QT_QPA_FONTDIR\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/fonts\",\n",
      "  \"LD_LIBRARY_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/../../lib64:\"\n",
      "}\n",
      "{\n",
      "  \"CUDA_VISIBLE_DEVICES\": \"6,7\",\n",
      "  \"SHELL\": \"/bin/bash\",\n",
      "  \"CONDA_EXE\": \"/opt/miniconda/bin/conda\",\n",
      "  \"_CE_M\": \"\",\n",
      "  \"PWD\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced_CountGD\",\n",
      "  \"LOGNAME\": \"renaldy_fredyan\",\n",
      "  \"CONDA_PREFIX\": \"/opt/miniconda/envs/Rey1\",\n",
      "  \"JPY_SESSION_NAME\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced.ipynb\",\n",
      "  \"_\": \"/opt/miniconda/envs/Rey1/bin/torchrun\",\n",
      "  \"MOTD_SHOWN\": \"pam\",\n",
      "  \"HOME\": \"/home/renaldy_fredyan\",\n",
      "  \"LANG\": \"en_US.UTF-8\",\n",
      "  \"LS_COLORS\": \"rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:\",\n",
      "  \"FORCE_COLOR\": \"1\",\n",
      "  \"CONDA_PROMPT_MODIFIER\": \"(Rey1) \",\n",
      "  \"PYDEVD_USE_FRAME_EVAL\": \"NO\",\n",
      "  \"CLICOLOR\": \"1\",\n",
      "  \"CLICOLOR_FORCE\": \"1\",\n",
      "  \"SSH_CONNECTION\": \"140.118.155.218 49304 140.118.125.208 6809\",\n",
      "  \"JPY_PARENT_PID\": \"28228\",\n",
      "  \"LESSCLOSE\": \"/usr/bin/lesspipe %s %s\",\n",
      "  \"TERM\": \"xterm-color\",\n",
      "  \"_CE_CONDA\": \"\",\n",
      "  \"LESSOPEN\": \"| /usr/bin/lesspipe %s\",\n",
      "  \"USER\": \"renaldy_fredyan\",\n",
      "  \"GIT_PAGER\": \"cat\",\n",
      "  \"CONDA_SHLVL\": \"1\",\n",
      "  \"SHLVL\": \"1\",\n",
      "  \"PAGER\": \"cat\",\n",
      "  \"MPLBACKEND\": \"module://matplotlib_inline.backend_inline\",\n",
      "  \"CONDA_PYTHON_EXE\": \"/opt/miniconda/bin/python\",\n",
      "  \"SSH_CLIENT\": \"140.118.155.218 49304 6809\",\n",
      "  \"CONDA_DEFAULT_ENV\": \"Rey1\",\n",
      "  \"XDG_DATA_DIRS\": \"/usr/local/share:/usr/share:/var/lib/snapd/desktop\",\n",
      "  \"PATH\": \"/opt/miniconda/envs/Rey1/bin:/opt/miniconda/condabin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\",\n",
      "  \"SSH_TTY\": \"/dev/pts/0\",\n",
      "  \"OMP_NUM_THREADS\": \"1\",\n",
      "  \"LOCAL_RANK\": \"1\",\n",
      "  \"RANK\": \"1\",\n",
      "  \"GROUP_RANK\": \"0\",\n",
      "  \"ROLE_RANK\": \"1\",\n",
      "  \"ROLE_NAME\": \"default\",\n",
      "  \"LOCAL_WORLD_SIZE\": \"2\",\n",
      "  \"WORLD_SIZE\": \"2\",\n",
      "  \"GROUP_WORLD_SIZE\": \"1\",\n",
      "  \"ROLE_WORLD_SIZE\": \"2\",\n",
      "  \"MASTER_ADDR\": \"127.0.0.1\",\n",
      "  \"MASTER_PORT\": \"29500\",\n",
      "  \"TORCHELASTIC_RESTART_COUNT\": \"0\",\n",
      "  \"TORCHELASTIC_MAX_RESTARTS\": \"0\",\n",
      "  \"TORCHELASTIC_RUN_ID\": \"none\",\n",
      "  \"TORCHELASTIC_USE_AGENT_STORE\": \"True\",\n",
      "  \"NCCL_ASYNC_ERROR_HANDLING\": \"1\",\n",
      "  \"TORCHELASTIC_ERROR_FILE\": \"/tmp/torchelastic_3emuv5af/none_wn0j7xt0/attempt_0/1/error.json\",\n",
      "  \"QT_QPA_PLATFORM_PLUGIN_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/plugins\",\n",
      "  \"QT_QPA_FONTDIR\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/fonts\",\n",
      "  \"LD_LIBRARY_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/../../lib64:\"\n",
      "}\n",
      "  == distributed init (rank 1) done.\n",
      "  == distributed init (rank 0) done.\n",
      "Loading config file from config/cfg_fsc147_test.py\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 14:31:16,534 | \u001b[34mgit:\n",
      "  sha: d3d2539b1c084bb62ba04308a2ace9b4476442ea, status: has uncommited changes, branch: main\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 14:31:16,536 | \u001b[34mCommand: main.py --output_dir ./gdino_test -c config/cfg_fsc147_test.py --eval --datasets config/datasets_fsc147_test.json --pretrain_model_path ./gdino_train/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 14:31:16,538 | \u001b[34mFull config saved to ./gdino_test/config_args_all.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 14:31:16,539 | \u001b[34mworld size: 2\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 14:31:16,540 | \u001b[34mrank: 0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 14:31:16,540 | \u001b[34mlocal_rank: 0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 14:31:16,541 | \u001b[34margs: Namespace(config_file='config/cfg_fsc147_test.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='config/datasets_fsc147_test.json', remove_difficult=False, fix_size=False, output_dir='./gdino_test', note='', device='cuda', seed=42, resume='', pretrain_model_path='./gdino_train/checkpoint_best_regular.pth', finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=2, dist_url='env://', rank=0, local_rank=0, amp=False, gpu=0, distributed=True, dist_backend='nccl', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=30, lr_drop=10, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[10, 20], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=False, label_list=['alcohol bottle', 'baguette roll', 'ball', 'banana', 'bead', 'bee', 'birthday candle', 'biscuit', 'boat', 'bottle', 'bowl', 'box', 'bread roll', 'brick', 'buffalo', 'bun', 'calamari ring', 'can', 'candle', 'cap', 'car', 'cartridge', 'cassette', 'cement bag', 'cereal', 'chewing gum piece', 'chopstick', 'clam', 'coffee bean', 'coin', 'cotton ball', 'cow', 'crane', 'crayon', 'croissant', 'crow', 'cup', 'cupcake', 'cupcake holder', 'fish', 'gemstone', 'go game piece', 'goat', 'goldfish snack', 'goose', 'ice cream', 'ice cream cone', 'instant noodle', 'jade stone', 'jeans', 'kidney bean', 'kitchen towel', 'lighter', 'lipstick', 'm&m piece', 'macaron', 'match', 'meat skewer', 'mini blind', 'mosaic tile', 'naan bread', 'nail', 'nut', 'onion ring', 'orange', 'pearl', 'pen', 'pencil', 'penguin', 'pepper', 'person', 'pigeon', 'plate', 'polka dot tile', 'potato', 'rice bag', 'roof tile', 'screw', 'shoe', 'spoon', 'spring roll', 'stair', 'stapler pin', 'straw', 'supermarket shelf', 'swan', 'tomato', 'watermelon', 'window', 'zebra'], val_label_list=['apple', 'candy piece', 'carrom board piece', 'cashew nut', 'comic book', 'crab cake', 'deer', 'egg', 'elephant', 'finger food', 'green pea', 'hot air balloon', 'keyboard key', 'lego', 'marble', 'marker', 'nail polish', 'potato chip', 'red bean', 'round dessert', 'sauce bottle', 'sea shell', 'sheep', 'ski', 'stamp', 'sticky note', 'strawberry', 'sunglasses', 'tree log', 'watch', 'yellow lego stud'])\n",
      "\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-13 14:31:16,543 | \u001b[34mbuild model ... ...\u001b[0m\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755849709/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755849709/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "final text_encoder_type: checkpoints/bert-base-uncased\n",
      "load tokenizer done.\n",
      "final text_encoder_type: checkpoints/bert-base-uncased\n",
      "load tokenizer done.\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-13 14:31:20,222 | \u001b[34mbuild model, done.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 14:31:20,323 | \u001b[34mnumber of params:236717952\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 14:31:20,330 | \u001b[34mparams before freezing:\n",
      "{\n",
      "  \"module.transformer.level_embed\": 1024,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.norm.weight\": 256,\n",
      "  \"module.transformer.decoder.norm.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
      "  \"module.transformer.tgt_embed.weight\": 230400,\n",
      "  \"module.transformer.enc_output.weight\": 65536,\n",
      "  \"module.transformer.enc_output.bias\": 256,\n",
      "  \"module.transformer.enc_output_norm.weight\": 256,\n",
      "  \"module.transformer.enc_output_norm.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
      "  \"module.feature_map_proj.weight\": 458752,\n",
      "  \"module.feature_map_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.norm.weight\": 256,\n",
      "  \"module.feature_map_encoder.norm.bias\": 256,\n",
      "  \"module.bert.embeddings.word_embeddings.weight\": 23440896,\n",
      "  \"module.bert.embeddings.position_embeddings.weight\": 393216,\n",
      "  \"module.bert.embeddings.token_type_embeddings.weight\": 1536,\n",
      "  \"module.bert.embeddings.LayerNorm.weight\": 768,\n",
      "  \"module.bert.embeddings.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.0.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.0.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.0.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.0.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.1.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.1.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.1.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.1.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.2.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.2.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.2.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.2.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.3.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.3.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.3.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.3.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.4.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.4.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.4.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.4.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.5.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.5.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.5.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.5.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.6.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.6.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.6.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.6.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.7.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.7.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.7.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.7.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.8.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.8.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.8.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.8.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.9.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.9.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.9.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.9.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.10.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.10.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.10.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.10.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.11.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.11.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.11.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.11.output.LayerNorm.bias\": 768,\n",
      "  \"module.feat_map.weight\": 196608,\n",
      "  \"module.feat_map.bias\": 256,\n",
      "  \"module.input_proj.0.0.weight\": 65536,\n",
      "  \"module.input_proj.0.0.bias\": 256,\n",
      "  \"module.input_proj.0.1.weight\": 256,\n",
      "  \"module.input_proj.0.1.bias\": 256,\n",
      "  \"module.input_proj.1.0.weight\": 131072,\n",
      "  \"module.input_proj.1.0.bias\": 256,\n",
      "  \"module.input_proj.1.1.weight\": 256,\n",
      "  \"module.input_proj.1.1.bias\": 256,\n",
      "  \"module.input_proj.2.0.weight\": 262144,\n",
      "  \"module.input_proj.2.0.bias\": 256,\n",
      "  \"module.input_proj.2.1.weight\": 256,\n",
      "  \"module.input_proj.2.1.bias\": 256,\n",
      "  \"module.input_proj.3.0.weight\": 2359296,\n",
      "  \"module.input_proj.3.0.bias\": 256,\n",
      "  \"module.input_proj.3.1.weight\": 256,\n",
      "  \"module.input_proj.3.1.bias\": 256,\n",
      "  \"module.backbone.0.patch_embed.proj.weight\": 6144,\n",
      "  \"module.backbone.0.patch_embed.proj.bias\": 128,\n",
      "  \"module.backbone.0.patch_embed.norm.weight\": 128,\n",
      "  \"module.backbone.0.patch_embed.norm.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm1.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm1.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table\": 2116,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.qkv.weight\": 49152,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.qkv.bias\": 384,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.proj.weight\": 16384,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.proj.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm2.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc1.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc1.bias\": 512,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc2.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm1.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm1.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table\": 2116,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.qkv.weight\": 49152,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.qkv.bias\": 384,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.proj.weight\": 16384,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.proj.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm2.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc1.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc1.bias\": 512,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc2.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.downsample.reduction.weight\": 131072,\n",
      "  \"module.backbone.0.layers.0.downsample.norm.weight\": 512,\n",
      "  \"module.backbone.0.layers.0.downsample.norm.bias\": 512,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm1.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm1.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table\": 4232,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.qkv.weight\": 196608,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.qkv.bias\": 768,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.proj.weight\": 65536,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.proj.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm2.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc1.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc2.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm1.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm1.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table\": 4232,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.qkv.weight\": 196608,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.qkv.bias\": 768,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.proj.weight\": 65536,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.proj.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm2.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc1.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc2.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.downsample.reduction.weight\": 524288,\n",
      "  \"module.backbone.0.layers.1.downsample.norm.weight\": 1024,\n",
      "  \"module.backbone.0.layers.1.downsample.norm.bias\": 1024,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.downsample.reduction.weight\": 2097152,\n",
      "  \"module.backbone.0.layers.2.downsample.norm.weight\": 2048,\n",
      "  \"module.backbone.0.layers.2.downsample.norm.bias\": 2048,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm1.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table\": 16928,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.qkv.weight\": 3145728,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.qkv.bias\": 3072,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.proj.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.proj.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm2.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc1.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc1.bias\": 4096,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc2.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm1.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table\": 16928,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.qkv.weight\": 3145728,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.qkv.bias\": 3072,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.proj.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.proj.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm2.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc1.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc1.bias\": 4096,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc2.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc2.bias\": 1024,\n",
      "  \"module.backbone.0.norm1.weight\": 256,\n",
      "  \"module.backbone.0.norm1.bias\": 256,\n",
      "  \"module.backbone.0.norm2.weight\": 512,\n",
      "  \"module.backbone.0.norm2.bias\": 512,\n",
      "  \"module.backbone.0.norm3.weight\": 1024,\n",
      "  \"module.backbone.0.norm3.bias\": 1024\n",
      "}\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 14:31:20,359 | \u001b[34mparams after freezing:\n",
      "{\n",
      "  \"module.transformer.level_embed\": 1024,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.norm.weight\": 256,\n",
      "  \"module.transformer.decoder.norm.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
      "  \"module.transformer.tgt_embed.weight\": 230400,\n",
      "  \"module.transformer.enc_output.weight\": 65536,\n",
      "  \"module.transformer.enc_output.bias\": 256,\n",
      "  \"module.transformer.enc_output_norm.weight\": 256,\n",
      "  \"module.transformer.enc_output_norm.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
      "  \"module.feature_map_proj.weight\": 458752,\n",
      "  \"module.feature_map_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.0.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.1.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.feature_map_encoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear1.bias\": 2048,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.weight\": 524288,\n",
      "  \"module.feature_map_encoder.layers.2.mlp.linear2.bias\": 256,\n",
      "  \"module.feature_map_encoder.norm.weight\": 256,\n",
      "  \"module.feature_map_encoder.norm.bias\": 256,\n",
      "  \"module.feat_map.weight\": 196608,\n",
      "  \"module.feat_map.bias\": 256,\n",
      "  \"module.input_proj.0.0.weight\": 65536,\n",
      "  \"module.input_proj.0.0.bias\": 256,\n",
      "  \"module.input_proj.0.1.weight\": 256,\n",
      "  \"module.input_proj.0.1.bias\": 256,\n",
      "  \"module.input_proj.1.0.weight\": 131072,\n",
      "  \"module.input_proj.1.0.bias\": 256,\n",
      "  \"module.input_proj.1.1.weight\": 256,\n",
      "  \"module.input_proj.1.1.bias\": 256,\n",
      "  \"module.input_proj.2.0.weight\": 262144,\n",
      "  \"module.input_proj.2.0.bias\": 256,\n",
      "  \"module.input_proj.2.1.weight\": 256,\n",
      "  \"module.input_proj.2.1.bias\": 256,\n",
      "  \"module.input_proj.3.0.weight\": 2359296,\n",
      "  \"module.input_proj.3.0.bias\": 256,\n",
      "  \"module.input_proj.3.1.weight\": 256,\n",
      "  \"module.input_proj.3.1.bias\": 256\n",
      "}\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-13 14:31:20,364 | \u001b[34mbuild dataset ... ...\u001b[0m\n",
      "/home/renaldy_fredyan/PhDResearch/LOCA/Dataset/images_384_VarV2 ./data/fsc147_gdino/fsc147_coco/coco_test_exemplars.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.45s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 14:31:21,618 | \u001b[34mIgnore keys: []\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-13 14:31:22,234 | \u001b[34m<All keys matched successfully>\u001b[0m\n",
      "Input text prompt: apple . candy piece . carrom board piece . cashew nut . comic book . crab cake . deer . egg . elephant . finger food . green pea . hot air balloon . keyboard key . lego . marble . marker . nail polish . potato chip . red bean . round dessert . sauce bottle . sea shell . sheep . ski . stamp . sticky note . strawberry . sunglasses . tree log . watch . yellow lego stud .\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "input_captions: ['sea shell .', 'hot air balloon .', 'hot air balloon .', 'strawberry .']\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/transformers/modeling_utils.py:812: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/transformers/modeling_utils.py:812: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "Test:  [  0/149]  eta: 0:17:53    time: 7.2027  data: 5.5606  max mem: 4327\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 26\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 126, GT Count: 124\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 20\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 100, GT Count: 113\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 55\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 39\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 63\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 43\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['strawberry .', 'strawberry .', 'stamp .', 'watch .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 14\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 66, GT Count: 63\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 94, GT Count: 80\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 53, GT Count: 52\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 77, GT Count: 60\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 46\n",
      "Test:  [ 10/149]  eta: 0:03:46    time: 1.6295  data: 0.5412  max mem: 4356\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 102, GT Count: 100\n",
      "input_captions: ['apple .', 'apple .', 'comic book .', 'comic book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 198, GT Count: 182\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 29\n",
      "input_captions: ['comic book .', 'watch .', 'watch .', 'watch .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 81, GT Count: 53\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 69, GT Count: 69\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 104, GT Count: 93\n",
      "input_captions: ['watch .', 'watch .', 'sheep .', 'sheep .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 133, GT Count: 136\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 22\n",
      "input_captions: ['marker .', 'keyboard key .', 'keyboard key .', 'keyboard key .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 896, GT Count: 3701\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 64, GT Count: 63\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 177, GT Count: 162\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 428, GT Count: 409\n",
      "input_captions: ['keyboard key .', 'keyboard key .', 'keyboard key .', 'carrom board piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 59\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 50\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 25\n",
      "input_captions: ['elephant .', 'elephant .', 'elephant .', 'elephant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'sunglasses .', 'sunglasses .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 409, GT Count: 226\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 156, GT Count: 108\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 375, GT Count: 198\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 146, GT Count: 79\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'sunglasses .', 'sunglasses .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 129, GT Count: 49\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 142, GT Count: 104\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 14\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'sunglasses .', 'sunglasses .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 29\n",
      "Test:  [ 20/149]  eta: 0:02:55    time: 1.0695  data: 0.0334  max mem: 4356\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'sunglasses .', 'sunglasses .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 168, GT Count: 134\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 133, GT Count: 81\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'sunglasses .', 'sunglasses .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 176, GT Count: 88\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 125, GT Count: 90\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 30\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'sunglasses .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 145, GT Count: 79\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 111, GT Count: 63\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 56, GT Count: 61\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 119, GT Count: 116\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 34\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 107, GT Count: 119\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 148, GT Count: 147\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 102, GT Count: 86\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 73\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 231, GT Count: 223\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 39\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 32\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 102, GT Count: 99\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 51, GT Count: 49\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 55\n",
      "Test:  [ 30/149]  eta: 0:02:37    time: 1.1588  data: 0.0356  max mem: 4357\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 27, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 483, GT Count: 356\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 64, GT Count: 47\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 93, GT Count: 111\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 82, GT Count: 64\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 20\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 37\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 53, GT Count: 53\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 227, GT Count: 174\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 157, GT Count: 174\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 11\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 155, GT Count: 165\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 49\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 186, GT Count: 157\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 48\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 226, GT Count: 195\n",
      "input_captions: ['deer .', 'deer .', 'deer .', 'deer .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 41\n",
      "input_captions: ['stamp .', 'stamp .', 'stamp .', 'stamp .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 61\n",
      "input_captions: ['stamp .', 'stamp .', 'stamp .', 'stamp .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 54\n",
      "Test:  [ 40/149]  eta: 0:02:24    time: 1.2857  data: 0.0409  max mem: 4357\n",
      "input_captions: ['stamp .', 'stamp .', 'stamp .', 'stamp .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 60\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['stamp .', 'stamp .', 'stamp .', 'stamp .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 56\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['stamp .', 'stamp .', 'stamp .', 'stamp .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 29\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['stamp .', 'stamp .', 'stamp .', 'crab cake .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 67, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18081, device='cuda:0')\n",
      "tensor(9850, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 10\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 76, GT Count: 58\n",
      "input_captions: ['finger food .', 'finger food .', 'finger food .', 'finger food .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['finger food .', 'finger food .', 'finger food .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 182, GT Count: 153\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 129, GT Count: 136\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 98, GT Count: 92\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 43\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 83, GT Count: 68\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 49\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 121, GT Count: 122\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 104, GT Count: 99\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 65, GT Count: 57\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 88, GT Count: 66\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 151, GT Count: 146\n",
      "Test:  [ 50/149]  eta: 0:02:04    time: 1.1434  data: 0.0420  max mem: 4357\n",
      "input_captions: ['green pea .', 'green pea .', 'sea shell .', 'crab cake .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 88, GT Count: 72\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 275, GT Count: 258\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2712, device='cuda:0')\n",
      "tensor(5806, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(18081, device='cuda:0')\n",
      "tensor(9850, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['red bean .', 'red bean .', 'red bean .', 'red bean .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2417, device='cuda:0')\n",
      "tensor(14068, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 38, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2417, device='cuda:0')\n",
      "tensor(14068, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 106, GT Count: 103\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2417, device='cuda:0')\n",
      "tensor(14068, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 101, GT Count: 96\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2417, device='cuda:0')\n",
      "tensor(14068, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['red bean .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2417, device='cuda:0')\n",
      "tensor(14068, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 73, GT Count: 70\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 35\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 24\n",
      "input_captions: ['cashew nut .', 'candy piece .', 'round dessert .', 'candy piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2461, device='cuda:0')\n",
      "tensor(18064, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9485, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 115, GT Count: 111\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'marble .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 295, GT Count: 275\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 150, GT Count: 119\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'marble .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 78, GT Count: 76\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 58\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'marble .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 54, GT Count: 54\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 91, GT Count: 94\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 89, GT Count: 86\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 120, GT Count: 118\n",
      "input_captions: ['marble .', 'finger food .', 'finger food .', 'finger food .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 59\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 37\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 8\n",
      "input_captions: ['finger food .', 'finger food .', 'finger food .', 'potato chip .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14557, device='cuda:0')\n",
      "tensor(9090, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 34\n",
      "Test:  [ 60/149]  eta: 0:01:48    time: 1.0085  data: 0.0455  max mem: 4357\n",
      "input_captions: ['potato chip .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(14557, device='cuda:0')\n",
      "tensor(9090, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 79, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 116, GT Count: 115\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 27\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 43\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 328, GT Count: 323\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 208, GT Count: 221\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 32\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 51, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 210, GT Count: 191\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 82, GT Count: 77\n",
      "input_captions: ['hot air balloon .', 'hot air balloon .', 'hot air balloon .', 'hot air balloon .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['hot air balloon .', 'hot air balloon .', 'hot air balloon .', 'hot air balloon .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2980, device='cuda:0')\n",
      "tensor(2250, device='cuda:0')\n",
      "tensor(13212, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['ski .', 'ski .', 'ski .', 'ski .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8301, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8301, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8301, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8301, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 10\n",
      "input_captions: ['ski .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8301, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 71, GT Count: 68\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 133, GT Count: 126\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 28\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 93, GT Count: 101\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 37\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 69, GT Count: 64\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 50\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 88, GT Count: 83\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "Test:  [ 70/149]  eta: 0:01:33    time: 1.0088  data: 0.0394  max mem: 4357\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 79, GT Count: 78\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 99, GT Count: 91\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 91, GT Count: 95\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 62, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 71, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 74\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'tree log .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 57, GT Count: 56\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['tree log .', 'tree log .', 'tree log .', 'tree log .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 177, GT Count: 175\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 222, GT Count: 205\n",
      "input_captions: ['tree log .', 'tree log .', 'tree log .', 'tree log .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 113, GT Count: 95\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 175, GT Count: 166\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 56, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 146, GT Count: 145\n",
      "input_captions: ['tree log .', 'tree log .', 'tree log .', 'tree log .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 117, GT Count: 93\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 402, GT Count: 363\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 223, GT Count: 218\n",
      "input_captions: ['tree log .', 'tree log .', 'tree log .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3392, device='cuda:0')\n",
      "tensor(8833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 44\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 194, GT Count: 193\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'marble .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 79, GT Count: 87\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 111, GT Count: 111\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'marble .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "Test:  [ 80/149]  eta: 0:01:20    time: 0.9749  data: 0.0342  max mem: 4357\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'finger food .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 151, GT Count: 150\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 26\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['finger food .', 'finger food .', 'finger food .', 'finger food .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['finger food .', 'finger food .', 'finger food .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 8, GT Count: 8\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 139, GT Count: 131\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 140, GT Count: 131\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 111, GT Count: 89\n",
      "input_captions: ['green pea .', 'green pea .', 'green pea .', 'green pea .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 269, GT Count: 262\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 144, GT Count: 155\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(2665, device='cuda:0')\n",
      "tensor(26034, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 90, GT Count: 89\n",
      "input_captions: ['finger food .', 'finger food .', 'finger food .', 'finger food .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(4344, device='cuda:0')\n",
      "tensor(2833, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'marble .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 102, GT Count: 90\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 70, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'marble .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 51, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'marble .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 94, GT Count: 93\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 40\n",
      "input_captions: ['marble .', 'marble .', 'marble .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 157, GT Count: 149\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(7720, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 21\n",
      "Test:  [ 90/149]  eta: 0:01:07    time: 0.9873  data: 0.0396  max mem: 4357\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 77, GT Count: 71\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['cashew nut .', 'cashew nut .', 'cashew nut .', 'cashew nut .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 14\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 43\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5356, device='cuda:0')\n",
      "tensor(7974, device='cuda:0')\n",
      "tensor(17490, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 64, GT Count: 53\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 95, GT Count: 90\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 53, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 102, GT Count: 101\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 56\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 132, GT Count: 128\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 24\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 130, GT Count: 122\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 99, GT Count: 113\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 113, GT Count: 111\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 52\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 65, GT Count: 75\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['strawberry .', 'strawberry .', 'strawberry .', 'strawberry .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 9, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(16876, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 79, GT Count: 78\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 53, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 35\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 66, GT Count: 58\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 14, GT Count: 14\n",
      "Test:  [100/149]  eta: 0:00:55    time: 1.0115  data: 0.0467  max mem: 4357\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 18, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 31\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'keyboard key .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 102, GT Count: 102\n",
      "input_captions: ['keyboard key .', 'keyboard key .', 'keyboard key .', 'keyboard key .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 188, GT Count: 185\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 94, GT Count: 82\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 86, GT Count: 84\n",
      "input_captions: ['keyboard key .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 109, GT Count: 108\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 90, GT Count: 73\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 43, GT Count: 39\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 84, GT Count: 82\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 50, GT Count: 42\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 90, GT Count: 89\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 67, GT Count: 76\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 80, GT Count: 74\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 99, GT Count: 92\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 133, GT Count: 118\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 10\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 36\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 71, GT Count: 66\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 94, GT Count: 89\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'marker .', 'marker .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 134, GT Count: 72\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 36\n",
      "Test:  [110/149]  eta: 0:00:44    time: 1.1160  data: 0.0484  max mem: 4357\n",
      "input_captions: ['marker .', 'marker .', 'marker .', 'marker .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 208, GT Count: 199\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 100, GT Count: 108\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 314, GT Count: 309\n",
      "input_captions: ['marker .', 'marker .', 'marker .', 'marker .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 233, GT Count: 240\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 126, GT Count: 123\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 10, GT Count: 9\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 368, GT Count: 371\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 36\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 62, GT Count: 52\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 308, GT Count: 289\n",
      "input_captions: ['apple .', 'apple .', 'apple .', 'sauce bottle .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 75, GT Count: 70\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 75, GT Count: 81\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 23, GT Count: 17\n",
      "input_captions: ['sauce bottle .', 'sauce bottle .', 'sauce bottle .', 'sauce bottle .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 48\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 42, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 49, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 34\n",
      "input_captions: ['sauce bottle .', 'sauce bottle .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 67, GT Count: 68\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12901, device='cuda:0')\n",
      "tensor(5835, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 26\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 49\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 15, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 93, GT Count: 89\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 77, GT Count: 58\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 24\n",
      "input_captions: ['egg .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 11, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 123, GT Count: 113\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 76, GT Count: 68\n",
      "input_captions: ['egg .', 'egg .', 'stamp .', 'stamp .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 12, GT Count: 12\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 60\n",
      "Test:  [120/149]  eta: 0:00:32    time: 1.1598  data: 0.0440  max mem: 4357\n",
      "input_captions: ['stamp .', 'stamp .', 'stamp .', 'stamp .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 54\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 46, GT Count: 43\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 55, GT Count: 55\n",
      "input_captions: ['stamp .', 'stamp .', 'marker .', 'marker .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(11359, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 76, GT Count: 73\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 298, GT Count: 292\n",
      "input_captions: ['marker .', 'comic book .', 'comic book .', 'comic book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 388, GT Count: 370\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 71, GT Count: 70\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['comic book .', 'comic book .', 'comic book .', 'comic book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 26, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 45\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 63, GT Count: 65\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 60, GT Count: 60\n",
      "input_captions: ['comic book .', 'comic book .', 'comic book .', 'sticky note .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 40, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 37, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 102, GT Count: 113\n",
      "input_captions: ['sticky note .', 'sticky note .', 'sticky note .', 'sticky note .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 58, GT Count: 60\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 116, GT Count: 121\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 75, GT Count: 75\n",
      "input_captions: ['sticky note .', 'nail polish .', 'nail polish .', 'nail polish .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(15875, device='cuda:0')\n",
      "tensor(3602, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 94, GT Count: 94\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 24\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 340, GT Count: 272\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 44, GT Count: 44\n",
      "input_captions: ['nail polish .', 'nail polish .', 'nail polish .', 'nail polish .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 161, GT Count: 158\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 68, GT Count: 60\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 133, GT Count: 146\n",
      "input_captions: ['nail polish .', 'nail polish .', 'nail polish .', 'sunglasses .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 34\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 559, GT Count: 508\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 210, GT Count: 141\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'sunglasses .', 'sunglasses .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 196, GT Count: 90\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 166, GT Count: 90\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 87, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 144, GT Count: 73\n",
      "Test:  [130/149]  eta: 0:00:21    time: 1.0762  data: 0.0561  max mem: 4357\n",
      "input_captions: ['watch .', 'watch .', 'watch .', 'sheep .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 67, GT Count: 67\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 30\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(3422, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 32, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 45, GT Count: 44\n",
      "input_captions: ['sheep .', 'sheep .', 'sheep .', 'sheep .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 137, GT Count: 128\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 31, GT Count: 31\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 91, GT Count: 122\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 178, GT Count: 180\n",
      "input_captions: ['sheep .', 'sheep .', 'sheep .', 'sheep .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 80, GT Count: 81\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 52, GT Count: 51\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 211, GT Count: 209\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 77, GT Count: 75\n",
      "input_captions: ['deer .', 'deer .', 'deer .', 'deer .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 20, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 16\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 17, GT Count: 15\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 80, GT Count: 77\n",
      "input_captions: ['deer .', 'elephant .', 'elephant .', 'elephant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8448, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 20\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 29, GT Count: 27\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['elephant .', 'elephant .', 'elephant .', 'elephant .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 13, GT Count: 13\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 23\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 38\n",
      "input_captions: ['elephant .', 'elephant .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 16, GT Count: 11\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(10777, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 24, GT Count: 21\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 358, GT Count: 384\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 492, GT Count: 512\n",
      "input_captions: ['lego .', 'lego .', 'lego .', 'carrom board piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 98, GT Count: 96\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 30, GT Count: 32\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 101, GT Count: 100\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 19\n",
      "input_captions: ['carrom board piece .', 'carrom board piece .', 'carrom board piece .', 'keyboard key .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 21, GT Count: 18\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 87, GT Count: 87\n",
      "input_captions: ['keyboard key .', 'keyboard key .', 'keyboard key .', 'keyboard key .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 87, GT Count: 84\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 105, GT Count: 104\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 79, GT Count: 79\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 103, GT Count: 104\n",
      "Test:  [140/149]  eta: 0:00:10    time: 1.0284  data: 0.0577  max mem: 4357\n",
      "input_captions: ['sunglasses .', 'sunglasses .', 'comic book .', 'marker .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 69, GT Count: 40\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(17072, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 112, GT Count: 64\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 48, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 254, GT Count: 233\n",
      "input_captions: ['marker .', 'marker .', 'carrom board piece .', 'carrom board piece .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 220, GT Count: 217\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12115, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 125, GT Count: 110\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 19\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(12385, device='cuda:0')\n",
      "tensor(5358, device='cuda:0')\n",
      "tensor(2604, device='cuda:0')\n",
      "tensor(3538, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 34, GT Count: 24\n",
      "input_captions: ['apple .', 'apple .', 'lego .', 'lego .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 41, GT Count: 41\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 166, GT Count: 159\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 189, GT Count: 36\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(23853, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 900, GT Count: 2560\n",
      "input_captions: ['keyboard key .', 'keyboard key .', 'apple .', 'apple .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 108, GT Count: 108\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(9019, device='cuda:0')\n",
      "tensor(3145, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 111, GT Count: 124\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 92, GT Count: 92\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['apple .', 'egg .', 'egg .', 'egg .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(6207, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 22, GT Count: 22\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 46\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 47, GT Count: 47\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 28, GT Count: 28\n",
      "input_captions: ['egg .', 'egg .', 'comic book .', 'comic book .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 35\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8288, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 39, GT Count: 38\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 25, GT Count: 25\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 36, GT Count: 33\n",
      "input_captions: ['comic book .', 'nail polish .', 'nail polish .', 'nail polish .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(5021, device='cuda:0')\n",
      "tensor(2338, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 142, GT Count: 143\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 105, GT Count: 103\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 214, GT Count: 211\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 33, GT Count: 33\n",
      "input_captions: ['nail polish .', 'sheep .', 'sheep .']\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(13774, device='cuda:0')\n",
      "tensor(3907, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 100, GT Count: 98\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 202, GT Count: 181\n",
      "tensor(101, device='cuda:0')\n",
      "tensor(8351, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1008, device='cuda:0')\n",
      "tensor(1012, device='cuda:0')\n",
      "Pred Count: 35, GT Count: 36\n",
      "Test:  [148/149]  eta: 0:00:01    time: 1.0438  data: 0.0441  max mem: 4357\n",
      "Test: Total time: 0:02:47 (1.1209 s / it)\n",
      "# of Images Tested: 595\n",
      "MAE: 14.502521008403361, RMSE: 134.97609498902906\n",
      "Averaged stats: \n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.73s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.053\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.050\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=6,7 torchrun --nproc_per_node=2 main.py --output_dir ./gdino_test -c config/cfg_fsc147_test.py --eval --datasets config/datasets_fsc147_test.json --pretrain_model_path ./gdino_train/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a96c5f9-81c6-4aac-b4ed-cc1d186ab239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17044a7e-c849-4a1b-b98c-af8ecf9ac273",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "world size: 1, rank: 0, local rank: 0\n",
      "{\n",
      "  \"CUDA_VISIBLE_DEVICES\": \"6\",\n",
      "  \"SHELL\": \"/bin/bash\",\n",
      "  \"CONDA_EXE\": \"/opt/miniconda/bin/conda\",\n",
      "  \"_CE_M\": \"\",\n",
      "  \"TMUX\": \"/tmp/tmux-1010/default,192425,0\",\n",
      "  \"PWD\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced_CountGD\",\n",
      "  \"LOGNAME\": \"renaldy_fredyan\",\n",
      "  \"CONDA_PREFIX\": \"/opt/miniconda/envs/Rey1\",\n",
      "  \"JPY_SESSION_NAME\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced_CountGD/Reproduced.ipynb\",\n",
      "  \"_\": \"/opt/miniconda/envs/Rey1/bin/torchrun\",\n",
      "  \"MOTD_SHOWN\": \"pam\",\n",
      "  \"HOME\": \"/home/renaldy_fredyan\",\n",
      "  \"LANG\": \"en_US.UTF-8\",\n",
      "  \"LS_COLORS\": \"rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:\",\n",
      "  \"FORCE_COLOR\": \"1\",\n",
      "  \"CONDA_PROMPT_MODIFIER\": \"(Rey1) \",\n",
      "  \"PYDEVD_USE_FRAME_EVAL\": \"NO\",\n",
      "  \"CLICOLOR\": \"1\",\n",
      "  \"CLICOLOR_FORCE\": \"1\",\n",
      "  \"SSH_CONNECTION\": \"140.118.155.218 56934 140.118.125.208 6809\",\n",
      "  \"JPY_PARENT_PID\": \"192484\",\n",
      "  \"LESSCLOSE\": \"/usr/bin/lesspipe %s %s\",\n",
      "  \"TERM\": \"xterm-color\",\n",
      "  \"_CE_CONDA\": \"\",\n",
      "  \"LESSOPEN\": \"| /usr/bin/lesspipe %s\",\n",
      "  \"USER\": \"renaldy_fredyan\",\n",
      "  \"GIT_PAGER\": \"cat\",\n",
      "  \"TMUX_PANE\": \"%0\",\n",
      "  \"CONDA_SHLVL\": \"1\",\n",
      "  \"SHLVL\": \"2\",\n",
      "  \"PAGER\": \"cat\",\n",
      "  \"MPLBACKEND\": \"module://matplotlib_inline.backend_inline\",\n",
      "  \"CONDA_PYTHON_EXE\": \"/opt/miniconda/bin/python\",\n",
      "  \"SSH_CLIENT\": \"140.118.155.218 56934 6809\",\n",
      "  \"CONDA_DEFAULT_ENV\": \"Rey1\",\n",
      "  \"XDG_DATA_DIRS\": \"/usr/local/share:/usr/share:/var/lib/snapd/desktop\",\n",
      "  \"PATH\": \"/opt/miniconda/envs/Rey1/bin:/opt/miniconda/bin:/opt/miniconda/condabin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\",\n",
      "  \"SSH_TTY\": \"/dev/pts/5\",\n",
      "  \"LOCAL_RANK\": \"0\",\n",
      "  \"RANK\": \"0\",\n",
      "  \"GROUP_RANK\": \"0\",\n",
      "  \"ROLE_RANK\": \"0\",\n",
      "  \"ROLE_NAME\": \"default\",\n",
      "  \"LOCAL_WORLD_SIZE\": \"1\",\n",
      "  \"WORLD_SIZE\": \"1\",\n",
      "  \"GROUP_WORLD_SIZE\": \"1\",\n",
      "  \"ROLE_WORLD_SIZE\": \"1\",\n",
      "  \"MASTER_ADDR\": \"127.0.0.1\",\n",
      "  \"MASTER_PORT\": \"29501\",\n",
      "  \"TORCHELASTIC_RESTART_COUNT\": \"0\",\n",
      "  \"TORCHELASTIC_MAX_RESTARTS\": \"0\",\n",
      "  \"TORCHELASTIC_RUN_ID\": \"none\",\n",
      "  \"TORCHELASTIC_USE_AGENT_STORE\": \"True\",\n",
      "  \"NCCL_ASYNC_ERROR_HANDLING\": \"1\",\n",
      "  \"TORCHELASTIC_ERROR_FILE\": \"/tmp/torchelastic_u98hj7g6/none_2hd20re2/attempt_0/0/error.json\",\n",
      "  \"QT_QPA_PLATFORM_PLUGIN_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/plugins\",\n",
      "  \"QT_QPA_FONTDIR\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/fonts\",\n",
      "  \"LD_LIBRARY_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/../../lib64:\"\n",
      "}\n",
      "  == distributed init (rank 0) done.\n",
      "Loading config file from config/cfg_fsc147_val.py\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:27:35,250 | \u001b[34mgit:\n",
      "  sha: 0b1cd46a7f8f6f4f87a35c10f1f1c9bdd733e312, status: has uncommited changes, branch: main\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:27:35,251 | \u001b[34mCommand: main_inference.py --output_dir ./gdino_val -c config/cfg_fsc147_val.py --eval --datasets config/datasets_fsc147_val.json --pretrain_model_path ./gdino_train/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased --sam_tt_norm --remove_bad_exemplar\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:27:35,254 | \u001b[34mFull config saved to ./gdino_val/config_args_all.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:27:35,255 | \u001b[34mworld size: 1\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:27:35,256 | \u001b[34mrank: 0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:27:35,256 | \u001b[34mlocal_rank: 0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:27:35,257 | \u001b[34margs: Namespace(config_file='config/cfg_fsc147_val.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='config/datasets_fsc147_val.json', no_text=False, num_exemplars=3, remove_difficult=False, fix_size=False, train_with_exemplar_only=False, output_dir='./gdino_val', note='', device='cuda', seed=42, resume='', pretrain_model_path='./gdino_train/checkpoint_best_regular.pth', finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, modality_dropout=False, sam_tt_norm=True, sam_model_path='./checkpoints/sam_vit_h_4b8939.pth', exemp_tt_norm=False, crop=False, simple_crop=False, remove_bad_exemplar=True, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, gpu=0, distributed=True, dist_backend='nccl', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=30, lr_drop=10, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[10, 20], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=False, label_list=['alcohol bottle', 'baguette roll', 'ball', 'banana', 'bead', 'bee', 'birthday candle', 'biscuit', 'boat', 'bottle', 'bowl', 'box', 'bread roll', 'brick', 'buffalo', 'bun', 'calamari ring', 'can', 'candle', 'cap', 'car', 'cartridge', 'cassette', 'cement bag', 'cereal', 'chewing gum piece', 'chopstick', 'clam', 'coffee bean', 'coin', 'cotton ball', 'cow', 'crane', 'crayon', 'croissant', 'crow', 'cup', 'cupcake', 'cupcake holder', 'fish', 'gemstone', 'go game piece', 'goat', 'goldfish snack', 'goose', 'ice cream', 'ice cream cone', 'instant noodle', 'jade stone', 'jeans', 'kidney bean', 'kitchen towel', 'lighter', 'lipstick', 'm&m piece', 'macaron', 'match', 'meat skewer', 'mini blind', 'mosaic tile', 'naan bread', 'nail', 'nut', 'onion ring', 'orange', 'pearl', 'pen', 'pencil', 'penguin', 'pepper', 'person', 'pigeon', 'plate', 'polka dot tile', 'potato', 'rice bag', 'roof tile', 'screw', 'shoe', 'spoon', 'spring roll', 'stair', 'stapler pin', 'straw', 'supermarket shelf', 'swan', 'tomato', 'watermelon', 'window', 'zebra'], val_label_list=['ant', 'bird', 'book', 'bottle cap', 'bullet', 'camel', 'chair', 'chicken wing', 'donut', 'donut holder', 'flamingo', 'flower', 'flower pot', 'grape', 'horse', 'kiwi', 'milk carton', 'oyster', 'oyster shell', 'package of fresh cut fruit', 'peach', 'pill', 'polka dot', 'prawn cracker', 'sausage', 'seagull', 'shallot', 'shirt', 'skateboard', 'toilet paper roll'])\n",
      "\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-18 16:27:35,258 | \u001b[34mbuild model ... ...\u001b[0m\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755849709/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "final text_encoder_type: checkpoints/bert-base-uncased\n",
      "load tokenizer done.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at checkpoints/bert-base-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "final text_encoder_type: checkpoints/bert-base-uncased\n",
      "load tokenizer done.\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-18 16:27:38,145 | \u001b[34mbuild model, done.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:27:38,223 | \u001b[34mnumber of params:232772224\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:27:38,229 | \u001b[34mparams before freezing:\n",
      "{\n",
      "  \"module.transformer.level_embed\": 1024,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
      ".attn.l_proj.bias\": 1024,oder.fusion_layers.0\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.norm.weight\": 256,\n",
      "  \"module.transformer.decoder.norm.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
      "  \"module.transformer.tgt_embed.weight\": 230400,\n",
      "  \"module.transformer.enc_output.weight\": 65536,\n",
      "  \"module.transformer.enc_output.bias\": 256,\n",
      "  \"module.transformer.enc_output_norm.weight\": 256,\n",
      "  \"module.transformer.enc_output_norm.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
      "  \"module.feature_map_proj.weight\": 458752,\n",
      "  \"module.feature_map_proj.bias\": 256,\n",
      "  \"module.bert.embeddings.word_embeddings.weight\": 23440896,\n",
      "  \"module.bert.embeddings.position_embeddings.weight\": 393216,\n",
      "  \"module.bert.embeddings.token_type_embeddings.weight\": 1536,\n",
      "  \"module.bert.embeddings.LayerNorm.weight\": 768,\n",
      "  \"module.bert.embeddings.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.0.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.0.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.0.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.0.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.1.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.1.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.1.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.1.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.2.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.2.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.2.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.2.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.3.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.3.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.3.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.3.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.4.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.4.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.4.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.4.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.5.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.5.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.5.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.5.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.6.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.6.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.6.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.6.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.7.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.7.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.7.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.7.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.8.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.8.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.8.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.8.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.9.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.9.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.9.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.9.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.10.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.10.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.10.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.10.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.11.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.11.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.11.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.11.output.LayerNorm.bias\": 768,\n",
      "  \"module.feat_map.weight\": 196608,\n",
      "  \"module.feat_map.bias\": 256,\n",
      "  \"module.input_proj.0.0.weight\": 65536,\n",
      "  \"module.input_proj.0.0.bias\": 256,\n",
      "  \"module.input_proj.0.1.weight\": 256,\n",
      "  \"module.input_proj.0.1.bias\": 256,\n",
      "  \"module.input_proj.1.0.weight\": 131072,\n",
      "  \"module.input_proj.1.0.bias\": 256,\n",
      "  \"module.input_proj.1.1.weight\": 256,\n",
      "  \"module.input_proj.1.1.bias\": 256,\n",
      "  \"module.input_proj.2.0.weight\": 262144,\n",
      "  \"module.input_proj.2.0.bias\": 256,\n",
      "  \"module.input_proj.2.1.weight\": 256,\n",
      "  \"module.input_proj.2.1.bias\": 256,\n",
      "  \"module.input_proj.3.0.weight\": 2359296,\n",
      "  \"module.input_proj.3.0.bias\": 256,\n",
      "  \"module.input_proj.3.1.weight\": 256,\n",
      "  \"module.input_proj.3.1.bias\": 256,\n",
      "  \"module.backbone.0.patch_embed.proj.weight\": 6144,\n",
      "  \"module.backbone.0.patch_embed.proj.bias\": 128,\n",
      "  \"module.backbone.0.patch_embed.norm.weight\": 128,\n",
      "  \"module.backbone.0.patch_embed.norm.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm1.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm1.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table\": 2116,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.qkv.weight\": 49152,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.qkv.bias\": 384,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.proj.weight\": 16384,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.proj.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm2.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc1.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc1.bias\": 512,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc2.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm1.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm1.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table\": 2116,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.qkv.weight\": 49152,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.qkv.bias\": 384,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.proj.weight\": 16384,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.proj.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm2.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc1.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc1.bias\": 512,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc2.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.downsample.reduction.weight\": 131072,\n",
      "  \"module.backbone.0.layers.0.downsample.norm.weight\": 512,\n",
      "  \"module.backbone.0.layers.0.downsample.norm.bias\": 512,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm1.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm1.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table\": 4232,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.qkv.weight\": 196608,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.qkv.bias\": 768,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.proj.weight\": 65536,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.proj.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm2.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc1.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc2.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm1.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm1.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table\": 4232,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.qkv.weight\": 196608,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.qkv.bias\": 768,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.proj.weight\": 65536,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.proj.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm2.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc1.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc2.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.downsample.reduction.weight\": 524288,\n",
      "  \"module.backbone.0.layers.1.downsample.norm.weight\": 1024,\n",
      "  \"module.backbone.0.layers.1.downsample.norm.bias\": 1024,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.downsample.reduction.weight\": 2097152,\n",
      "  \"module.backbone.0.layers.2.downsample.norm.weight\": 2048,\n",
      "  \"module.backbone.0.layers.2.downsample.norm.bias\": 2048,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm1.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table\": 16928,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.qkv.weight\": 3145728,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.qkv.bias\": 3072,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.proj.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.proj.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm2.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc1.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc1.bias\": 4096,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc2.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm1.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table\": 16928,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.qkv.weight\": 3145728,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.qkv.bias\": 3072,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.proj.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.proj.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm2.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc1.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc1.bias\": 4096,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc2.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc2.bias\": 1024,\n",
      "  \"module.backbone.0.norm1.weight\": 256,\n",
      "  \"module.backbone.0.norm1.bias\": 256,\n",
      "  \"module.backbone.0.norm2.weight\": 512,\n",
      "  \"module.backbone.0.norm2.bias\": 512,\n",
      "  \"module.backbone.0.norm3.weight\": 1024,\n",
      "  \"module.backbone.0.norm3.bias\": 1024\n",
      "}\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:27:38,258 | \u001b[34mparams after freezing:\n",
      "{\n",
      "  \"module.transformer.level_embed\": 1024,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.norm.weight\": 256,\n",
      "  \"module.transformer.decoder.norm.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
      "  \"module.transformer.tgt_embed.weight\": 230400,\n",
      "  \"module.transformer.enc_output.weight\": 65536,\n",
      "  \"module.transformer.enc_output.bias\": 256,\n",
      "  \"module.transformer.enc_output_norm.weight\": 256,\n",
      "  \"module.transformer.enc_output_norm.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
      "  \"module.feature_map_proj.weight\": 458752,\n",
      "  \"module.feature_map_proj.bias\": 256,\n",
      "  \"module.feat_map.weight\": 196608,\n",
      "  \"module.feat_map.bias\": 256,\n",
      "  \"module.input_proj.0.0.weight\": 65536,\n",
      "  \"module.input_proj.0.0.bias\": 256,\n",
      "  \"module.input_proj.0.1.weight\": 256,\n",
      "  \"module.input_proj.0.1.bias\": 256,\n",
      "  \"module.input_proj.1.0.weight\": 131072,\n",
      "  \"module.input_proj.1.0.bias\": 256,\n",
      "  \"module.input_proj.1.1.weight\": 256,\n",
      "  \"module.input_proj.1.1.bias\": 256,\n",
      "  \"module.input_proj.2.0.weight\": 262144,\n",
      "  \"module.input_proj.2.0.bias\": 256,\n",
      "  \"module.input_proj.2.1.weight\": 256,\n",
      "  \"module.input_proj.2.1.bias\": 256,\n",
      "  \"module.input_proj.3.0.weight\": 2359296,\n",
      "  \"module.input_proj.3.0.bias\": 256,\n",
      "  \"module.input_proj.3.1.weight\": 256,\n",
      "  \"module.input_proj.3.1.bias\": 256\n",
      "}\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-18 16:27:38,262 | \u001b[34mbuild dataset ... ...\u001b[0m\n",
      "/home/renaldy_fredyan/PhDResearch/LOCA/Dataset/images_384_VarV2 ./data/fsc147_gdino/fsc147_coco/coco_val_exemplars.json\n",
      "max(scales): 800\n",
      "loading annotations into memory...\n",
      "Done (t=0.78s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:27:40,029 | \u001b[34mIgnore keys: []\u001b[0m\n",
      "_ignorekeywordlist: []\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:27:40,458 | \u001b[34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['feature_map_encoder.layers.0.norm1.weight', 'feature_map_encoder.layers.0.norm1.bias', 'feature_map_encoder.layers.0.norm2.weight', 'feature_map_encoder.layers.0.norm2.bias', 'feature_map_encoder.layers.0.self_attn.in_proj_weight', 'feature_map_encoder.layers.0.self_attn.in_proj_bias', 'feature_map_encoder.layers.0.self_attn.out_proj.weight', 'feature_map_encoder.layers.0.self_attn.out_proj.bias', 'feature_map_encoder.layers.0.mlp.linear1.weight', 'feature_map_encoder.layers.0.mlp.linear1.bias', 'feature_map_encoder.layers.0.mlp.linear2.weight', 'feature_map_encoder.layers.0.mlp.linear2.bias', 'feature_map_encoder.layers.1.norm1.weight', 'feature_map_encoder.layers.1.norm1.bias', 'feature_map_encoder.layers.1.norm2.weight', 'feature_map_encoder.layers.1.norm2.bias', 'feature_map_encoder.layers.1.self_attn.in_proj_weight', 'feature_map_encoder.layers.1.self_attn.in_proj_bias', 'feature_map_encoder.layers.1.self_attn.out_proj.weight', 'feature_map_encoder.layers.1.self_attn.out_proj.bias', 'feature_map_encoder.layers.1.mlp.linear1.weight', 'feature_map_encoder.layers.1.mlp.linear1.bias', 'feature_map_encoder.layers.1.mlp.linear2.weight', 'feature_map_encoder.layers.1.mlp.linear2.bias', 'feature_map_encoder.layers.2.norm1.weight', 'feature_map_encoder.layers.2.norm1.bias', 'feature_map_encoder.layers.2.norm2.weight', 'feature_map_encoder.layers.2.norm2.bias', 'feature_map_encoder.layers.2.self_attn.in_proj_weight', 'feature_map_encoder.layers.2.self_attn.in_proj_bias', 'feature_map_encoder.layers.2.self_attn.out_proj.weight', 'feature_map_encoder.layers.2.self_attn.out_proj.bias', 'feature_map_encoder.layers.2.mlp.linear1.weight', 'feature_map_encoder.layers.2.mlp.linear1.bias', 'feature_map_encoder.layers.2.mlp.linear2.weight', 'feature_map_encoder.layers.2.mlp.linear2.bias', 'feature_map_encoder.norm.weight', 'feature_map_encoder.norm.bias', 'bert.embeddings.position_ids'])\u001b[0m\n",
      "Input text prompt: ant . bird . book . bottle cap . bullet . camel . chair . chicken wing . donut . donut holder . flamingo . flower . flower pot . grape . horse . kiwi . milk carton . oyster . oyster shell . package of fresh cut fruit . peach . pill . polka dot . prawn cracker . sausage . seagull . shallot . shirt . skateboard . toilet paper roll .\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "input_captions: ['seagull .']\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/transformers/modeling_utils.py:977: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "refining tt norm with SAM\n",
      "Pred Count: 12, GT Count: 13\n",
      "Test:  [   0/1286]  eta: 1:32:10    time: 4.3008  data: 2.5782  max mem: 7547\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 16, GT Count: 15\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 20, GT Count: 19\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 99, GT Count: 82\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['peach .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 94, GT Count: 85\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 87, GT Count: 77\n",
      "input_captions: ['peach .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 70, GT Count: 69\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 70, GT Count: 64\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 227, GT Count: 259\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 58\n",
      "new count: 21.75\n",
      "Pred Count: 21.75, GT Count: 46\n",
      "Test:  [  10/1286]  eta: 0:51:20    time: 2.4145  data: 0.2391  max mem: 7547\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 70, GT Count: 60\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 58, GT Count: 58\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 60, GT Count: 47\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 59, GT Count: 59\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 44, GT Count: 42\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 77, GT Count: 65\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 23, GT Count: 20\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 79, GT Count: 78\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 28, GT Count: 25\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 58\n",
      "new count: 34.8\n",
      "Pred Count: 34.8, GT Count: 44\n",
      "Test:  [  20/1286]  eta: 0:45:14    time: 2.0367  data: 0.0062  max mem: 7548\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 31, GT Count: 25\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 27, GT Count: 24\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 40, GT Count: 27\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 125, GT Count: 126\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 47, GT Count: 38\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 37, GT Count: 11\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 57, GT Count: 65\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 26, GT Count: 20\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 32, GT Count: 26\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 40, GT Count: 37\n",
      "Test:  [  30/1286]  eta: 0:39:51    time: 1.6237  data: 0.0080  max mem: 7548\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 38, GT Count: 35\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 44, GT Count: 33\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 25, GT Count: 12\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 57, GT Count: 55\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 35, GT Count: 30\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 59, GT Count: 48\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 46, GT Count: 45\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 56, GT Count: 50\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 79, GT Count: 69\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 23, GT Count: 22\n",
      "Test:  [  40/1286]  eta: 0:39:23    time: 1.6372  data: 0.0087  max mem: 7548\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 210, GT Count: 192\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 81, GT Count: 74\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 61, GT Count: 50\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 38, GT Count: 38\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 202, GT Count: 191\n",
      "input_captions: ['oyster .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 13, GT Count: 14\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 13, GT Count: 14\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 17, GT Count: 18\n",
      "Test:  [  50/1286]  eta: 0:40:04    time: 2.0097  data: 0.0091  max mem: 7548\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 23, GT Count: 20\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 21, GT Count: 20\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 12, GT Count: 13\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 14, GT Count: 18\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 14, GT Count: 15\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "Test:  [  60/1286]  eta: 0:36:28    time: 1.5554  data: 0.0087  max mem: 7548\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 18, GT Count: 17\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 18, GT Count: 19\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 31, GT Count: 31\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 27, GT Count: 25\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 10, GT Count: 11\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "Test:  [  70/1286]  eta: 0:34:04    time: 1.0075  data: 0.0102  max mem: 7548\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 11, GT Count: 10\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 12, GT Count: 8\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 12, GT Count: 13\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 17, GT Count: 15\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "Test:  [  80/1286]  eta: 0:32:10    time: 1.0369  data: 0.0107  max mem: 7548\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 17, GT Count: 16\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 26, GT Count: 23\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 13, GT Count: 14\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 56, GT Count: 54\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "Test:  [  90/1286]  eta: 0:30:44    time: 1.0479  data: 0.0117  max mem: 7549\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 47, GT Count: 46\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 40, GT Count: 39\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 29, GT Count: 27\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['seagull .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['seagull .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 21, GT Count: 20\n",
      "Test:  [ 100/1286]  eta: 0:29:28    time: 1.0505  data: 0.0143  max mem: 7549\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 9, GT Count: 7\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 22, GT Count: 23\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 125, GT Count: 119\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 12, GT Count: 11\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 34, GT Count: 20\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['seagull .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 16, GT Count: 12\n",
      "Test:  [ 110/1286]  eta: 0:28:25    time: 1.0341  data: 0.0134  max mem: 7549\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 24, GT Count: 34\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 15, GT Count: 14\n",
      "input_captions: ['seagull .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['ant .']\n",
      "Pred Count: 19, GT Count: 20\n",
      "input_captions: ['ant .']\n",
      "Pred Count: 18, GT Count: 14\n",
      "input_captions: ['ant .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 95\n",
      "new count: 47.5\n",
      "Pred Count: 47.5, GT Count: 44\n",
      "input_captions: ['ant .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 15\n",
      "new count: 9.0\n",
      "Pred Count: 9.0, GT Count: 9\n",
      "input_captions: ['ant .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 13, GT Count: 13\n",
      "Test:  [ 120/1286]  eta: 0:28:07    time: 1.2244  data: 0.0109  max mem: 7549\n",
      "input_captions: ['ant .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 21, GT Count: 10\n",
      "input_captions: ['ant .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 18, GT Count: 13\n",
      "input_captions: ['ant .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 21\n",
      "new count: 10.5\n",
      "Pred Count: 10.5, GT Count: 13\n",
      "input_captions: ['ant .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 17\n",
      "new count: 7.285714285714286\n",
      "Pred Count: 7.285714285714286, GT Count: 8\n",
      "input_captions: ['ant .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 166\n",
      "new count: 55.333333333333336\n",
      "Pred Count: 55.333333333333336, GT Count: 60\n",
      "input_captions: ['ant .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 14\n",
      "new count: 8.4\n",
      "Pred Count: 8.4, GT Count: 8\n",
      "input_captions: ['ant .']\n",
      "Pred Count: 17, GT Count: 16\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 11, GT Count: 10\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 62, GT Count: 58\n",
      "Test:  [ 130/1286]  eta: 0:28:43    time: 1.7123  data: 0.0101  max mem: 7549\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 43, GT Count: 36\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 11, GT Count: 12\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 14, GT Count: 13\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 11, GT Count: 10\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['bird .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 20, GT Count: 16\n",
      "Test:  [ 140/1286]  eta: 0:27:52    time: 1.5329  data: 0.0097  max mem: 7549\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 78, GT Count: 77\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 57, GT Count: 56\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 101, GT Count: 85\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 12, GT Count: 11\n",
      "input_captions: ['bird .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 55, GT Count: 50\n",
      "input_captions: ['book .']\n",
      "Pred Count: 53, GT Count: 55\n",
      "input_captions: ['book .']\n",
      "Pred Count: 17, GT Count: 16\n",
      "input_captions: ['book .']\n",
      "Pred Count: 22, GT Count: 13\n",
      "input_captions: ['book .']\n",
      "Pred Count: 110, GT Count: 83\n",
      "input_captions: ['book .']\n",
      "Pred Count: 18, GT Count: 15\n",
      "Test:  [ 150/1286]  eta: 0:27:10    time: 1.0740  data: 0.0080  max mem: 7549\n",
      "input_captions: ['book .']\n",
      "Pred Count: 21, GT Count: 28\n",
      "input_captions: ['book .']\n",
      "Pred Count: 12, GT Count: 10\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 11, GT Count: 8\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 21, GT Count: 20\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 26, GT Count: 15\n",
      "input_captions: ['book .']\n",
      "Pred Count: 14, GT Count: 13\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 36, GT Count: 36\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 179, GT Count: 182\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 327, GT Count: 323\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 22, GT Count: 22\n",
      "Test:  [ 160/1286]  eta: 0:27:01    time: 1.3030  data: 0.0092  max mem: 7549\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 14, GT Count: 17\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 54, GT Count: 51\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 184, GT Count: 185\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 36, GT Count: 34\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 40, GT Count: 40\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 439, GT Count: 437\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 56, GT Count: 53\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 196, GT Count: 195\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "Test:  [ 170/1286]  eta: 0:26:18    time: 1.2590  data: 0.0101  max mem: 7549\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 51, GT Count: 50\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 70, GT Count: 70\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 41, GT Count: 40\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 76, GT Count: 87\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 570, GT Count: 577\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 117, GT Count: 117\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 117, GT Count: 116\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 55, GT Count: 54\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 80, GT Count: 80\n",
      "input_captions: ['book .']\n",
      "Pred Count: 22, GT Count: 22\n",
      "Test:  [ 180/1286]  eta: 0:25:37    time: 0.9896  data: 0.0087  max mem: 7549\n",
      "input_captions: ['book .']\n",
      "Pred Count: 215, GT Count: 230\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 43, GT Count: 35\n",
      "input_captions: ['book .']\n",
      "Pred Count: 92, GT Count: 113\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 452, GT Count: 637\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 22\n",
      "new count: 11.0\n",
      "Pred Count: 11.0, GT Count: 11\n",
      "input_captions: ['book .']\n",
      "Pred Count: 42, GT Count: 46\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 187, GT Count: 191\n",
      "input_captions: ['book .']\n",
      "Pred Count: 171, GT Count: 142\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 37, GT Count: 35\n",
      "input_captions: ['book .']\n",
      "Pred Count: 24, GT Count: 21\n",
      "Test:  [ 190/1286]  eta: 0:26:32    time: 1.7762  data: 0.0094  max mem: 7549\n",
      "input_captions: ['book .']\n",
      "Pred Count: 190, GT Count: 183\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 336, GT Count: 320\n",
      "input_captions: ['book .']\n",
      "Pred Count: 30, GT Count: 41\n",
      "input_captions: ['book .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['book .']\n",
      "Pred Count: 11, GT Count: 10\n",
      "input_captions: ['book .']\n",
      "Pred Count: 46, GT Count: 44\n",
      "input_captions: ['book .']\n",
      "Pred Count: 188, GT Count: 162\n",
      "input_captions: ['book .']\n",
      "Pred Count: 99, GT Count: 97\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 293\n",
      "new count: 146.5\n",
      "Pred Count: 146.5, GT Count: 240\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 53, GT Count: 65\n",
      "Test:  [ 200/1286]  eta: 0:26:31    time: 2.1479  data: 0.0096  max mem: 7549\n",
      "input_captions: ['book .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['book .']\n",
      "Pred Count: 79, GT Count: 84\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 650, GT Count: 1022\n",
      "input_captions: ['book .']\n",
      "Pred Count: 251, GT Count: 230\n",
      "input_captions: ['book .']\n",
      "Pred Count: 24, GT Count: 23\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 9, GT Count: 8\n",
      "input_captions: ['book .']\n",
      "Pred Count: 286, GT Count: 250\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 15, GT Count: 18\n",
      "input_captions: ['book .']\n",
      "Pred Count: 25, GT Count: 21\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 153, GT Count: 207\n",
      "Test:  [ 210/1286]  eta: 0:26:48    time: 1.8989  data: 0.0090  max mem: 7549\n",
      "input_captions: ['skateboard .']\n",
      "Pred Count: 16, GT Count: 9\n",
      "input_captions: ['skateboard .']\n",
      "Pred Count: 52, GT Count: 65\n",
      "input_captions: ['skateboard .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['skateboard .']\n",
      "Pred Count: 14, GT Count: 9\n",
      "input_captions: ['skateboard .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['skateboard .']\n",
      "Pred Count: 47, GT Count: 47\n",
      "input_captions: ['skateboard .']\n",
      "Pred Count: 27, GT Count: 32\n",
      "input_captions: ['skateboard .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['skateboard .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['bird .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 118, GT Count: 122\n",
      "Test:  [ 220/1286]  eta: 0:26:13    time: 1.5773  data: 0.0095  max mem: 7549\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 51, GT Count: 47\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 42, GT Count: 39\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 22, GT Count: 23\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 383, GT Count: 298\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 62, GT Count: 53\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 70, GT Count: 67\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 14, GT Count: 13\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 900, GT Count: 2092\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "Test:  [ 230/1286]  eta: 0:25:42    time: 1.0961  data: 0.0083  max mem: 7549\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 15, GT Count: 13\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 37, GT Count: 37\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 94, GT Count: 97\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 148, GT Count: 122\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['bird .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 900, GT Count: 1092\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 149, GT Count: 139\n",
      "input_captions: ['bird .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 97, GT Count: 86\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 552, GT Count: 530\n",
      "Test:  [ 240/1286]  eta: 0:25:53    time: 1.5879  data: 0.0074  max mem: 7549\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 21, GT Count: 18\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['bird .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 49, GT Count: 48\n",
      "input_captions: ['bird .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 7, GT Count: 7\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 69, GT Count: 63\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 83, GT Count: 76\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 40, GT Count: 38\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 67, GT Count: 63\n",
      "Test:  [ 250/1286]  eta: 0:25:25    time: 1.6091  data: 0.0075  max mem: 7549\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 489, GT Count: 485\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 50, GT Count: 45\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 702, GT Count: 718\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 90, GT Count: 85\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 182, GT Count: 165\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 121, GT Count: 108\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 53, GT Count: 50\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 66, GT Count: 64\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 52, GT Count: 35\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 36, GT Count: 42\n",
      "Test:  [ 260/1286]  eta: 0:24:55    time: 1.1301  data: 0.0074  max mem: 7549\n",
      "input_captions: ['pill .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 115, GT Count: 166\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 64, GT Count: 76\n",
      "input_captions: ['bottle cap .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 36, GT Count: 31\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 180, GT Count: 180\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 27, GT Count: 32\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 31, GT Count: 30\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 148, GT Count: 123\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 180, GT Count: 149\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "Test:  [ 270/1286]  eta: 0:24:47    time: 1.3679  data: 0.0071  max mem: 7549\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 19, GT Count: 17\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 95, GT Count: 94\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 162, GT Count: 139\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 70, GT Count: 70\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 29, GT Count: 28\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 31, GT Count: 28\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 115, GT Count: 119\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 49, GT Count: 46\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 52, GT Count: 50\n",
      "Test:  [ 280/1286]  eta: 0:24:14    time: 1.2932  data: 0.0070  max mem: 7549\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 486, GT Count: 684\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 24, GT Count: 20\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 443, GT Count: 436\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 117, GT Count: 138\n",
      "input_captions: ['bottle cap .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 44, GT Count: 49\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 45, GT Count: 45\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 48, GT Count: 48\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 29, GT Count: 29\n",
      "Test:  [ 290/1286]  eta: 0:24:20    time: 1.4940  data: 0.0070  max mem: 7549\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 60, GT Count: 68\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 118, GT Count: 86\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 21, GT Count: 18\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 54, GT Count: 54\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 216, GT Count: 215\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 179, GT Count: 171\n",
      "input_captions: ['bottle cap .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 170, GT Count: 175\n",
      "input_captions: ['bottle cap .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 510, GT Count: 501\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 128, GT Count: 117\n",
      "Test:  [ 300/1286]  eta: 0:24:00    time: 1.6639  data: 0.0071  max mem: 7549\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['bottle cap .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 78, GT Count: 69\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 184, GT Count: 163\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 216, GT Count: 221\n",
      "input_captions: ['bottle cap .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 54, GT Count: 48\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 42, GT Count: 44\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 40, GT Count: 40\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 17, GT Count: 22\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 150, GT Count: 150\n",
      "Test:  [ 310/1286]  eta: 0:23:59    time: 1.6033  data: 0.0073  max mem: 7549\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 21, GT Count: 19\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 49, GT Count: 37\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 839, GT Count: 1229\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 41, GT Count: 39\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 68, GT Count: 68\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 176, GT Count: 163\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 123, GT Count: 111\n",
      "Test:  [ 320/1286]  eta: 0:23:30    time: 1.4454  data: 0.0074  max mem: 7549\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 96, GT Count: 96\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 36, GT Count: 36\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['bottle cap .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 131, GT Count: 134\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "Test:  [ 330/1286]  eta: 0:23:16    time: 1.2423  data: 0.0072  max mem: 7549\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 30, GT Count: 32\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 136, GT Count: 132\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 35, GT Count: 35\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 41, GT Count: 40\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 215, GT Count: 159\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 162, GT Count: 172\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 35, GT Count: 35\n",
      "input_captions: ['bottle cap .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 247, GT Count: 248\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 68, GT Count: 95\n",
      "Test:  [ 340/1286]  eta: 0:22:56    time: 1.3901  data: 0.0074  max mem: 7549\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 157, GT Count: 148\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 392, GT Count: 476\n",
      "input_captions: ['bottle cap .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 96, GT Count: 119\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 48, GT Count: 48\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 309, GT Count: 313\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 110, GT Count: 83\n",
      "Test:  [ 350/1286]  eta: 0:22:39    time: 1.3001  data: 0.0076  max mem: 7549\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 22, GT Count: 18\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 100, GT Count: 100\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['ant .']\n",
      "Pred Count: 71, GT Count: 72\n",
      "input_captions: ['camel .']\n",
      "Pred Count: 9, GT Count: 8\n",
      "input_captions: ['camel .']\n",
      "Pred Count: 12, GT Count: 19\n",
      "input_captions: ['camel .']\n",
      "Pred Count: 71, GT Count: 14\n",
      "input_captions: ['camel .']\n",
      "Pred Count: 16, GT Count: 11\n",
      "input_captions: ['camel .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['camel .']\n",
      "Pred Count: 10, GT Count: 9\n",
      "Test:  [ 360/1286]  eta: 0:22:12    time: 1.1556  data: 0.0074  max mem: 7549\n",
      "input_captions: ['camel .']\n",
      "Pred Count: 31, GT Count: 27\n",
      "input_captions: ['camel .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['camel .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['camel .']\n",
      "Pred Count: 10, GT Count: 8\n",
      "input_captions: ['camel .']\n",
      "Pred Count: 83, GT Count: 58\n",
      "input_captions: ['camel .']\n",
      "Pred Count: 8, GT Count: 10\n",
      "input_captions: ['horse .']\n",
      "Pred Count: 18, GT Count: 9\n",
      "input_captions: ['horse .']\n",
      "Pred Count: 20, GT Count: 17\n",
      "input_captions: ['horse .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 63, GT Count: 59\n",
      "input_captions: ['horse .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 28, GT Count: 25\n",
      "Test:  [ 370/1286]  eta: 0:22:06    time: 1.3861  data: 0.0073  max mem: 7549\n",
      "input_captions: ['horse .']\n",
      "Pred Count: 10, GT Count: 9\n",
      "input_captions: ['horse .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 12, GT Count: 15\n",
      "input_captions: ['horse .']\n",
      "Pred Count: 9, GT Count: 8\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 253, GT Count: 263\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 30, GT Count: 26\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 47, GT Count: 45\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 119, GT Count: 158\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 46, GT Count: 49\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 53, GT Count: 45\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 231, GT Count: 252\n",
      "Test:  [ 380/1286]  eta: 0:21:59    time: 1.7756  data: 0.0072  max mem: 7549\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 37, GT Count: 34\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 126, GT Count: 136\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 48, GT Count: 22\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 165, GT Count: 140\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 76, GT Count: 58\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 71, GT Count: 61\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 78, GT Count: 62\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 11, GT Count: 9\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 90, GT Count: 89\n",
      "Test:  [ 390/1286]  eta: 0:22:02    time: 1.9934  data: 0.0072  max mem: 7549\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 23, GT Count: 25\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 71, GT Count: 67\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 24, GT Count: 35\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 133, GT Count: 124\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 34, GT Count: 38\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 19, GT Count: 20\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 55, GT Count: 57\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 183, GT Count: 287\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 64, GT Count: 61\n",
      "Test:  [ 400/1286]  eta: 0:21:44    time: 1.7722  data: 0.0069  max mem: 7549\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 22\n",
      "new count: 13.2\n",
      "Pred Count: 13.2, GT Count: 16\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 64, GT Count: 56\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 97, GT Count: 107\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 132, GT Count: 131\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 38, GT Count: 38\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 46, GT Count: 40\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 93, GT Count: 85\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 147, GT Count: 151\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 54, GT Count: 45\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 30, GT Count: 25\n",
      "Test:  [ 410/1286]  eta: 0:21:30    time: 1.4012  data: 0.0065  max mem: 7549\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 9, GT Count: 8\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 12, GT Count: 13\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 141, GT Count: 119\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 30\n",
      "new count: 18.0\n",
      "Pred Count: 18.0, GT Count: 23\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 70, GT Count: 48\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 12, GT Count: 10\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 12, GT Count: 11\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 76, GT Count: 60\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 144, GT Count: 111\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 298, GT Count: 301\n",
      "Test:  [ 420/1286]  eta: 0:21:35    time: 1.9570  data: 0.0071  max mem: 7549\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 160, GT Count: 150\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 144, GT Count: 158\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 125, GT Count: 131\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 192, GT Count: 174\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 150, GT Count: 165\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 23, GT Count: 18\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 39, GT Count: 32\n",
      "input_captions: ['shirt .']\n",
      "Pred Count: 36, GT Count: 39\n",
      "input_captions: ['shirt .']\n",
      "Pred Count: 37, GT Count: 35\n",
      "input_captions: ['shirt .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 19, GT Count: 9\n",
      "Test:  [ 430/1286]  eta: 0:21:45    time: 2.6042  data: 0.0074  max mem: 7549\n",
      "input_captions: ['shirt .']\n",
      "Pred Count: 17, GT Count: 14\n",
      "input_captions: ['shirt .']\n",
      "Pred Count: 30, GT Count: 69\n",
      "input_captions: ['shirt .']\n",
      "Pred Count: 19, GT Count: 16\n",
      "input_captions: ['bullet .']\n",
      "Pred Count: 36, GT Count: 35\n",
      "input_captions: ['bullet .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['bullet .']\n",
      "Pred Count: 28, GT Count: 25\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 900, GT Count: 885\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 235, GT Count: 219\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['polka dot .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 732\n",
      "new count: 439.2\n",
      "Pred Count: 439.2, GT Count: 458\n",
      "Test:  [ 440/1286]  eta: 0:21:20    time: 1.9038  data: 0.0077  max mem: 7549\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 37, GT Count: 36\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 75, GT Count: 75\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 50, GT Count: 49\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 476, GT Count: 538\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 264, GT Count: 305\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 117, GT Count: 116\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 762, GT Count: 443\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 424, GT Count: 501\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 56, GT Count: 60\n",
      "input_captions: ['polka dot .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 269, GT Count: 262\n",
      "Test:  [ 450/1286]  eta: 0:20:54    time: 0.9820  data: 0.0077  max mem: 7549\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 13, GT Count: 344\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 40, GT Count: 41\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 372, GT Count: 431\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 285, GT Count: 315\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 119, GT Count: 261\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 27, GT Count: 356\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 8, GT Count: 174\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 92, GT Count: 81\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 268, GT Count: 321\n",
      "input_captions: ['polka dot .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 446, GT Count: 431\n",
      "Test:  [ 460/1286]  eta: 0:20:31    time: 0.9776  data: 0.0077  max mem: 7549\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 276, GT Count: 278\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 64, GT Count: 64\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 71, GT Count: 69\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['chicken wing .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 11, GT Count: 10\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 27, GT Count: 27\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 27, GT Count: 27\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 39, GT Count: 42\n",
      "Test:  [ 470/1286]  eta: 0:20:09    time: 1.0452  data: 0.0079  max mem: 7549\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 29, GT Count: 29\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 23, GT Count: 30\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 21, GT Count: 20\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 23, GT Count: 23\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "Test:  [ 480/1286]  eta: 0:19:46    time: 1.0586  data: 0.0082  max mem: 7549\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 26, GT Count: 28\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "Test:  [ 490/1286]  eta: 0:19:25    time: 1.0405  data: 0.0092  max mem: 7549\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 14, GT Count: 15\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 24, GT Count: 22\n",
      "Test:  [ 500/1286]  eta: 0:19:02    time: 1.0024  data: 0.0084  max mem: 7549\n",
      "input_captions: ['chicken wing .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 23, GT Count: 23\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 20, GT Count: 19\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 22, GT Count: 22\n",
      "input_captions: ['chicken wing .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 15, GT Count: 13\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 23, GT Count: 22\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 21, GT Count: 23\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "Test:  [ 510/1286]  eta: 0:18:45    time: 1.1114  data: 0.0071  max mem: 7549\n",
      "input_captions: ['chicken wing .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 15, GT Count: 12\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 28, GT Count: 25\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['chicken wing .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 10, GT Count: 9\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 41, GT Count: 42\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 33, GT Count: 32\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 26, GT Count: 26\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 9, GT Count: 11\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "Test:  [ 520/1286]  eta: 0:18:27    time: 1.2375  data: 0.0068  max mem: 7549\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 38, GT Count: 37\n",
      "input_captions: ['chicken wing .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 23, GT Count: 22\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['chicken wing .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 10, GT Count: 9\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 22, GT Count: 22\n",
      "input_captions: ['chicken wing .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "Test:  [ 530/1286]  eta: 0:18:11    time: 1.2759  data: 0.0070  max mem: 7549\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 52, GT Count: 50\n",
      "input_captions: ['toilet paper roll .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 846, GT Count: 907\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 48, GT Count: 32\n",
      "input_captions: ['toilet paper roll .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 34, GT Count: 31\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 38, GT Count: 36\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 16, GT Count: 15\n",
      "Test:  [ 540/1286]  eta: 0:17:52    time: 1.2241  data: 0.0073  max mem: 7549\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 55, GT Count: 46\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 34, GT Count: 33\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "Test:  [ 550/1286]  eta: 0:17:31    time: 1.0323  data: 0.0070  max mem: 7549\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 10\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "Test:  [ 560/1286]  eta: 0:17:11    time: 0.9605  data: 0.0070  max mem: 7549\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 33, GT Count: 31\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 18, GT Count: 14\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 14, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "Test:  [ 570/1286]  eta: 0:16:53    time: 1.0596  data: 0.0070  max mem: 7549\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 9, GT Count: 8\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['shallot .']\n",
      "Pred Count: 20, GT Count: 17\n",
      "input_captions: ['shallot .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 30, GT Count: 31\n",
      "input_captions: ['shallot .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['shallot .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 7, GT Count: 7\n",
      "input_captions: ['oyster .']\n",
      "Pred Count: 10, GT Count: 9\n",
      "input_captions: ['oyster .']\n",
      "Pred Count: 15, GT Count: 16\n",
      "input_captions: ['oyster .']\n",
      "Pred Count: 9, GT Count: 8\n",
      "input_captions: ['bullet .']\n",
      "Pred Count: 41, GT Count: 40\n",
      "Test:  [ 580/1286]  eta: 0:16:37    time: 1.2005  data: 0.0070  max mem: 7549\n",
      "input_captions: ['bullet .']\n",
      "Pred Count: 20, GT Count: 19\n",
      "input_captions: ['bullet .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['bullet .']\n",
      "Pred Count: 16, GT Count: 14\n",
      "input_captions: ['bullet .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['bullet .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['bullet .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['bullet .']\n",
      "Pred Count: 18, GT Count: 17\n",
      "input_captions: ['oyster shell .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['oyster shell .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['oyster shell .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "Test:  [ 590/1286]  eta: 0:16:18    time: 1.1288  data: 0.0072  max mem: 7549\n",
      "input_captions: ['oyster shell .']\n",
      "Pred Count: 41, GT Count: 44\n",
      "input_captions: ['oyster shell .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 16, GT Count: 12\n",
      "input_captions: ['oyster shell .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['oyster shell .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['oyster shell .']\n",
      "Pred Count: 50, GT Count: 49\n",
      "input_captions: ['oyster shell .']\n",
      "Pred Count: 10, GT Count: 9\n",
      "input_captions: ['prawn cracker .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 17, GT Count: 13\n",
      "input_captions: ['prawn cracker .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['sausage .']\n",
      "Pred Count: 27, GT Count: 26\n",
      "input_captions: ['sausage .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "Test:  [ 600/1286]  eta: 0:16:01    time: 1.0780  data: 0.0072  max mem: 7549\n",
      "input_captions: ['sausage .']\n",
      "Pred Count: 111, GT Count: 104\n",
      "input_captions: ['sausage .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['sausage .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 35, GT Count: 25\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 49, GT Count: 44\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 20, GT Count: 22\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 26, GT Count: 22\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 28, GT Count: 27\n",
      "Test:  [ 610/1286]  eta: 0:15:48    time: 1.3306  data: 0.0072  max mem: 7549\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 46, GT Count: 51\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 15, GT Count: 16\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 24, GT Count: 23\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 20, GT Count: 17\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 23, GT Count: 23\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 34, GT Count: 33\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 31, GT Count: 21\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 35, GT Count: 35\n",
      "Test:  [ 620/1286]  eta: 0:15:30    time: 1.2837  data: 0.0074  max mem: 7549\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 35, GT Count: 35\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 62, GT Count: 55\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 34, GT Count: 33\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 51, GT Count: 42\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 20, GT Count: 17\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 70, GT Count: 65\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 135, GT Count: 133\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 28, GT Count: 29\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "Test:  [ 630/1286]  eta: 0:15:13    time: 1.0789  data: 0.0078  max mem: 7549\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 36, GT Count: 35\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 11, GT Count: 9\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 143, GT Count: 133\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 23, GT Count: 24\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 37, GT Count: 37\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 10, GT Count: 13\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "Test:  [ 640/1286]  eta: 0:14:56    time: 1.0930  data: 0.0078  max mem: 7549\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 10, GT Count: 11\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 45, GT Count: 47\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 139, GT Count: 141\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 39, GT Count: 36\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 413, GT Count: 402\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 24, GT Count: 22\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 37, GT Count: 38\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 39, GT Count: 37\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "Test:  [ 650/1286]  eta: 0:14:40    time: 1.1041  data: 0.0076  max mem: 7549\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 36, GT Count: 34\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 170, GT Count: 165\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 37, GT Count: 42\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 18, GT Count: 16\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['kiwi .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 34, GT Count: 33\n",
      "input_captions: ['kiwi .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 9, GT Count: 8\n",
      "Test:  [ 660/1286]  eta: 0:14:25    time: 1.1953  data: 0.0076  max mem: 7549\n",
      "input_captions: ['kiwi .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 37, GT Count: 34\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 43, GT Count: 38\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['kiwi .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 35, GT Count: 34\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 17, GT Count: 16\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 64, GT Count: 64\n",
      "input_captions: ['kiwi .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 24, GT Count: 22\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 23, GT Count: 19\n",
      "Test:  [ 670/1286]  eta: 0:14:16    time: 1.5758  data: 0.0071  max mem: 7549\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 35, GT Count: 41\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 10, GT Count: 8\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 56, GT Count: 54\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 84, GT Count: 87\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 32, GT Count: 34\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 54, GT Count: 54\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 14, GT Count: 13\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 27, GT Count: 19\n",
      "input_captions: ['kiwi .']\n",
      "Pred Count: 54, GT Count: 51\n",
      "Test:  [ 680/1286]  eta: 0:13:58    time: 1.4264  data: 0.0070  max mem: 7549\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 11, GT Count: 13\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 53, GT Count: 47\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 14, GT Count: 13\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 121, GT Count: 117\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 20, GT Count: 18\n",
      "Test:  [ 690/1286]  eta: 0:13:41    time: 0.9786  data: 0.0070  max mem: 7549\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 27, GT Count: 26\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 16, GT Count: 15\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 34, GT Count: 33\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 15, GT Count: 14\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "Test:  [ 700/1286]  eta: 0:13:24    time: 0.9722  data: 0.0071  max mem: 7549\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 19, GT Count: 21\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 10, GT Count: 11\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 23, GT Count: 23\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 17, GT Count: 15\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 57, GT Count: 56\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 113, GT Count: 104\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "Test:  [ 710/1286]  eta: 0:13:07    time: 0.9613  data: 0.0073  max mem: 7549\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 29, GT Count: 28\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['peach .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 34, GT Count: 23\n",
      "input_captions: ['peach .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 42, GT Count: 40\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['peach .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 51, GT Count: 41\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 51, GT Count: 47\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 9, GT Count: 8\n",
      "input_captions: ['peach .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 59, GT Count: 41\n",
      "input_captions: ['peach .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 28, GT Count: 24\n",
      "Test:  [ 720/1286]  eta: 0:13:08    time: 2.1604  data: 0.0075  max mem: 7549\n",
      "input_captions: ['peach .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 44, GT Count: 39\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 57, GT Count: 55\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 22, GT Count: 20\n",
      "input_captions: ['peach .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 120, GT Count: 133\n",
      "input_captions: ['peach .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 43, GT Count: 39\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 43, GT Count: 42\n",
      "input_captions: ['peach .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 41, GT Count: 40\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 23, GT Count: 22\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 116, GT Count: 109\n",
      "Test:  [ 730/1286]  eta: 0:12:57    time: 2.5571  data: 0.0076  max mem: 7549\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 42, GT Count: 42\n",
      "input_captions: ['peach .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 25, GT Count: 22\n",
      "input_captions: ['peach .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 32, GT Count: 30\n",
      "input_captions: ['peach .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 30, GT Count: 24\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 22, GT Count: 21\n",
      "input_captions: ['peach .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 129, GT Count: 114\n",
      "input_captions: ['peach .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 25, GT Count: 21\n",
      "input_captions: ['peach .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 59, GT Count: 55\n",
      "Test:  [ 740/1286]  eta: 0:12:52    time: 2.1706  data: 0.0078  max mem: 7549\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 184, GT Count: 196\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 95, GT Count: 80\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 148, GT Count: 122\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 33, GT Count: 32\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 60, GT Count: 60\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 62, GT Count: 61\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 55, GT Count: 50\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 34, GT Count: 34\n",
      "Test:  [ 750/1286]  eta: 0:12:36    time: 1.8998  data: 0.0078  max mem: 7549\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 75, GT Count: 73\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 54, GT Count: 41\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 24, GT Count: 25\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 135, GT Count: 120\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 275, GT Count: 306\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 104, GT Count: 112\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 193, GT Count: 213\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 72, GT Count: 67\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 40, GT Count: 43\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 24, GT Count: 19\n",
      "Test:  [ 760/1286]  eta: 0:12:23    time: 1.3286  data: 0.0077  max mem: 7549\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 77, GT Count: 70\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 45, GT Count: 33\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 54, GT Count: 57\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 38, GT Count: 37\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 52, GT Count: 41\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 169, GT Count: 144\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 112, GT Count: 90\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 34, GT Count: 29\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 60, GT Count: 49\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 41, GT Count: 36\n",
      "Test:  [ 770/1286]  eta: 0:12:07    time: 1.2950  data: 0.0092  max mem: 7549\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 43, GT Count: 39\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 109, GT Count: 84\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 44, GT Count: 39\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 45, GT Count: 40\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 101, GT Count: 90\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 126, GT Count: 122\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 57, GT Count: 50\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 104, GT Count: 98\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 46, GT Count: 46\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 69, GT Count: 65\n",
      "Test:  [ 780/1286]  eta: 0:11:57    time: 1.6521  data: 0.0092  max mem: 7549\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 54, GT Count: 42\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 30, GT Count: 26\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 48, GT Count: 46\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 50, GT Count: 46\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 59, GT Count: 57\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 131, GT Count: 122\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 43, GT Count: 43\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 22, GT Count: 21\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 58, GT Count: 55\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 75, GT Count: 61\n",
      "Test:  [ 790/1286]  eta: 0:11:45    time: 1.8891  data: 0.0074  max mem: 7549\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 92, GT Count: 80\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 131, GT Count: 121\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 116, GT Count: 101\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 39, GT Count: 32\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 33, GT Count: 31\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 48, GT Count: 50\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 43, GT Count: 36\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 22, GT Count: 22\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 132, GT Count: 134\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 101, GT Count: 100\n",
      "Test:  [ 800/1286]  eta: 0:11:30    time: 1.5097  data: 0.0073  max mem: 7549\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 119, GT Count: 131\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 232, GT Count: 215\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 39, GT Count: 39\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 224, GT Count: 286\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 87, GT Count: 98\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 31, GT Count: 32\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 66, GT Count: 72\n",
      "input_captions: ['chicken wing .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 19, GT Count: 19\n",
      "Test:  [ 810/1286]  eta: 0:11:14    time: 1.2380  data: 0.0070  max mem: 7549\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 11, GT Count: 10\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "Test:  [ 820/1286]  eta: 0:10:57    time: 1.0324  data: 0.0073  max mem: 7549\n",
      "input_captions: ['chicken wing .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 53, GT Count: 52\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 27, GT Count: 27\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 29, GT Count: 51\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 26, GT Count: 28\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['chicken wing .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 14, GT Count: 12\n",
      "Test:  [ 830/1286]  eta: 0:10:42    time: 1.1018  data: 0.0075  max mem: 7549\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 31, GT Count: 31\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 14, GT Count: 15\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "Test:  [ 840/1286]  eta: 0:10:26    time: 1.0853  data: 0.0067  max mem: 7549\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 27, GT Count: 27\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 22, GT Count: 22\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 10, GT Count: 9\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 24, GT Count: 23\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 23, GT Count: 21\n",
      "input_captions: ['chicken wing .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 14, GT Count: 13\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 18, GT Count: 17\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 24, GT Count: 23\n",
      "Test:  [ 850/1286]  eta: 0:10:10    time: 1.0136  data: 0.0069  max mem: 7549\n",
      "input_captions: ['chicken wing .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 14\n",
      "new count: 8.4\n",
      "Pred Count: 8.4, GT Count: 12\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 10, GT Count: 9\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 22, GT Count: 22\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 22, GT Count: 22\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 23, GT Count: 22\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "Test:  [ 860/1286]  eta: 0:09:55    time: 1.1505  data: 0.0072  max mem: 7549\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 62, GT Count: 57\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 49, GT Count: 32\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 16, GT Count: 15\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 33, GT Count: 32\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['toilet paper roll .']\n",
      "Pred Count: 49, GT Count: 31\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "Test:  [ 870/1286]  eta: 0:09:39    time: 1.0857  data: 0.0069  max mem: 7549\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "Test:  [ 880/1286]  eta: 0:09:23    time: 0.9610  data: 0.0060  max mem: 7549\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 17, GT Count: 13\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "Test:  [ 890/1286]  eta: 0:09:07    time: 0.9742  data: 0.0059  max mem: 7549\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 13, GT Count: 9\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 38, GT Count: 38\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 59, GT Count: 54\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 17, GT Count: 16\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "Test:  [ 900/1286]  eta: 0:08:52    time: 0.9765  data: 0.0069  max mem: 7549\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut holder .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 14, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 19, GT Count: 16\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 21, GT Count: 20\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 17, GT Count: 15\n",
      "Test:  [ 910/1286]  eta: 0:08:37    time: 1.0223  data: 0.0071  max mem: 7549\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['donut .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 30, GT Count: 32\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 250, GT Count: 239\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 88, GT Count: 103\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 25, GT Count: 27\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 57, GT Count: 53\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 95, GT Count: 87\n",
      "Test:  [ 920/1286]  eta: 0:08:21    time: 1.0061  data: 0.0062  max mem: 7549\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 31, GT Count: 36\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 52, GT Count: 43\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 229, GT Count: 270\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 262, GT Count: 322\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 131, GT Count: 146\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 101, GT Count: 100\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 92, GT Count: 100\n",
      "input_captions: ['polka dot .']\n",
      "Pred Count: 62, GT Count: 74\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 43, GT Count: 44\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 167, GT Count: 170\n",
      "Test:  [ 930/1286]  eta: 0:08:06    time: 0.9447  data: 0.0061  max mem: 7549\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 53, GT Count: 49\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 787, GT Count: 757\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 76, GT Count: 67\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 70, GT Count: 58\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 72, GT Count: 76\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 96, GT Count: 81\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 135, GT Count: 114\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 332, GT Count: 267\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 83, GT Count: 83\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 60, GT Count: 54\n",
      "Test:  [ 940/1286]  eta: 0:07:51    time: 1.0352  data: 0.0063  max mem: 7549\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 32, GT Count: 32\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 49, GT Count: 47\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 63, GT Count: 53\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 136, GT Count: 116\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 78, GT Count: 69\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 135, GT Count: 124\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 79, GT Count: 74\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 227, GT Count: 216\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 41, GT Count: 32\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 52, GT Count: 44\n",
      "Test:  [ 950/1286]  eta: 0:07:39    time: 1.4128  data: 0.0068  max mem: 7549\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 44, GT Count: 36\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 34, GT Count: 30\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 108, GT Count: 99\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 54, GT Count: 47\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 78, GT Count: 69\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 49, GT Count: 41\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 127, GT Count: 115\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 26, GT Count: 25\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 53, GT Count: 49\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 95, GT Count: 84\n",
      "Test:  [ 960/1286]  eta: 0:07:26    time: 1.6886  data: 0.0079  max mem: 7549\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 31, GT Count: 27\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 37, GT Count: 33\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 92, GT Count: 89\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 95, GT Count: 103\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 78, GT Count: 73\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 71, GT Count: 62\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 45, GT Count: 43\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 55, GT Count: 55\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 121, GT Count: 109\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 48, GT Count: 32\n",
      "Test:  [ 970/1286]  eta: 0:07:14    time: 1.7339  data: 0.0077  max mem: 7549\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 117, GT Count: 99\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 37, GT Count: 39\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 56, GT Count: 48\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 190, GT Count: 209\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 51, GT Count: 48\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 36, GT Count: 33\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 139, GT Count: 147\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 134, GT Count: 113\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 175, GT Count: 156\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 118, GT Count: 116\n",
      "Test:  [ 980/1286]  eta: 0:07:01    time: 1.6598  data: 0.0072  max mem: 7549\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 77, GT Count: 65\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 69, GT Count: 62\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 41, GT Count: 40\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 49, GT Count: 42\n",
      "input_captions: ['grape .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 120, GT Count: 123\n",
      "input_captions: ['grape .']\n",
      "Pred Count: 73, GT Count: 63\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 60, GT Count: 55\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 19, GT Count: 13\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "Test:  [ 990/1286]  eta: 0:06:51    time: 2.0671  data: 0.0070  max mem: 7549\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 34, GT Count: 29\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 74, GT Count: 48\n",
      "input_captions: ['seagull .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 53, GT Count: 49\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 9, GT Count: 10\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 10, GT Count: 11\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 110, GT Count: 104\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "Test:  [1000/1286]  eta: 0:06:36    time: 1.9175  data: 0.0070  max mem: 7549\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 25, GT Count: 23\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 33, GT Count: 33\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 17, GT Count: 12\n",
      "input_captions: ['seagull .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 38, GT Count: 36\n",
      "input_captions: ['seagull .']\n",
      "Pred Count: 54, GT Count: 53\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 20, GT Count: 16\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['flamingo .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 31, GT Count: 36\n",
      "Test:  [1010/1286]  eta: 0:06:21    time: 1.1408  data: 0.0078  max mem: 7549\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 20, GT Count: 18\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 26, GT Count: 25\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 94, GT Count: 98\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 28, GT Count: 27\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 38, GT Count: 37\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 368, GT Count: 277\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 8, GT Count: 9\n",
      "input_captions: ['flamingo .']\n",
      "Pred Count: 32, GT Count: 31\n",
      "Test:  [1020/1286]  eta: 0:06:07    time: 1.0212  data: 0.0079  max mem: 7549\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 34, GT Count: 30\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 20, GT Count: 18\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 10, GT Count: 11\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 32, GT Count: 32\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 13, GT Count: 12\n",
      "Test:  [1030/1286]  eta: 0:05:52    time: 0.9764  data: 0.0072  max mem: 7549\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 26, GT Count: 28\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 29, GT Count: 29\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 26, GT Count: 26\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "Test:  [1040/1286]  eta: 0:05:37    time: 0.9492  data: 0.0072  max mem: 7549\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 31, GT Count: 32\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 28, GT Count: 27\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 22, GT Count: 18\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 29, GT Count: 32\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 47, GT Count: 46\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 23, GT Count: 23\n",
      "Test:  [1050/1286]  eta: 0:05:22    time: 0.9452  data: 0.0072  max mem: 7549\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 23, GT Count: 21\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['chicken wing .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 16, GT Count: 12\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['chicken wing .']\n",
      "Pred Count: 16, GT Count: 15\n",
      "Test:  [1060/1286]  eta: 0:05:08    time: 0.9856  data: 0.0072  max mem: 7549\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 49, GT Count: 49\n",
      "input_captions: ['pill .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 26, GT Count: 23\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 21, GT Count: 18\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 15, GT Count: 16\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 31, GT Count: 31\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['pill .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 15, GT Count: 9\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 49, GT Count: 50\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 70, GT Count: 70\n",
      "Test:  [1070/1286]  eta: 0:04:54    time: 1.0344  data: 0.0073  max mem: 7549\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 33, GT Count: 33\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 62, GT Count: 61\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 28, GT Count: 28\n",
      "input_captions: ['pill .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 25, GT Count: 24\n",
      "input_captions: ['pill .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['pill .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 58, GT Count: 58\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 11, GT Count: 9\n",
      "input_captions: ['pill .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 33, GT Count: 32\n",
      "Test:  [1080/1286]  eta: 0:04:40    time: 1.2829  data: 0.0074  max mem: 7549\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 20, GT Count: 11\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['package of fresh cut fruit .']\n",
      "Pred Count: 21, GT Count: 20\n",
      "input_captions: ['package of fresh cut fruit .']\n",
      "Pred Count: 32, GT Count: 32\n",
      "input_captions: ['package of fresh cut fruit .']\n",
      "Pred Count: 78, GT Count: 99\n",
      "input_captions: ['package of fresh cut fruit .']\n",
      "Pred Count: 60, GT Count: 63\n",
      "input_captions: ['package of fresh cut fruit .']\n",
      "Pred Count: 47, GT Count: 40\n",
      "input_captions: ['package of fresh cut fruit .']\n",
      "Pred Count: 118, GT Count: 119\n",
      "input_captions: ['package of fresh cut fruit .']\n",
      "Pred Count: 54, GT Count: 64\n",
      "input_captions: ['package of fresh cut fruit .']\n",
      "Pred Count: 172, GT Count: 167\n",
      "Test:  [1090/1286]  eta: 0:04:26    time: 1.2715  data: 0.0079  max mem: 7549\n",
      "input_captions: ['package of fresh cut fruit .']\n",
      "Pred Count: 71, GT Count: 66\n",
      "input_captions: ['package of fresh cut fruit .']\n",
      "Pred Count: 51, GT Count: 53\n",
      "input_captions: ['package of fresh cut fruit .']\n",
      "Pred Count: 189, GT Count: 177\n",
      "input_captions: ['milk carton .']\n",
      "Pred Count: 77, GT Count: 66\n",
      "input_captions: ['milk carton .']\n",
      "Pred Count: 75, GT Count: 66\n",
      "input_captions: ['milk carton .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 25, GT Count: 22\n",
      "input_captions: ['milk carton .']\n",
      "Pred Count: 141, GT Count: 121\n",
      "input_captions: ['milk carton .']\n",
      "Pred Count: 40, GT Count: 39\n",
      "input_captions: ['milk carton .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 77, GT Count: 59\n",
      "input_captions: ['milk carton .']\n",
      "Pred Count: 50, GT Count: 34\n",
      "Test:  [1100/1286]  eta: 0:04:15    time: 1.8079  data: 0.0086  max mem: 7549\n",
      "input_captions: ['milk carton .']\n",
      "Pred Count: 55, GT Count: 49\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 106, GT Count: 110\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 141, GT Count: 136\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 108, GT Count: 106\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 113, GT Count: 73\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 72, GT Count: 67\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 234, GT Count: 218\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 207, GT Count: 211\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 44, GT Count: 35\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 81, GT Count: 79\n",
      "Test:  [1110/1286]  eta: 0:04:05    time: 3.2780  data: 0.0085  max mem: 7549\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 166, GT Count: 142\n",
      "input_captions: ['chair .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 58, GT Count: 33\n",
      "input_captions: ['chair .']\n",
      "Pred Count: 152, GT Count: 142\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 218, GT Count: 199\n",
      "input_captions: ['book .']\n",
      "Pred Count: 114, GT Count: 74\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 22, GT Count: 16\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['book .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 19, GT Count: 17\n",
      "input_captions: ['book .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "Test:  [1120/1286]  eta: 0:03:53    time: 3.4347  data: 0.0076  max mem: 7549\n",
      "input_captions: ['book .']\n",
      "Pred Count: 76, GT Count: 75\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 20, GT Count: 15\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 25, GT Count: 26\n",
      "input_captions: ['book .']\n",
      "Pred Count: 38, GT Count: 37\n",
      "input_captions: ['book .']\n",
      "Pred Count: 242, GT Count: 207\n",
      "input_captions: ['book .']\n",
      "Pred Count: 76, GT Count: 52\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 269\n",
      "new count: 42.473684210526315\n",
      "Pred Count: 42.473684210526315, GT Count: 47\n",
      "input_captions: ['book .']\n",
      "Pred Count: 147, GT Count: 140\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 28, GT Count: 29\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 137, GT Count: 116\n",
      "Test:  [1130/1286]  eta: 0:03:43    time: 3.6404  data: 0.0066  max mem: 7549\n",
      "input_captions: ['book .']\n",
      "Pred Count: 167, GT Count: 182\n",
      "input_captions: ['book .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['book .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['book .']\n",
      "Pred Count: 20, GT Count: 17\n",
      "input_captions: ['book .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['shirt .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 205, GT Count: 169\n",
      "input_captions: ['shirt .']\n",
      "Pred Count: 22, GT Count: 19\n",
      "input_captions: ['shirt .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 101, GT Count: 62\n",
      "input_captions: ['shirt .']\n",
      "Pred Count: 266, GT Count: 251\n",
      "input_captions: ['shirt .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 897, GT Count: 1231\n",
      "Test:  [1140/1286]  eta: 0:03:31    time: 3.5931  data: 0.0066  max mem: 7549\n",
      "input_captions: ['shirt .']\n",
      "Pred Count: 207, GT Count: 191\n",
      "input_captions: ['shirt .']\n",
      "Pred Count: 41, GT Count: 36\n",
      "input_captions: ['shirt .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 118, GT Count: 105\n",
      "input_captions: ['shirt .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 201, GT Count: 186\n",
      "input_captions: ['shirt .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 33, GT Count: 22\n",
      "input_captions: ['shirt .']\n",
      "Pred Count: 41, GT Count: 37\n",
      "input_captions: ['shirt .']\n",
      "Pred Count: 223, GT Count: 214\n",
      "input_captions: ['shirt .']\n",
      "Pred Count: 24, GT Count: 20\n",
      "input_captions: ['shirt .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 31, GT Count: 27\n",
      "input_captions: ['ant .']\n",
      "Pred Count: 15, GT Count: 13\n",
      "Test:  [1150/1286]  eta: 0:03:18    time: 2.7206  data: 0.0070  max mem: 7549\n",
      "input_captions: ['ant .']\n",
      "Pred Count: 27, GT Count: 22\n",
      "input_captions: ['ant .']\n",
      "Pred Count: 21, GT Count: 19\n",
      "input_captions: ['ant .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 30, GT Count: 24\n",
      "input_captions: ['ant .']\n",
      "Pred Count: 85, GT Count: 72\n",
      "input_captions: ['ant .']\n",
      "Pred Count: 29, GT Count: 28\n",
      "input_captions: ['ant .']\n",
      "Pred Count: 52, GT Count: 40\n",
      "input_captions: ['ant .']\n",
      "Pred Count: 123, GT Count: 67\n",
      "input_captions: ['ant .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 322, GT Count: 238\n",
      "input_captions: ['horse .']\n",
      "Pred Count: 12, GT Count: 13\n",
      "input_captions: ['horse .']\n",
      "Pred Count: 19, GT Count: 17\n",
      "Test:  [1160/1286]  eta: 0:03:03    time: 1.9165  data: 0.0068  max mem: 7549\n",
      "input_captions: ['horse .']\n",
      "Pred Count: 17, GT Count: 13\n",
      "input_captions: ['horse .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 11, GT Count: 12\n",
      "input_captions: ['horse .']\n",
      "Pred Count: 11, GT Count: 10\n",
      "input_captions: ['horse .']\n",
      "Pred Count: 13, GT Count: 11\n",
      "input_captions: ['horse .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['horse .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['horse .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 16, GT Count: 14\n",
      "input_captions: ['horse .']\n",
      "Pred Count: 13, GT Count: 11\n",
      "input_captions: ['horse .']\n",
      "Pred Count: 12, GT Count: 10\n",
      "input_captions: ['horse .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "Test:  [1170/1286]  eta: 0:02:48    time: 1.1266  data: 0.0068  max mem: 7549\n",
      "input_captions: ['horse .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['horse .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['horse .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['horse .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 70, GT Count: 65\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 33, GT Count: 28\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 142, GT Count: 142\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 50, GT Count: 50\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "Test:  [1180/1286]  eta: 0:02:33    time: 1.0637  data: 0.0070  max mem: 7549\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 81, GT Count: 84\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 141, GT Count: 138\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 33, GT Count: 31\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 162, GT Count: 144\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 114, GT Count: 112\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 60, GT Count: 60\n",
      "input_captions: ['bird .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 383, GT Count: 355\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 26, GT Count: 26\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 179, GT Count: 166\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 83, GT Count: 83\n",
      "Test:  [1190/1286]  eta: 0:02:18    time: 1.1779  data: 0.0071  max mem: 7549\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 891, GT Count: 949\n",
      "input_captions: ['bird .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 59, GT Count: 57\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 36, GT Count: 36\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 24, GT Count: 20\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 64, GT Count: 61\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 41, GT Count: 39\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 43, GT Count: 42\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 25, GT Count: 23\n",
      "Test:  [1200/1286]  eta: 0:02:04    time: 1.1686  data: 0.0072  max mem: 7549\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 115, GT Count: 117\n",
      "input_captions: ['camel .']\n",
      "Pred Count: 44, GT Count: 43\n",
      "input_captions: ['camel .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 32\n",
      "new count: 16.0\n",
      "Pred Count: 16.0, GT Count: 18\n",
      "input_captions: ['skateboard .']\n",
      "Pred Count: 18, GT Count: 17\n",
      "input_captions: ['skateboard .']\n",
      "Pred Count: 129, GT Count: 127\n",
      "input_captions: ['skateboard .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 70, GT Count: 65\n",
      "input_captions: ['skateboard .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['skateboard .']\n",
      "Pred Count: 81, GT Count: 78\n",
      "input_captions: ['skateboard .']\n",
      "Pred Count: 44, GT Count: 23\n",
      "input_captions: ['skateboard .']\n",
      "Pred Count: 54, GT Count: 53\n",
      "Test:  [1210/1286]  eta: 0:01:49    time: 1.1084  data: 0.0069  max mem: 7549\n",
      "input_captions: ['skateboard .']\n",
      "Pred Count: 36, GT Count: 35\n",
      "input_captions: ['skateboard .']\n",
      "Pred Count: 26, GT Count: 26\n",
      "input_captions: ['skateboard .']\n",
      "Pred Count: 50, GT Count: 48\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 83, GT Count: 76\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 21, GT Count: 18\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 36, GT Count: 27\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 16, GT Count: 15\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 22, GT Count: 22\n",
      "Test:  [1220/1286]  eta: 0:01:34    time: 1.0662  data: 0.0071  max mem: 7549\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 28, GT Count: 27\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 84, GT Count: 83\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 53, GT Count: 17\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 60, GT Count: 40\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 39, GT Count: 39\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 60, GT Count: 61\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 29, GT Count: 28\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "Test:  [1230/1286]  eta: 0:01:20    time: 0.9867  data: 0.0081  max mem: 7549\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 28, GT Count: 28\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['flower pot .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 32, GT Count: 24\n",
      "input_captions: ['flower pot .']\n",
      "Pred Count: 30, GT Count: 25\n",
      "input_captions: ['flower .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['flower .']\n",
      "Pred Count: 43, GT Count: 42\n",
      "input_captions: ['flower pot .']\n",
      "Pred Count: 20, GT Count: 18\n",
      "input_captions: ['flower pot .']\n",
      "Pred Count: 87, GT Count: 68\n",
      "input_captions: ['flower pot .']\n",
      "Pred Count: 41, GT Count: 40\n",
      "input_captions: ['flower pot .']\n",
      "Pred Count: 67, GT Count: 69\n",
      "Test:  [1240/1286]  eta: 0:01:05    time: 1.0505  data: 0.0079  max mem: 7549\n",
      "input_captions: ['flower pot .']\n",
      "Pred Count: 49, GT Count: 49\n",
      "input_captions: ['flower pot .']\n",
      "Pred Count: 85, GT Count: 76\n",
      "input_captions: ['flower pot .']\n",
      "Pred Count: 88, GT Count: 68\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 146, GT Count: 144\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 150, GT Count: 150\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 32, GT Count: 30\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 87, GT Count: 84\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 136, GT Count: 138\n",
      "input_captions: ['bottle cap .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 477, GT Count: 452\n",
      "input_captions: ['bottle cap .']\n",
      "Pred Count: 277, GT Count: 274\n",
      "Test:  [1250/1286]  eta: 0:00:51    time: 1.0995  data: 0.0071  max mem: 7549\n",
      "input_captions: ['flower pot .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['flower pot .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['flower pot .']\n",
      "Pred Count: 24, GT Count: 23\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 135, GT Count: 135\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 197, GT Count: 193\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 129, GT Count: 139\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 289, GT Count: 283\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 201, GT Count: 198\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 96, GT Count: 93\n",
      "input_captions: ['milk carton .']\n",
      "Pred Count: 29, GT Count: 27\n",
      "Test:  [1260/1286]  eta: 0:00:37    time: 1.0326  data: 0.0064  max mem: 7549\n",
      "input_captions: ['milk carton .']\n",
      "Pred Count: 55, GT Count: 69\n",
      "input_captions: ['milk carton .']\n",
      "Pred Count: 78, GT Count: 71\n",
      "input_captions: ['milk carton .']\n",
      "Pred Count: 184, GT Count: 185\n",
      "input_captions: ['milk carton .']\n",
      "Pred Count: 140, GT Count: 134\n",
      "input_captions: ['milk carton .']\n",
      "Pred Count: 74, GT Count: 68\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 123, GT Count: 118\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 117, GT Count: 111\n",
      "input_captions: ['pill .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 76, GT Count: 74\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 78, GT Count: 65\n",
      "input_captions: ['pill .']\n",
      "Pred Count: 27, GT Count: 27\n",
      "Test:  [1270/1286]  eta: 0:00:22    time: 1.2497  data: 0.0062  max mem: 7549\n",
      "input_captions: ['book .']\n",
      "Pred Count: 26, GT Count: 26\n",
      "input_captions: ['book .']\n",
      "Pred Count: 87, GT Count: 80\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 58, GT Count: 69\n",
      "input_captions: ['book .']\n",
      "Pred Count: 117, GT Count: 116\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 166, GT Count: 162\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 104, GT Count: 100\n",
      "input_captions: ['book .']\n",
      "Pred Count: 107, GT Count: 99\n",
      "input_captions: ['book .']\n",
      "Pred Count: 55, GT Count: 49\n",
      "input_captions: ['book .']\n",
      "Pred Count: 27, GT Count: 26\n",
      "input_captions: ['book .']\n",
      "Pred Count: 84, GT Count: 83\n",
      "Test:  [1280/1286]  eta: 0:00:08    time: 1.5785  data: 0.0069  max mem: 7549\n",
      "input_captions: ['book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 66, GT Count: 65\n",
      "input_captions: ['book .']\n",
      "Pred Count: 20, GT Count: 21\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 95, GT Count: 87\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 46, GT Count: 44\n",
      "input_captions: ['bird .']\n",
      "Pred Count: 93, GT Count: 92\n",
      "Test:  [1285/1286]  eta: 0:00:01    time: 1.6317  data: 0.0070  max mem: 7549\n",
      "Test: Total time: 0:30:34 (1.4266 s / it)\n",
      "# of Images Tested: 1286\n",
      "MAE: 8.37982680262086, RMSE: 43.90064269746818\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=6 torchrun --nproc_per_node=1 --master_port=29501 main_inference.py --output_dir ./gdino_val \\\n",
    "-c config/cfg_fsc147_val.py --eval --datasets config/datasets_fsc147_val.json \\\n",
    "--pretrain_model_path ./gdino_train/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased \\\n",
    "--sam_tt_norm --remove_bad_exemplar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34869a74-a10e-42f3-9014-667104664138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "world size: 1, rank: 0, local rank: 0\n",
      "{\n",
      "  \"CUDA_VISIBLE_DEVICES\": \"6\",\n",
      "  \"SHELL\": \"/bin/bash\",\n",
      "  \"CONDA_EXE\": \"/opt/miniconda/bin/conda\",\n",
      "  \"_CE_M\": \"\",\n",
      "  \"TMUX\": \"/tmp/tmux-1010/default,192425,0\",\n",
      "  \"PWD\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced_CountGD\",\n",
      "  \"LOGNAME\": \"renaldy_fredyan\",\n",
      "  \"CONDA_PREFIX\": \"/opt/miniconda/envs/Rey1\",\n",
      "  \"JPY_SESSION_NAME\": \"/home/renaldy_fredyan/PhDResearch/CountGD/Reproduced_CountGD/Reproduced.ipynb\",\n",
      "  \"_\": \"/opt/miniconda/envs/Rey1/bin/torchrun\",\n",
      "  \"MOTD_SHOWN\": \"pam\",\n",
      "  \"HOME\": \"/home/renaldy_fredyan\",\n",
      "  \"LANG\": \"en_US.UTF-8\",\n",
      "  \"LS_COLORS\": \"rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:\",\n",
      "  \"FORCE_COLOR\": \"1\",\n",
      "  \"CONDA_PROMPT_MODIFIER\": \"(Rey1) \",\n",
      "  \"PYDEVD_USE_FRAME_EVAL\": \"NO\",\n",
      "  \"CLICOLOR\": \"1\",\n",
      "  \"CLICOLOR_FORCE\": \"1\",\n",
      "  \"SSH_CONNECTION\": \"140.118.155.218 56934 140.118.125.208 6809\",\n",
      "  \"JPY_PARENT_PID\": \"192484\",\n",
      "  \"LESSCLOSE\": \"/usr/bin/lesspipe %s %s\",\n",
      "  \"TERM\": \"xterm-color\",\n",
      "  \"_CE_CONDA\": \"\",\n",
      "  \"LESSOPEN\": \"| /usr/bin/lesspipe %s\",\n",
      "  \"USER\": \"renaldy_fredyan\",\n",
      "  \"GIT_PAGER\": \"cat\",\n",
      "  \"TMUX_PANE\": \"%0\",\n",
      "  \"CONDA_SHLVL\": \"1\",\n",
      "  \"SHLVL\": \"2\",\n",
      "  \"PAGER\": \"cat\",\n",
      "  \"MPLBACKEND\": \"module://matplotlib_inline.backend_inline\",\n",
      "  \"CONDA_PYTHON_EXE\": \"/opt/miniconda/bin/python\",\n",
      "  \"SSH_CLIENT\": \"140.118.155.218 56934 6809\",\n",
      "  \"CONDA_DEFAULT_ENV\": \"Rey1\",\n",
      "  \"XDG_DATA_DIRS\": \"/usr/local/share:/usr/share:/var/lib/snapd/desktop\",\n",
      "  \"PATH\": \"/opt/miniconda/envs/Rey1/bin:/opt/miniconda/bin:/opt/miniconda/condabin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\",\n",
      "  \"SSH_TTY\": \"/dev/pts/5\",\n",
      "  \"LOCAL_RANK\": \"0\",\n",
      "  \"RANK\": \"0\",\n",
      "  \"GROUP_RANK\": \"0\",\n",
      "  \"ROLE_RANK\": \"0\",\n",
      "  \"ROLE_NAME\": \"default\",\n",
      "  \"LOCAL_WORLD_SIZE\": \"1\",\n",
      "  \"WORLD_SIZE\": \"1\",\n",
      "  \"GROUP_WORLD_SIZE\": \"1\",\n",
      "  \"ROLE_WORLD_SIZE\": \"1\",\n",
      "  \"MASTER_ADDR\": \"127.0.0.1\",\n",
      "  \"MASTER_PORT\": \"29501\",\n",
      "  \"TORCHELASTIC_RESTART_COUNT\": \"0\",\n",
      "  \"TORCHELASTIC_MAX_RESTARTS\": \"0\",\n",
      "  \"TORCHELASTIC_RUN_ID\": \"none\",\n",
      "  \"TORCHELASTIC_USE_AGENT_STORE\": \"True\",\n",
      "  \"NCCL_ASYNC_ERROR_HANDLING\": \"1\",\n",
      "  \"TORCHELASTIC_ERROR_FILE\": \"/tmp/torchelastic_mc2nnyya/none_c1c_y6rt/attempt_0/0/error.json\",\n",
      "  \"QT_QPA_PLATFORM_PLUGIN_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/plugins\",\n",
      "  \"QT_QPA_FONTDIR\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/qt/fonts\",\n",
      "  \"LD_LIBRARY_PATH\": \"/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/cv2/../../lib64:\"\n",
      "}\n",
      "  == distributed init (rank 0) done.\n",
      "Loading config file from config/cfg_fsc147_test.py\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:58:43,190 | \u001b[34mgit:\n",
      "  sha: 96d581309f1ba5850906cd5602659a930ef690a1, status: has uncommited changes, branch: main\n",
      "\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:58:43,192 | \u001b[34mCommand: main_inference.py --output_dir ./gdino_test -c config/cfg_fsc147_test.py --eval --datasets config/datasets_fsc147_test.json --pretrain_model_path ./gdino_train/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased --sam_tt_norm --remove_bad_exemplar\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:58:43,194 | \u001b[34mFull config saved to ./gdino_test/config_args_all.json\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:58:43,195 | \u001b[34mworld size: 1\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:58:43,195 | \u001b[34mrank: 0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:58:43,195 | \u001b[34mlocal_rank: 0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:58:43,196 | \u001b[34margs: Namespace(config_file='config/cfg_fsc147_test.py', options={'text_encoder_type': 'checkpoints/bert-base-uncased'}, datasets='config/datasets_fsc147_test.json', no_text=False, num_exemplars=3, remove_difficult=False, fix_size=False, train_with_exemplar_only=False, output_dir='./gdino_test', note='', device='cuda', seed=42, resume='', pretrain_model_path='./gdino_train/checkpoint_best_regular.pth', finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, modality_dropout=False, sam_tt_norm=True, sam_model_path='./checkpoints/sam_vit_h_4b8939.pth', exemp_tt_norm=False, crop=False, simple_crop=False, remove_bad_exemplar=True, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, gpu=0, distributed=True, dist_backend='nccl', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_B_384_22k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='checkpoints/bert-base-uncased', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=90, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['backbone.0', 'bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=30, lr_drop=10, save_checkpoint_interval=10, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[10, 20], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=900, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=5.0, set_cost_bbox=1.0, set_cost_giou=0.0, cls_loss_coef=5.0, bbox_loss_coef=1.0, giou_loss_coef=0.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, box_threshold=0.23, text_threshold=0, use_coco_eval=False, label_list=['alcohol bottle', 'baguette roll', 'ball', 'banana', 'bead', 'bee', 'birthday candle', 'biscuit', 'boat', 'bottle', 'bowl', 'box', 'bread roll', 'brick', 'buffalo', 'bun', 'calamari ring', 'can', 'candle', 'cap', 'car', 'cartridge', 'cassette', 'cement bag', 'cereal', 'chewing gum piece', 'chopstick', 'clam', 'coffee bean', 'coin', 'cotton ball', 'cow', 'crane', 'crayon', 'croissant', 'crow', 'cup', 'cupcake', 'cupcake holder', 'fish', 'gemstone', 'go game piece', 'goat', 'goldfish snack', 'goose', 'ice cream', 'ice cream cone', 'instant noodle', 'jade stone', 'jeans', 'kidney bean', 'kitchen towel', 'lighter', 'lipstick', 'm&m piece', 'macaron', 'match', 'meat skewer', 'mini blind', 'mosaic tile', 'naan bread', 'nail', 'nut', 'onion ring', 'orange', 'pearl', 'pen', 'pencil', 'penguin', 'pepper', 'person', 'pigeon', 'plate', 'polka dot tile', 'potato', 'rice bag', 'roof tile', 'screw', 'shoe', 'spoon', 'spring roll', 'stair', 'stapler pin', 'straw', 'supermarket shelf', 'swan', 'tomato', 'watermelon', 'window', 'zebra'], val_label_list=['apple', 'candy piece', 'carrom board piece', 'cashew nut', 'comic book', 'crab cake', 'deer', 'egg', 'elephant', 'finger food', 'green pea', 'hot air balloon', 'keyboard key', 'lego', 'marble', 'marker', 'nail polish', 'potato chip', 'red bean', 'round dessert', 'sauce bottle', 'sea shell', 'sheep', 'ski', 'stamp', 'sticky note', 'strawberry', 'sunglasses', 'tree log', 'watch', 'yellow lego stud'])\n",
      "\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-18 16:58:43,197 | \u001b[34mbuild model ... ...\u001b[0m\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755849709/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "final text_encoder_type: checkpoints/bert-base-uncased\n",
      "load tokenizer done.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at checkpoints/bert-base-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "final text_encoder_type: checkpoints/bert-base-uncased\n",
      "load tokenizer done.\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-18 16:58:45,633 | \u001b[34mbuild model, done.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:58:45,678 | \u001b[34mnumber of params:232772224\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:58:45,682 | \u001b[34mparams before freezing:\n",
      "{\n",
      "  \"module.transformer.level_embed\": 1024,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.norm.weight\": 256,\n",
      "  \"module.transformer.decoder.norm.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
      "  \"module.transformer.tgt_embed.weight\": 230400,\n",
      "  \"module.transformer.enc_output.weight\": 65536,\n",
      "  \"module.transformer.enc_output.bias\": 256,\n",
      "  \"module.transformer.enc_output_norm.weight\": 256,\n",
      "  \"module.transformer.enc_output_norm.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
      "  \"module.feature_map_proj.weight\": 458752,\n",
      "  \"module.feature_map_proj.bias\": 256,\n",
      "  \"module.bert.embeddings.word_embeddings.weight\": 23440896,\n",
      "  \"module.bert.embeddings.position_embeddings.weight\": 393216,\n",
      "  \"module.bert.embeddings.token_type_embeddings.weight\": 1536,\n",
      "  \"module.bert.embeddings.LayerNorm.weight\": 768,\n",
      "  \"module.bert.embeddings.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.0.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.0.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.0.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.0.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.0.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.0.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.0.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.1.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.1.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.1.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.1.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.1.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.1.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.1.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.2.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.2.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.2.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.2.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.2.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.2.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.2.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.3.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.3.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.3.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.3.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.3.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.3.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.3.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.4.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.4.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.4.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.4.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.4.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.4.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.4.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.5.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.5.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.5.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.5.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.5.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.5.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.5.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.6.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.6.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.6.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.6.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.6.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.6.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.6.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.7.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.7.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.7.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.7.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.7.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.7.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.7.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.8.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.8.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.8.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.8.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.8.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.8.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.8.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.9.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.9.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.9.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.9.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.9.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.9.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.9.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.10.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.10.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.10.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.10.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.10.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.10.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.10.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.query.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.query.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.key.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.key.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.self.value.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.self.value.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.dense.weight\": 589824,\n",
      "  \"module.bert.encoder.layer.11.attention.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.11.attention.output.LayerNorm.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.intermediate.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.11.intermediate.dense.bias\": 3072,\n",
      "  \"module.bert.encoder.layer.11.output.dense.weight\": 2359296,\n",
      "  \"module.bert.encoder.layer.11.output.dense.bias\": 768,\n",
      "  \"module.bert.encoder.layer.11.output.LayerNorm.weight\": 768,\n",
      "  \"module.bert.encoder.layer.11.output.LayerNorm.bias\": 768,\n",
      "  \"module.feat_map.weight\": 196608,\n",
      "  \"module.feat_map.bias\": 256,\n",
      "  \"module.input_proj.0.0.weight\": 65536,\n",
      "  \"module.input_proj.0.0.bias\": 256,\n",
      "  \"module.input_proj.0.1.weight\": 256,\n",
      "  \"module.input_proj.0.1.bias\": 256,\n",
      "  \"module.input_proj.1.0.weight\": 131072,\n",
      "  \"module.input_proj.1.0.bias\": 256,\n",
      "  \"module.input_proj.1.1.weight\": 256,\n",
      "  \"module.input_proj.1.1.bias\": 256,\n",
      "  \"module.input_proj.2.0.weight\": 262144,\n",
      "  \"module.input_proj.2.0.bias\": 256,\n",
      "  \"module.input_proj.2.1.weight\": 256,\n",
      "  \"module.input_proj.2.1.bias\": 256,\n",
      "  \"module.input_proj.3.0.weight\": 2359296,\n",
      "  \"module.input_proj.3.0.bias\": 256,\n",
      "  \"module.input_proj.3.1.weight\": 256,\n",
      "  \"module.input_proj.3.1.bias\": 256,\n",
      "  \"module.backbone.0.patch_embed.proj.weight\": 6144,\n",
      "  \"module.backbone.0.patch_embed.proj.bias\": 128,\n",
      "  \"module.backbone.0.patch_embed.norm.weight\": 128,\n",
      "  \"module.backbone.0.patch_embed.norm.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm1.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm1.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.relative_position_bias_table\": 2116,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.qkv.weight\": 49152,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.qkv.bias\": 384,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.proj.weight\": 16384,\n",
      "  \"module.backbone.0.layers.0.blocks.0.attn.proj.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm2.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.norm2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc1.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc1.bias\": 512,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc2.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.0.mlp.fc2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm1.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm1.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.relative_position_bias_table\": 2116,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.qkv.weight\": 49152,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.qkv.bias\": 384,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.proj.weight\": 16384,\n",
      "  \"module.backbone.0.layers.0.blocks.1.attn.proj.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm2.weight\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.norm2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc1.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc1.bias\": 512,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc2.weight\": 65536,\n",
      "  \"module.backbone.0.layers.0.blocks.1.mlp.fc2.bias\": 128,\n",
      "  \"module.backbone.0.layers.0.downsample.reduction.weight\": 131072,\n",
      "  \"module.backbone.0.layers.0.downsample.norm.weight\": 512,\n",
      "  \"module.backbone.0.layers.0.downsample.norm.bias\": 512,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm1.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm1.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.relative_position_bias_table\": 4232,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.qkv.weight\": 196608,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.qkv.bias\": 768,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.proj.weight\": 65536,\n",
      "  \"module.backbone.0.layers.1.blocks.0.attn.proj.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm2.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.norm2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc1.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc2.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.0.mlp.fc2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm1.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm1.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.relative_position_bias_table\": 4232,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.qkv.weight\": 196608,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.qkv.bias\": 768,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.proj.weight\": 65536,\n",
      "  \"module.backbone.0.layers.1.blocks.1.attn.proj.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm2.weight\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.norm2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc1.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc2.weight\": 262144,\n",
      "  \"module.backbone.0.layers.1.blocks.1.mlp.fc2.bias\": 256,\n",
      "  \"module.backbone.0.layers.1.downsample.reduction.weight\": 524288,\n",
      "  \"module.backbone.0.layers.1.downsample.norm.weight\": 1024,\n",
      "  \"module.backbone.0.layers.1.downsample.norm.bias\": 1024,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.0.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.0.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.1.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.1.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.2.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.2.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.3.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.3.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.4.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.4.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.5.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.5.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.6.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.6.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.7.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.7.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.8.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.8.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.9.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.9.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.10.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.10.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.11.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.11.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.12.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.12.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.13.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.13.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.14.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.14.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.15.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.15.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.16.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.16.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm1.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm1.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.relative_position_bias_table\": 8464,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.qkv.weight\": 786432,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.qkv.bias\": 1536,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.proj.weight\": 262144,\n",
      "  \"module.backbone.0.layers.2.blocks.17.attn.proj.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm2.weight\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.norm2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc1.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc1.bias\": 2048,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc2.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.2.blocks.17.mlp.fc2.bias\": 512,\n",
      "  \"module.backbone.0.layers.2.downsample.reduction.weight\": 2097152,\n",
      "  \"module.backbone.0.layers.2.downsample.norm.weight\": 2048,\n",
      "  \"module.backbone.0.layers.2.downsample.norm.bias\": 2048,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm1.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.relative_position_bias_table\": 16928,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.qkv.weight\": 3145728,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.qkv.bias\": 3072,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.proj.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.3.blocks.0.attn.proj.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm2.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.norm2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc1.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc1.bias\": 4096,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc2.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.0.mlp.fc2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm1.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm1.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.relative_position_bias_table\": 16928,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.qkv.weight\": 3145728,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.qkv.bias\": 3072,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.proj.weight\": 1048576,\n",
      "  \"module.backbone.0.layers.3.blocks.1.attn.proj.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm2.weight\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.norm2.bias\": 1024,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc1.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc1.bias\": 4096,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc2.weight\": 4194304,\n",
      "  \"module.backbone.0.layers.3.blocks.1.mlp.fc2.bias\": 1024,\n",
      "  \"module.backbone.0.norm1.weight\": 256,\n",
      "  \"module.backbone.0.norm1.bias\": 256,\n",
      "  \"module.backbone.0.norm2.weight\": 512,\n",
      "  \"module.backbone.0.norm2.bias\": 512,\n",
      "  \"module.backbone.0.norm3.weight\": 1024,\n",
      "  \"module.backbone.0.norm3.bias\": 1024\n",
      "}\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:58:45,705 | \u001b[34mparams after freezing:\n",
      "{\n",
      "  \"module.transformer.level_embed\": 1024,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm1.bias\": 256,\n",
      "former.encoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.encoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.encoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.encoder.text_layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear1.bias\": 1024,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.weight\": 262144,\n",
      "  \"module.transformer.encoder.text_layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.encoder.text_layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.0.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.1.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.2.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.3.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.4.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_v\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.gamma_l\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_v.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.weight\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.layer_norm_l.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_v_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.values_l_proj.bias\": 1024,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_v_proj.bias\": 256,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.weight\": 262144,\n",
      "  \"module.transformer.encoder.fusion_layers.5.attn.out_l_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.0.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.0.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.0.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.1.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.1.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.1.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.2.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.2.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.2.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.3.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.3.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.3.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.4.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.4.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.4.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm1.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.ca_text.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.catext_norm.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n",
      "  \"module.transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.linear1.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear1.bias\": 2048,\n",
      "  \"module.transformer.decoder.layers.5.linear2.weight\": 524288,\n",
      "  \"module.transformer.decoder.layers.5.linear2.bias\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.weight\": 256,\n",
      "  \"module.transformer.decoder.layers.5.norm3.bias\": 256,\n",
      "  \"module.transformer.decoder.norm.weight\": 256,\n",
      "  \"module.transformer.decoder.norm.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.ref_point_head.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n",
      "  \"module.transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n",
      "  \"module.transformer.tgt_embed.weight\": 230400,\n",
      "  \"module.transformer.enc_output.weight\": 65536,\n",
      "  \"module.transformer.enc_output.bias\": 256,\n",
      "  \"module.transformer.enc_output_norm.weight\": 256,\n",
      "  \"module.transformer.enc_output_norm.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n",
      "  \"module.transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n",
      "  \"module.feature_map_proj.weight\": 458752,\n",
      "  \"module.feature_map_proj.bias\": 256,\n",
      "  \"module.feat_map.weight\": 196608,\n",
      "  \"module.feat_map.bias\": 256,\n",
      "  \"module.input_proj.0.0.weight\": 65536,\n",
      "  \"module.input_proj.0.0.bias\": 256,\n",
      "  \"module.input_proj.0.1.weight\": 256,\n",
      "  \"module.input_proj.0.1.bias\": 256,\n",
      "  \"module.input_proj.1.0.weight\": 131072,\n",
      "  \"module.input_proj.1.0.bias\": 256,\n",
      "  \"module.input_proj.1.1.weight\": 256,\n",
      "  \"module.input_proj.1.1.bias\": 256,\n",
      "  \"module.input_proj.2.0.weight\": 262144,\n",
      "  \"module.input_proj.2.0.bias\": 256,\n",
      "  \"module.input_proj.2.1.weight\": 256,\n",
      "  \"module.input_proj.2.1.bias\": 256,\n",
      "  \"module.input_proj.3.0.weight\": 2359296,\n",
      "  \"module.input_proj.3.0.bias\": 256,\n",
      "  \"module.input_proj.3.1.weight\": 256,\n",
      "  \"module.input_proj.3.1.bias\": 256\n",
      "}\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[36m2025-01-18 16:58:45,714 | \u001b[34mbuild dataset ... ...\u001b[0m\n",
      "/home/renaldy_fredyan/PhDResearch/LOCA/Dataset/images_384_VarV2 ./data/fsc147_gdino/fsc147_coco/coco_test_exemplars.json\n",
      "max(scales): 800\n",
      "loading annotations into memory...\n",
      "Done (t=0.53s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:58:47,089 | \u001b[34mIgnore keys: []\u001b[0m\n",
      "_ignorekeywordlist: []\n",
      "\u001b[32mINFO    \u001b[0m \u001b[32m2025-01-18 16:58:47,525 | \u001b[34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['feature_map_encoder.layers.0.norm1.weight', 'feature_map_encoder.layers.0.norm1.bias', 'feature_map_encoder.layers.0.norm2.weight', 'feature_map_encoder.layers.0.norm2.bias', 'feature_map_encoder.layers.0.self_attn.in_proj_weight', 'feature_map_encoder.layers.0.self_attn.in_proj_bias', 'feature_map_encoder.layers.0.self_attn.out_proj.weight', 'feature_map_encoder.layers.0.self_attn.out_proj.bias', 'feature_map_encoder.layers.0.mlp.linear1.weight', 'feature_map_encoder.layers.0.mlp.linear1.bias', 'feature_map_encoder.layers.0.mlp.linear2.weight', 'feature_map_encoder.layers.0.mlp.linear2.bias', 'feature_map_encoder.layers.1.norm1.weight', 'feature_map_encoder.layers.1.norm1.bias', 'feature_map_encoder.layers.1.norm2.weight', 'feature_map_encoder.layers.1.norm2.bias', 'feature_map_encoder.layers.1.self_attn.in_proj_weight', 'feature_map_encoder.layers.1.self_attn.in_proj_bias', 'feature_map_encoder.layers.1.self_attn.out_proj.weight', 'feature_map_encoder.layers.1.self_attn.out_proj.bias', 'feature_map_encoder.layers.1.mlp.linear1.weight', 'feature_map_encoder.layers.1.mlp.linear1.bias', 'feature_map_encoder.layers.1.mlp.linear2.weight', 'feature_map_encoder.layers.1.mlp.linear2.bias', 'feature_map_encoder.layers.2.norm1.weight', 'feature_map_encoder.layers.2.norm1.bias', 'feature_map_encoder.layers.2.norm2.weight', 'feature_map_encoder.layers.2.norm2.bias', 'feature_map_encoder.layers.2.self_attn.in_proj_weight', 'feature_map_encoder.layers.2.self_attn.in_proj_bias', 'feature_map_encoder.layers.2.self_attn.out_proj.weight', 'feature_map_encoder.layers.2.self_attn.out_proj.bias', 'feature_map_encoder.layers.2.mlp.linear1.weight', 'feature_map_encoder.layers.2.mlp.linear1.bias', 'feature_map_encoder.layers.2.mlp.linear2.weight', 'feature_map_encoder.layers.2.mlp.linear2.bias', 'feature_map_encoder.norm.weight', 'feature_map_encoder.norm.bias', 'bert.embeddings.position_ids'])\u001b[0m\n",
      "Input text prompt: apple . candy piece . carrom board piece . cashew nut . comic book . crab cake . deer . egg . elephant . finger food . green pea . hot air balloon . keyboard key . lego . marble . marker . nail polish . potato chip . red bean . round dessert . sauce bottle . sea shell . sheep . ski . stamp . sticky note . strawberry . sunglasses . tree log . watch . yellow lego stud .\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "input_captions: ['sea shell .']\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/transformers/modeling_utils.py:977: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/Rey1/lib/python3.9/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "Pred Count: 8, GT Count: 8\n",
      "Test:  [   0/1190]  eta: 1:06:57    time: 3.3756  data: 1.7430  max mem: 7549\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 11, GT Count: 10\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 110, GT Count: 113\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 8, GT Count: 9\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 28, GT Count: 28\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 20, GT Count: 21\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 30, GT Count: 26\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 27, GT Count: 26\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 14, GT Count: 13\n",
      "Test:  [  10/1190]  eta: 0:37:08    time: 1.8884  data: 0.1683  max mem: 7549\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 30, GT Count: 32\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 47, GT Count: 41\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 125, GT Count: 124\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 60, GT Count: 64\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 31, GT Count: 30\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 33, GT Count: 33\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 21, GT Count: 16\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 33, GT Count: 33\n",
      "Test:  [  20/1190]  eta: 0:31:58    time: 1.5525  data: 0.0105  max mem: 7549\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 31, GT Count: 28\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 22, GT Count: 20\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 52, GT Count: 51\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 29, GT Count: 30\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 22, GT Count: 21\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 27, GT Count: 27\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 100, GT Count: 113\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 73, GT Count: 65\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 56, GT Count: 55\n",
      "Test:  [  30/1190]  eta: 0:30:00    time: 1.3673  data: 0.0101  max mem: 7549\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 52, GT Count: 53\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 22, GT Count: 23\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 61, GT Count: 53\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 28, GT Count: 25\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 40, GT Count: 39\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 24, GT Count: 27\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "Test:  [  40/1190]  eta: 0:34:04    time: 1.9226  data: 0.0100  max mem: 7549\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 10, GT Count: 11\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 35, GT Count: 33\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 36, GT Count: 35\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 32, GT Count: 33\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 10, GT Count: 11\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 32, GT Count: 32\n",
      "Test:  [  50/1190]  eta: 0:31:26    time: 1.8137  data: 0.0096  max mem: 7549\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 35, GT Count: 35\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 24, GT Count: 16\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 60, GT Count: 63\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 29, GT Count: 16\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 42, GT Count: 43\n",
      "Test:  [  60/1190]  eta: 0:29:29    time: 1.1334  data: 0.0091  max mem: 7549\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 69, GT Count: 63\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 42, GT Count: 41\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 30, GT Count: 27\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 42, GT Count: 39\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 45, GT Count: 41\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['watch .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['watch .']\n",
      "Pred Count: 16, GT Count: 14\n",
      "Test:  [  70/1190]  eta: 0:27:43    time: 1.0533  data: 0.0083  max mem: 7549\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 98, GT Count: 86\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 50, GT Count: 47\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 635, GT Count: 548\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 66, GT Count: 63\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 108, GT Count: 109\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 95, GT Count: 80\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 12, GT Count: 11\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 53, GT Count: 52\n",
      "Test:  [  80/1190]  eta: 0:26:58    time: 1.1291  data: 0.0083  max mem: 7549\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 175, GT Count: 154\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 76, GT Count: 60\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 67, GT Count: 65\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 50, GT Count: 44\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 71, GT Count: 59\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 49, GT Count: 46\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 85, GT Count: 90\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 17, GT Count: 15\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 141, GT Count: 132\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "Test:  [  90/1190]  eta: 0:27:50    time: 1.6377  data: 0.0091  max mem: 7549\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 31, GT Count: 27\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 70, GT Count: 67\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 26, GT Count: 24\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 102, GT Count: 100\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 20, GT Count: 21\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 193, GT Count: 182\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 17, GT Count: 12\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 40, GT Count: 44\n",
      "Test:  [ 100/1190]  eta: 0:27:38    time: 1.7757  data: 0.0083  max mem: 7549\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 241, GT Count: 235\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 32, GT Count: 29\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 44, GT Count: 62\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['comic book .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 131\n",
      "new count: 78.6\n",
      "Pred Count: 78.6, GT Count: 85\n",
      "input_captions: ['watch .']\n",
      "Pred Count: 80, GT Count: 53\n",
      "input_captions: ['watch .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['watch .']\n",
      "Pred Count: 68, GT Count: 69\n",
      "input_captions: ['watch .']\n",
      "Pred Count: 97, GT Count: 111\n",
      "input_captions: ['watch .']\n",
      "Pred Count: 106, GT Count: 93\n",
      "Test:  [ 110/1190]  eta: 0:27:37    time: 1.6073  data: 0.0074  max mem: 7550\n",
      "input_captions: ['watch .']\n",
      "Pred Count: 16, GT Count: 17\n",
      "input_captions: ['watch .']\n",
      "Pred Count: 21, GT Count: 20\n",
      "input_captions: ['watch .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['watch .']\n",
      "Pred Count: 25, GT Count: 24\n",
      "input_captions: ['watch .']\n",
      "Pred Count: 16, GT Count: 14\n",
      "input_captions: ['sheep .']\n",
      "Pred Count: 132, GT Count: 136\n",
      "input_captions: ['sheep .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 222, GT Count: 207\n",
      "input_captions: ['sheep .']\n",
      "Pred Count: 28, GT Count: 22\n",
      "input_captions: ['marker .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 69, GT Count: 49\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 900, GT Count: 3701\n",
      "Test:  [ 120/1190]  eta: 0:26:52    time: 1.4365  data: 0.0093  max mem: 7550\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 50, GT Count: 61\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 64, GT Count: 63\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 184, GT Count: 184\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 176, GT Count: 162\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 101, GT Count: 99\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 420, GT Count: 409\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 61, GT Count: 60\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 58, GT Count: 59\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 76, GT Count: 70\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 70, GT Count: 67\n",
      "Test:  [ 130/1190]  eta: 0:25:55    time: 1.0931  data: 0.0093  max mem: 7550\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 209, GT Count: 207\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 45, GT Count: 50\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 115, GT Count: 110\n",
      "input_captions: ['carrom board piece .']\n",
      "Pred Count: 12, GT Count: 25\n",
      "input_captions: ['elephant .']\n",
      "Pred Count: 11, GT Count: 12\n",
      "input_captions: ['elephant .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 14, GT Count: 11\n",
      "input_captions: ['elephant .']\n",
      "Pred Count: 59, GT Count: 54\n",
      "input_captions: ['elephant .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 13, GT Count: 11\n",
      "input_captions: ['elephant .']\n",
      "Pred Count: 13, GT Count: 16\n",
      "input_captions: ['elephant .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 16, GT Count: 12\n",
      "Test:  [ 140/1190]  eta: 0:25:25    time: 1.1250  data: 0.0076  max mem: 7550\n",
      "input_captions: ['elephant .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['elephant .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['elephant .']\n",
      "Pred Count: 19, GT Count: 17\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 409\n",
      "new count: 153.375\n",
      "Pred Count: 153.375, GT Count: 226\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 260\n",
      "new count: 130.0\n",
      "Pred Count: 130.0, GT Count: 140\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 155\n",
      "new count: 77.5\n",
      "Pred Count: 77.5, GT Count: 108\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 86\n",
      "new count: 43.0\n",
      "Pred Count: 43.0, GT Count: 42\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 375\n",
      "new count: 187.5\n",
      "Pred Count: 187.5, GT Count: 198\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 26\n",
      "new count: 15.6\n",
      "Pred Count: 15.6, GT Count: 15\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 146\n",
      "new count: 73.0\n",
      "Pred Count: 73.0, GT Count: 79\n",
      "Test:  [ 150/1190]  eta: 0:31:02    time: 3.9123  data: 0.0087  max mem: 7550\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 86, GT Count: 69\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 120\n",
      "new count: 72.0\n",
      "Pred Count: 72.0, GT Count: 49\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 27\n",
      "new count: 13.5\n",
      "Pred Count: 13.5, GT Count: 18\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 44\n",
      "new count: 22.0\n",
      "Pred Count: 22.0, GT Count: 25\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 49\n",
      "new count: 24.5\n",
      "Pred Count: 24.5, GT Count: 24\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 144\n",
      "new count: 86.39999999999999\n",
      "Pred Count: 86.39999999999999, GT Count: 104\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 135\n",
      "new count: 50.625\n",
      "Pred Count: 50.625, GT Count: 68\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 29\n",
      "new count: 14.5\n",
      "Pred Count: 14.5, GT Count: 14\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 58\n",
      "new count: 43.5\n",
      "Pred Count: 43.5, GT Count: 36\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 66\n",
      "new count: 39.6\n",
      "Pred Count: 39.6, GT Count: 44\n",
      "Test:  [ 160/1190]  eta: 0:35:47    time: 6.5385  data: 0.0089  max mem: 7550\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 104\n",
      "new count: 52.0\n",
      "Pred Count: 52.0, GT Count: 60\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 33\n",
      "new count: 16.5\n",
      "Pred Count: 16.5, GT Count: 16\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 36\n",
      "new count: 21.599999999999998\n",
      "Pred Count: 21.599999999999998, GT Count: 23\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 30, GT Count: 19\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 136\n",
      "new count: 68.0\n",
      "Pred Count: 68.0, GT Count: 79\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 53\n",
      "new count: 31.799999999999997\n",
      "Pred Count: 31.799999999999997, GT Count: 29\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 53, GT Count: 31\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 23\n",
      "new count: 11.5\n",
      "Pred Count: 11.5, GT Count: 12\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 43\n",
      "new count: 18.428571428571427\n",
      "Pred Count: 18.428571428571427, GT Count: 20\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 55\n",
      "new count: 27.5\n",
      "Pred Count: 27.5, GT Count: 28\n",
      "Test:  [ 170/1190]  eta: 0:39:24    time: 6.2934  data: 0.0088  max mem: 7550\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 47\n",
      "new count: 23.5\n",
      "Pred Count: 23.5, GT Count: 27\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 163, GT Count: 134\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 377\n",
      "new count: 188.5\n",
      "Pred Count: 188.5, GT Count: 198\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 133\n",
      "new count: 66.5\n",
      "Pred Count: 66.5, GT Count: 81\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 46, GT Count: 32\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 176\n",
      "new count: 88.0\n",
      "Pred Count: 88.0, GT Count: 88\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 122\n",
      "new count: 73.2\n",
      "Pred Count: 73.2, GT Count: 81\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 126\n",
      "new count: 75.6\n",
      "Pred Count: 75.6, GT Count: 90\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 56\n",
      "new count: 28.0\n",
      "Pred Count: 28.0, GT Count: 27\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 36\n",
      "new count: 21.599999999999998\n",
      "Pred Count: 21.599999999999998, GT Count: 22\n",
      "Test:  [ 180/1190]  eta: 0:44:17    time: 7.0269  data: 0.0089  max mem: 7550\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 32, GT Count: 20\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 34\n",
      "new count: 20.4\n",
      "Pred Count: 20.4, GT Count: 30\n",
      "input_captions: ['sunglasses .']\n",
      "Pred Count: 58, GT Count: 43\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 144\n",
      "new count: 72.0\n",
      "Pred Count: 72.0, GT Count: 79\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 30\n",
      "new count: 15.0\n",
      "Pred Count: 15.0, GT Count: 15\n",
      "input_captions: ['sunglasses .']\n",
      "Pred Count: 7, GT Count: 8\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 90\n",
      "new count: 45.0\n",
      "Pred Count: 45.0, GT Count: 47\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 112\n",
      "new count: 67.2\n",
      "Pred Count: 67.2, GT Count: 63\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 34, GT Count: 29\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 56, GT Count: 61\n",
      "Test:  [ 190/1190]  eta: 0:45:01    time: 5.9799  data: 0.0077  max mem: 7550\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 38, GT Count: 35\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 15, GT Count: 14\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 26, GT Count: 23\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 46, GT Count: 37\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 22, GT Count: 22\n",
      "Test:  [ 200/1190]  eta: 0:44:46    time: 3.4606  data: 0.0072  max mem: 7550\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 17, GT Count: 18\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 76, GT Count: 68\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 116, GT Count: 116\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 711, GT Count: 621\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 28, GT Count: 34\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 23, GT Count: 23\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 108, GT Count: 119\n",
      "Test:  [ 210/1190]  eta: 0:43:33    time: 2.3413  data: 0.0069  max mem: 7550\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 188, GT Count: 175\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 148, GT Count: 147\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 105, GT Count: 86\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 186, GT Count: 169\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 44, GT Count: 41\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 117, GT Count: 91\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 58, GT Count: 73\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 35, GT Count: 27\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 13, GT Count: 10\n",
      "Test:  [ 220/1190]  eta: 0:43:22    time: 2.3773  data: 0.0062  max mem: 7550\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 232, GT Count: 223\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 38, GT Count: 39\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 42, GT Count: 33\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 25, GT Count: 23\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 49, GT Count: 42\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 27, GT Count: 24\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 35, GT Count: 32\n",
      "Test:  [ 230/1190]  eta: 0:43:19    time: 3.1316  data: 0.0067  max mem: 7550\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 40, GT Count: 38\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 14, GT Count: 13\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 98, GT Count: 90\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 28, GT Count: 27\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 19, GT Count: 13\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 102, GT Count: 99\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 22, GT Count: 22\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 102, GT Count: 88\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "Test:  [ 240/1190]  eta: 0:42:45    time: 2.8887  data: 0.0073  max mem: 7550\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 43, GT Count: 41\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 50, GT Count: 49\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 43, GT Count: 97\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 57, GT Count: 55\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 44, GT Count: 36\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 28, GT Count: 25\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 16, GT Count: 15\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 483, GT Count: 356\n",
      "Test:  [ 250/1190]  eta: 0:43:17    time: 3.4152  data: 0.0073  max mem: 7550\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 17, GT Count: 16\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 34, GT Count: 30\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 64, GT Count: 47\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 12, GT Count: 11\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 91, GT Count: 111\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 98, GT Count: 96\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 82, GT Count: 64\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 21, GT Count: 16\n",
      "Test:  [ 260/1190]  eta: 0:43:10    time: 3.8123  data: 0.0073  max mem: 7550\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 112, GT Count: 98\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 25, GT Count: 20\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 24, GT Count: 26\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 70, GT Count: 54\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 27, GT Count: 25\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 526, GT Count: 544\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 15, GT Count: 12\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 63, GT Count: 82\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 44, GT Count: 37\n",
      "Test:  [ 270/1190]  eta: 0:43:02    time: 3.3489  data: 0.0072  max mem: 7550\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 17, GT Count: 16\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 53, GT Count: 53\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 89, GT Count: 82\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 80, GT Count: 59\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 28, GT Count: 23\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 83, GT Count: 75\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 227, GT Count: 174\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 158, GT Count: 174\n",
      "Test:  [ 280/1190]  eta: 0:41:55    time: 2.4859  data: 0.0073  max mem: 7550\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 8, GT Count: 9\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 56, GT Count: 57\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 10, GT Count: 9\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 77, GT Count: 74\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 13, GT Count: 11\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 57, GT Count: 50\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 46, GT Count: 42\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 18, GT Count: 15\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 157, GT Count: 165\n",
      "Test:  [ 290/1190]  eta: 0:40:41    time: 1.4321  data: 0.0073  max mem: 7550\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 64, GT Count: 66\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 37, GT Count: 38\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 35, GT Count: 30\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 50, GT Count: 49\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 40, GT Count: 37\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 182, GT Count: 157\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 22, GT Count: 22\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 48, GT Count: 47\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 31, GT Count: 25\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 45, GT Count: 48\n",
      "Test:  [ 300/1190]  eta: 0:40:18    time: 2.0589  data: 0.0074  max mem: 7550\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 15, GT Count: 14\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 233, GT Count: 195\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 20, GT Count: 18\n",
      "input_captions: ['deer .']\n",
      "Pred Count: 35, GT Count: 36\n",
      "input_captions: ['deer .']\n",
      "Pred Count: 25, GT Count: 18\n",
      "input_captions: ['deer .']\n",
      "Pred Count: 25, GT Count: 28\n",
      "input_captions: ['deer .']\n",
      "Pred Count: 19, GT Count: 15\n",
      "input_captions: ['deer .']\n",
      "Pred Count: 19, GT Count: 20\n",
      "input_captions: ['deer .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 10, GT Count: 9\n",
      "input_captions: ['deer .']\n",
      "Pred Count: 41, GT Count: 41\n",
      "Test:  [ 310/1190]  eta: 0:39:08    time: 2.0389  data: 0.0078  max mem: 7550\n",
      "input_captions: ['deer .']\n",
      "Pred Count: 50, GT Count: 47\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 32, GT Count: 28\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 33, GT Count: 33\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 72, GT Count: 72\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 29, GT Count: 28\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 58, GT Count: 61\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 200, GT Count: 202\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "Test:  [ 320/1190]  eta: 0:37:56    time: 1.1046  data: 0.0081  max mem: 7550\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 26, GT Count: 25\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 18, GT Count: 13\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 27, GT Count: 27\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 77, GT Count: 86\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 55, GT Count: 54\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 69, GT Count: 65\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 50, GT Count: 49\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 25, GT Count: 45\n",
      "Test:  [ 330/1190]  eta: 0:36:49    time: 1.0164  data: 0.0090  max mem: 7550\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 80, GT Count: 77\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 60, GT Count: 60\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 48, GT Count: 43\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 45, GT Count: 45\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 58, GT Count: 56\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 15, GT Count: 13\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 23, GT Count: 23\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 76, GT Count: 78\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 10, GT Count: 9\n",
      "Test:  [ 340/1190]  eta: 0:35:44    time: 1.0160  data: 0.0089  max mem: 7550\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 52, GT Count: 52\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 29, GT Count: 29\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 69, GT Count: 68\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 37, GT Count: 36\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "Test:  [ 350/1190]  eta: 0:34:42    time: 0.9952  data: 0.0081  max mem: 7550\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 17, GT Count: 14\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 68, GT Count: 67\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 24, GT Count: 22\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 38, GT Count: 38\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 106, GT Count: 105\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['crab cake .']\n",
      "Pred Count: 19, GT Count: 20\n",
      "input_captions: ['crab cake .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 12, GT Count: 10\n",
      "input_captions: ['crab cake .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 26, GT Count: 24\n",
      "Test:  [ 360/1190]  eta: 0:33:51    time: 1.1766  data: 0.0090  max mem: 7550\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 55, GT Count: 47\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 48, GT Count: 45\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 65\n",
      "new count: 39.0\n",
      "Pred Count: 39.0, GT Count: 50\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 53, GT Count: 42\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 70, GT Count: 43\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 76, GT Count: 58\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 15, GT Count: 13\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['finger food .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 23, GT Count: 20\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "Test:  [ 370/1190]  eta: 0:33:21    time: 1.7728  data: 0.0085  max mem: 7550\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 22, GT Count: 21\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 23, GT Count: 23\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 35, GT Count: 31\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 37, GT Count: 37\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "Test:  [ 380/1190]  eta: 0:32:27    time: 1.6071  data: 0.0073  max mem: 7550\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 35, GT Count: 34\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 182, GT Count: 153\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 31, GT Count: 31\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 153, GT Count: 154\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 131, GT Count: 136\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 87, GT Count: 63\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 99, GT Count: 92\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 206, GT Count: 210\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 50, GT Count: 43\n",
      "Test:  [ 390/1190]  eta: 0:31:34    time: 1.0030  data: 0.0073  max mem: 7550\n",
      "input_captions: ['green pea .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 191, GT Count: 185\n",
      "input_captions: ['green pea .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 83, GT Count: 68\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 164, GT Count: 159\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 57, GT Count: 49\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 430, GT Count: 450\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['green pea .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 56, GT Count: 56\n",
      "input_captions: ['green pea .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 125, GT Count: 122\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 33, GT Count: 33\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 101, GT Count: 99\n",
      "Test:  [ 400/1190]  eta: 0:31:10    time: 1.6680  data: 0.0073  max mem: 7550\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 238, GT Count: 178\n",
      "input_captions: ['green pea .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 64, GT Count: 57\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 152, GT Count: 133\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 90, GT Count: 66\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 115, GT Count: 113\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 149, GT Count: 146\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 349, GT Count: 350\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 90, GT Count: 72\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 314, GT Count: 295\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 269, GT Count: 258\n",
      "Test:  [ 410/1190]  eta: 0:30:25    time: 1.7932  data: 0.0074  max mem: 7550\n",
      "input_captions: ['sea shell .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['sea shell .']\n",
      "Pred Count: 36, GT Count: 36\n",
      "input_captions: ['sea shell .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['crab cake .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['red bean .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 52, GT Count: 45\n",
      "input_captions: ['red bean .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 38, GT Count: 37\n",
      "input_captions: ['red bean .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 121, GT Count: 107\n",
      "input_captions: ['red bean .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 107, GT Count: 103\n",
      "input_captions: ['red bean .']\n",
      "Pred Count: 175, GT Count: 161\n",
      "input_captions: ['red bean .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 100, GT Count: 96\n",
      "Test:  [ 420/1190]  eta: 0:30:12    time: 2.0888  data: 0.0076  max mem: 7550\n",
      "input_captions: ['red bean .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 102, GT Count: 91\n",
      "input_captions: ['red bean .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['red bean .']\n",
      "Pred Count: 63, GT Count: 60\n",
      "input_captions: ['red bean .']\n",
      "Pred Count: 73, GT Count: 70\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 62\n",
      "new count: 37.199999999999996\n",
      "Pred Count: 37.199999999999996, GT Count: 59\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 14, GT Count: 13\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 62, GT Count: 60\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 76, GT Count: 87\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 42, GT Count: 35\n",
      "Test:  [ 430/1190]  eta: 0:30:06    time: 3.1438  data: 0.0078  max mem: 7550\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 45, GT Count: 35\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 44, GT Count: 46\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 83, GT Count: 65\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 15, GT Count: 13\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 44, GT Count: 45\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 25, GT Count: 24\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 42, GT Count: 36\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 51, GT Count: 41\n",
      "Test:  [ 440/1190]  eta: 0:29:58    time: 3.3232  data: 0.0075  max mem: 7550\n",
      "input_captions: ['candy piece .']\n",
      "Pred Count: 36, GT Count: 36\n",
      "input_captions: ['candy piece .']\n",
      "Pred Count: 34, GT Count: 34\n",
      "input_captions: ['candy piece .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['round dessert .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['round dessert .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['candy piece .']\n",
      "Pred Count: 115, GT Count: 111\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 100, GT Count: 95\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 297, GT Count: 275\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 152, GT Count: 119\n",
      "Test:  [ 450/1190]  eta: 0:29:11    time: 2.1464  data: 0.0072  max mem: 7550\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 37, GT Count: 37\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 10, GT Count: 9\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 40, GT Count: 42\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 122, GT Count: 118\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 78, GT Count: 76\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 48, GT Count: 48\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 23, GT Count: 23\n",
      "Test:  [ 460/1190]  eta: 0:28:25    time: 0.9691  data: 0.0074  max mem: 7550\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 227, GT Count: 221\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 58, GT Count: 58\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 54, GT Count: 54\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 119, GT Count: 108\n",
      "input_captions: ['marble .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 92, GT Count: 94\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 89, GT Count: 86\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 119, GT Count: 118\n",
      "Test:  [ 470/1190]  eta: 0:27:45    time: 1.0970  data: 0.0075  max mem: 7550\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 28, GT Count: 28\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 61, GT Count: 59\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 14, GT Count: 11\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 41, GT Count: 37\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 10, GT Count: 8\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "Test:  [ 480/1190]  eta: 0:27:02    time: 1.1167  data: 0.0073  max mem: 7550\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 47, GT Count: 46\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['potato chip .']\n",
      "Pred Count: 35, GT Count: 34\n",
      "input_captions: ['potato chip .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['potato chip .']\n",
      "Pred Count: 37, GT Count: 36\n",
      "input_captions: ['potato chip .']\n",
      "Pred Count: 28, GT Count: 21\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 78, GT Count: 65\n",
      "Test:  [ 490/1190]  eta: 0:26:21    time: 0.9799  data: 0.0075  max mem: 7550\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 102, GT Count: 91\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 117, GT Count: 115\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 313, GT Count: 333\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 31, GT Count: 27\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 132, GT Count: 118\n",
      "input_captions: ['green pea .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 43, GT Count: 43\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 330, GT Count: 323\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['green pea .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 205, GT Count: 221\n",
      "Test:  [ 500/1190]  eta: 0:26:04    time: 1.8518  data: 0.0074  max mem: 7550\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 120, GT Count: 110\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 34, GT Count: 32\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 103, GT Count: 108\n",
      "input_captions: ['green pea .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 51, GT Count: 44\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 95, GT Count: 83\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 49, GT Count: 44\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 136, GT Count: 131\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 205, GT Count: 191\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 83, GT Count: 77\n",
      "Test:  [ 510/1190]  eta: 0:25:29    time: 2.0056  data: 0.0072  max mem: 7550\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 10, GT Count: 12\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['hot air balloon .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 66, GT Count: 69\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 14, GT Count: 13\n",
      "Test:  [ 520/1190]  eta: 0:24:53    time: 1.2518  data: 0.0073  max mem: 7550\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 66, GT Count: 63\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 31, GT Count: 30\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 12, GT Count: 15\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['hot air balloon .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['ski .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['ski .']\n",
      "Pred Count: 17, GT Count: 18\n",
      "input_captions: ['ski .']\n",
      "Pred Count: 27, GT Count: 26\n",
      "input_captions: ['ski .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 11, GT Count: 10\n",
      "Test:  [ 530/1190]  eta: 0:24:16    time: 1.1132  data: 0.0077  max mem: 7550\n",
      "input_captions: ['ski .']\n",
      "Pred Count: 16, GT Count: 13\n",
      "input_captions: ['ski .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['ski .']\n",
      "Pred Count: 14, GT Count: 12\n",
      "input_captions: ['ski .']\n",
      "Pred Count: 9, GT Count: 10\n",
      "input_captions: ['ski .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['ski .']\n",
      "Pred Count: 19, GT Count: 18\n",
      "input_captions: ['ski .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 71, GT Count: 68\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 40, GT Count: 40\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 39, GT Count: 42\n",
      "Test:  [ 540/1190]  eta: 0:23:42    time: 1.1297  data: 0.0077  max mem: 7550\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 43, GT Count: 44\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 134, GT Count: 126\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 78, GT Count: 76\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 34, GT Count: 32\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 33, GT Count: 35\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 29, GT Count: 28\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 17, GT Count: 15\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 94, GT Count: 101\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 13, GT Count: 11\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 36, GT Count: 37\n",
      "Test:  [ 550/1190]  eta: 0:23:09    time: 1.2612  data: 0.0074  max mem: 7550\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 29, GT Count: 32\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 15, GT Count: 14\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 28, GT Count: 27\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 69, GT Count: 64\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 28, GT Count: 27\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 52, GT Count: 50\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 32, GT Count: 28\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 89, GT Count: 83\n",
      "Test:  [ 560/1190]  eta: 0:22:36    time: 1.1787  data: 0.0074  max mem: 7550\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 37, GT Count: 35\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 49, GT Count: 51\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 13, GT Count: 14\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 18, GT Count: 16\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 268, GT Count: 250\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 79, GT Count: 78\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 17, GT Count: 16\n",
      "Test:  [ 570/1190]  eta: 0:22:02    time: 1.0435  data: 0.0078  max mem: 7550\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 15, GT Count: 14\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 29, GT Count: 30\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 49, GT Count: 39\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 82, GT Count: 87\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 99, GT Count: 91\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 38, GT Count: 37\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 91, GT Count: 95\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 32, GT Count: 31\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 59, GT Count: 20\n",
      "Test:  [ 580/1190]  eta: 0:21:28    time: 0.9831  data: 0.0080  max mem: 7550\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 14, GT Count: 13\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 31, GT Count: 31\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 71, GT Count: 67\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 142, GT Count: 142\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 42, GT Count: 40\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 69, GT Count: 63\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 39, GT Count: 40\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 37, GT Count: 36\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 66, GT Count: 74\n",
      "Test:  [ 590/1190]  eta: 0:20:59    time: 1.1429  data: 0.0077  max mem: 7550\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 61, GT Count: 58\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 57, GT Count: 56\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 55, GT Count: 54\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 71, GT Count: 58\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 21, GT Count: 20\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 34, GT Count: 31\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 176, GT Count: 175\n",
      "Test:  [ 600/1190]  eta: 0:20:27    time: 1.1663  data: 0.0080  max mem: 7550\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 45, GT Count: 56\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 68, GT Count: 65\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 55, GT Count: 49\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 41, GT Count: 41\n",
      "input_captions: ['tree log .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 75, GT Count: 71\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 222, GT Count: 205\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 19, GT Count: 18\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 113, GT Count: 95\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 38, GT Count: 33\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 176, GT Count: 166\n",
      "Test:  [ 610/1190]  eta: 0:20:02    time: 1.3132  data: 0.0086  max mem: 7550\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 249, GT Count: 247\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 57, GT Count: 51\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 37, GT Count: 29\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 146, GT Count: 145\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 111, GT Count: 102\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 117, GT Count: 93\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 101, GT Count: 118\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 33, GT Count: 31\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 28, GT Count: 29\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 399, GT Count: 363\n",
      "Test:  [ 620/1190]  eta: 0:19:32    time: 1.3352  data: 0.0094  max mem: 7550\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 223, GT Count: 218\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 54, GT Count: 51\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 51, GT Count: 46\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 26, GT Count: 19\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 121, GT Count: 109\n",
      "input_captions: ['tree log .']\n",
      "Pred Count: 52, GT Count: 44\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 42, GT Count: 30\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 193, GT Count: 193\n",
      "Test:  [ 630/1190]  eta: 0:19:05    time: 1.1810  data: 0.0091  max mem: 7550\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 64, GT Count: 63\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 77, GT Count: 87\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 45, GT Count: 46\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 37, GT Count: 36\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 112, GT Count: 111\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 33, GT Count: 33\n",
      "Test:  [ 640/1190]  eta: 0:18:37    time: 1.2722  data: 0.0082  max mem: 7550\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 66, GT Count: 65\n",
      "input_captions: ['marble .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 29, GT Count: 27\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 37, GT Count: 35\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 23, GT Count: 23\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 57, GT Count: 57\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 150, GT Count: 150\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 159, GT Count: 153\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 26, GT Count: 26\n",
      "Test:  [ 650/1190]  eta: 0:18:08    time: 1.1289  data: 0.0076  max mem: 7550\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 44, GT Count: 44\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 31, GT Count: 31\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 42, GT Count: 40\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 14, GT Count: 13\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 11, GT Count: 9\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "Test:  [ 660/1190]  eta: 0:17:40    time: 0.9913  data: 0.0071  max mem: 7550\n",
      "input_captions: ['finger food .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['finger food .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "Test:  [ 670/1190]  eta: 0:17:13    time: 1.0323  data: 0.0071  max mem: 7550\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 74, GT Count: 72\n",
      "input_captions: ['green pea .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 139, GT Count: 131\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 53, GT Count: 54\n",
      "input_captions: ['green pea .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 140, GT Count: 131\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 122, GT Count: 122\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 111, GT Count: 89\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 96, GT Count: 88\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 263, GT Count: 262\n",
      "Test:  [ 680/1190]  eta: 0:16:49    time: 1.2599  data: 0.0072  max mem: 7550\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 87, GT Count: 84\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 143, GT Count: 155\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 127, GT Count: 121\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 73, GT Count: 72\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 90, GT Count: 89\n",
      "input_captions: ['green pea .']\n",
      "Pred Count: 109, GT Count: 112\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 16, GT Count: 13\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 194, GT Count: 189\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "Test:  [ 690/1190]  eta: 0:16:22    time: 1.2110  data: 0.0072  max mem: 7550\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 9, GT Count: 8\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 33, GT Count: 33\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 51, GT Count: 51\n",
      "input_captions: ['finger food .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 26, GT Count: 26\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 100, GT Count: 90\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 70, GT Count: 67\n",
      "Test:  [ 700/1190]  eta: 0:15:55    time: 0.9899  data: 0.0074  max mem: 7550\n",
      "input_captions: ['marble .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 53, GT Count: 51\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 32, GT Count: 32\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 34, GT Count: 33\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 42, GT Count: 42\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 47, GT Count: 47\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 51, GT Count: 51\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 32, GT Count: 32\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "Test:  [ 710/1190]  eta: 0:15:32    time: 1.1465  data: 0.0073  max mem: 7550\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 50, GT Count: 49\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 32, GT Count: 32\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 94, GT Count: 93\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 23, GT Count: 23\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 40, GT Count: 40\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 134, GT Count: 128\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 23, GT Count: 23\n",
      "Test:  [ 720/1190]  eta: 0:15:06    time: 1.1462  data: 0.0075  max mem: 7550\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 33, GT Count: 33\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 158, GT Count: 149\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 22, GT Count: 22\n",
      "input_captions: ['marble .']\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 51, GT Count: 35\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 23, GT Count: 21\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 48, GT Count: 48\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 14, GT Count: 13\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 86, GT Count: 84\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 77, GT Count: 71\n",
      "Test:  [ 730/1190]  eta: 0:14:45    time: 1.3449  data: 0.0075  max mem: 7550\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 62, GT Count: 58\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 44, GT Count: 45\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 61, GT Count: 50\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 195, GT Count: 157\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 13, GT Count: 14\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 37, GT Count: 35\n",
      "input_captions: ['cashew nut .']\n",
      "Pred Count: 45, GT Count: 43\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 41, GT Count: 31\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 44, GT Count: 46\n",
      "Test:  [ 740/1190]  eta: 0:14:29    time: 2.0755  data: 0.0074  max mem: 7550\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 112, GT Count: 110\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 62, GT Count: 53\n",
      "input_captions: ['cashew nut .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 29, GT Count: 26\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 95, GT Count: 90\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 37, GT Count: 37\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 53, GT Count: 51\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 34, GT Count: 34\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 136, GT Count: 146\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 101, GT Count: 101\n",
      "Test:  [ 750/1190]  eta: 0:14:10    time: 2.1910  data: 0.0074  max mem: 7550\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 42, GT Count: 41\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 51, GT Count: 56\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 23, GT Count: 23\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 93, GT Count: 96\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 134, GT Count: 128\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 77, GT Count: 69\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 19, GT Count: 24\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 45, GT Count: 47\n",
      "Test:  [ 760/1190]  eta: 0:13:53    time: 2.1424  data: 0.0072  max mem: 7550\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 55, GT Count: 56\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 13, GT Count: 12\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 166, GT Count: 165\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 33, GT Count: 35\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 113, GT Count: 101\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 130, GT Count: 122\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 93, GT Count: 92\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 31, GT Count: 27\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 76, GT Count: 79\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "Test:  [ 770/1190]  eta: 0:13:28    time: 1.6465  data: 0.0073  max mem: 7550\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 98, GT Count: 113\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 48, GT Count: 45\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 112, GT Count: 111\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 48, GT Count: 51\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 49, GT Count: 52\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 73, GT Count: 74\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 65, GT Count: 75\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 60, GT Count: 57\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 36, GT Count: 34\n",
      "Test:  [ 780/1190]  eta: 0:13:09    time: 1.4612  data: 0.0073  max mem: 7550\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['strawberry .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 39, GT Count: 38\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 45, GT Count: 43\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 46, GT Count: 42\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 88, GT Count: 95\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 135, GT Count: 135\n",
      "input_captions: ['strawberry .']\n",
      "Pred Count: 82, GT Count: 78\n",
      "Test:  [ 790/1190]  eta: 0:12:45    time: 1.5024  data: 0.0074  max mem: 7550\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['egg .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 53, GT Count: 38\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['egg .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 45, GT Count: 39\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 37, GT Count: 35\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 15, GT Count: 13\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 17, GT Count: 16\n",
      "Test:  [ 800/1190]  eta: 0:12:23    time: 1.1693  data: 0.0075  max mem: 7550\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 22, GT Count: 22\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['egg .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 68, GT Count: 58\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 75, GT Count: 76\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 14, GT Count: 14\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "Test:  [ 810/1190]  eta: 0:12:00    time: 1.1545  data: 0.0075  max mem: 7550\n",
      "input_captions: ['egg .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 18, GT Count: 18\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 32, GT Count: 31\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 8, GT Count: 8\n",
      "input_captions: ['egg .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 30, GT Count: 27\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 45, GT Count: 48\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "Test:  [ 820/1190]  eta: 0:11:38    time: 1.1290  data: 0.0073  max mem: 7550\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 102, GT Count: 102\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 85, GT Count: 86\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 40, GT Count: 42\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 61, GT Count: 60\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 191, GT Count: 185\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 103, GT Count: 103\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 92, GT Count: 82\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 107, GT Count: 104\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 88, GT Count: 84\n",
      "Test:  [ 830/1190]  eta: 0:11:15    time: 1.0999  data: 0.0073  max mem: 7550\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 48, GT Count: 47\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 110, GT Count: 108\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 113, GT Count: 112\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 28, GT Count: 34\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 264, GT Count: 293\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 90, GT Count: 73\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 26, GT Count: 24\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 43, GT Count: 39\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 32, GT Count: 35\n",
      "Test:  [ 840/1190]  eta: 0:10:53    time: 1.0280  data: 0.0072  max mem: 7550\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 83, GT Count: 82\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 129, GT Count: 111\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 50, GT Count: 42\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 27, GT Count: 25\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 90, GT Count: 89\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 73, GT Count: 74\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 35, GT Count: 34\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 50, GT Count: 49\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 44, GT Count: 41\n",
      "Test:  [ 850/1190]  eta: 0:10:35    time: 1.6203  data: 0.0075  max mem: 7550\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 84, GT Count: 74\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 66, GT Count: 76\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 362, GT Count: 324\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 80, GT Count: 74\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 23, GT Count: 23\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 94, GT Count: 90\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "Test:  [ 860/1190]  eta: 0:10:18    time: 2.1835  data: 0.0077  max mem: 7550\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 104, GT Count: 95\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 49, GT Count: 50\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 97, GT Count: 92\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 251, GT Count: 240\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 132, GT Count: 118\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 36, GT Count: 34\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 45, GT Count: 32\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 37, GT Count: 36\n",
      "Test:  [ 870/1190]  eta: 0:10:00    time: 2.1039  data: 0.0075  max mem: 7550\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 46, GT Count: 42\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 48, GT Count: 45\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 41, GT Count: 41\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 707, GT Count: 675\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 71, GT Count: 66\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 23, GT Count: 21\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 95, GT Count: 89\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 104, GT Count: 101\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 134\n",
      "new count: 57.42857142857142\n",
      "Pred Count: 57.42857142857142, GT Count: 72\n",
      "Test:  [ 880/1190]  eta: 0:09:47    time: 2.7216  data: 0.0081  max mem: 7550\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 31\n",
      "new count: 15.5\n",
      "Pred Count: 15.5, GT Count: 18\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 33, GT Count: 16\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 22\n",
      "new count: 13.2\n",
      "Pred Count: 13.2, GT Count: 14\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 31, GT Count: 35\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 570, GT Count: 500\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 37, GT Count: 36\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 17, GT Count: 13\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 210, GT Count: 199\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 50, GT Count: 48\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 101, GT Count: 108\n",
      "Test:  [ 890/1190]  eta: 0:09:27    time: 2.5964  data: 0.0082  max mem: 7550\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 33, GT Count: 33\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 313, GT Count: 309\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 43, GT Count: 41\n",
      "input_captions: ['marker .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 231, GT Count: 240\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 102, GT Count: 100\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 124, GT Count: 123\n",
      "input_captions: ['marker .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 354, GT Count: 361\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 9, GT Count: 9\n",
      "Test:  [ 900/1190]  eta: 0:09:06    time: 1.5076  data: 0.0074  max mem: 7550\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 10, GT Count: 10\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 368, GT Count: 371\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 120, GT Count: 101\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 35, GT Count: 32\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 41, GT Count: 33\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 44, GT Count: 36\n",
      "Test:  [ 910/1190]  eta: 0:08:45    time: 1.1481  data: 0.0073  max mem: 7550\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 175, GT Count: 107\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 62, GT Count: 52\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 337, GT Count: 298\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 21, GT Count: 21\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 27, GT Count: 27\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 41, GT Count: 32\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 117, GT Count: 111\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 309, GT Count: 289\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 44, GT Count: 38\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "Test:  [ 920/1190]  eta: 0:08:24    time: 1.1728  data: 0.0073  max mem: 7550\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 23, GT Count: 22\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 75, GT Count: 70\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 135, GT Count: 93\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 74, GT Count: 81\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 225, GT Count: 191\n",
      "input_captions: ['sauce bottle .']\n",
      "Pred Count: 23, GT Count: 17\n",
      "input_captions: ['sauce bottle .']\n",
      "Pred Count: 54, GT Count: 50\n",
      "input_captions: ['sauce bottle .']\n",
      "Pred Count: 48, GT Count: 48\n",
      "input_captions: ['sauce bottle .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 30, GT Count: 25\n",
      "input_captions: ['sauce bottle .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 41, GT Count: 36\n",
      "Test:  [ 930/1190]  eta: 0:08:06    time: 1.6671  data: 0.0074  max mem: 7550\n",
      "input_captions: ['sauce bottle .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 17, GT Count: 14\n",
      "input_captions: ['sauce bottle .']\n",
      "Pred Count: 48, GT Count: 45\n",
      "input_captions: ['sauce bottle .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 40, GT Count: 31\n",
      "input_captions: ['sauce bottle .']\n",
      "Pred Count: 41, GT Count: 34\n",
      "input_captions: ['sauce bottle .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 26, GT Count: 23\n",
      "input_captions: ['sauce bottle .']\n",
      "Pred Count: 65, GT Count: 68\n",
      "input_captions: ['sauce bottle .']\n",
      "Pred Count: 46, GT Count: 43\n",
      "input_captions: ['sauce bottle .']\n",
      "Pred Count: 35, GT Count: 26\n",
      "input_captions: ['sauce bottle .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 71\n",
      "new count: 42.6\n",
      "Pred Count: 42.6, GT Count: 44\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 55, GT Count: 49\n",
      "Test:  [ 940/1190]  eta: 0:07:49    time: 2.2977  data: 0.0078  max mem: 7550\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 17, GT Count: 17\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 15, GT Count: 15\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 24, GT Count: 23\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 90, GT Count: 89\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 75, GT Count: 58\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 31, GT Count: 24\n",
      "Test:  [ 950/1190]  eta: 0:07:28    time: 1.7864  data: 0.0076  max mem: 7550\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 11, GT Count: 11\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 149, GT Count: 145\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 123, GT Count: 113\n",
      "input_captions: ['egg .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 115\n",
      "new count: 43.125\n",
      "Pred Count: 43.125, GT Count: 39\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 75, GT Count: 68\n",
      "input_captions: ['egg .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 33, GT Count: 26\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "Test:  [ 960/1190]  eta: 0:07:10    time: 1.4947  data: 0.0078  max mem: 7550\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 61, GT Count: 49\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 12, GT Count: 12\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 54, GT Count: 49\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 32, GT Count: 32\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 48, GT Count: 43\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 60, GT Count: 60\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 55, GT Count: 54\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 32, GT Count: 32\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 46, GT Count: 43\n",
      "Test:  [ 970/1190]  eta: 0:06:49    time: 1.4846  data: 0.0079  max mem: 7550\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 28, GT Count: 28\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 36, GT Count: 36\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 37, GT Count: 31\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 55, GT Count: 55\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 56, GT Count: 56\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 41, GT Count: 36\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 53, GT Count: 52\n",
      "input_captions: ['stamp .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 75, GT Count: 71\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 73, GT Count: 73\n",
      "Test:  [ 980/1190]  eta: 0:06:28    time: 0.9491  data: 0.0073  max mem: 7550\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 84, GT Count: 72\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 298, GT Count: 292\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 180, GT Count: 175\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 387, GT Count: 370\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 49, GT Count: 48\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 71, GT Count: 70\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 22, GT Count: 21\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 21, GT Count: 21\n",
      "Test:  [ 990/1190]  eta: 0:06:08    time: 0.9577  data: 0.0072  max mem: 7550\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 23, GT Count: 21\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 26, GT Count: 25\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 49, GT Count: 45\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 28, GT Count: 25\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 63, GT Count: 65\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 100, GT Count: 98\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 60, GT Count: 60\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 35, GT Count: 35\n",
      "Test:  [1000/1190]  eta: 0:05:48    time: 0.9899  data: 0.0077  max mem: 7550\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 40, GT Count: 40\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 125, GT Count: 120\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 37, GT Count: 36\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 51, GT Count: 49\n",
      "input_captions: ['sticky note .']\n",
      "Pred Count: 99, GT Count: 113\n",
      "input_captions: ['sticky note .']\n",
      "Pred Count: 62, GT Count: 56\n",
      "input_captions: ['sticky note .']\n",
      "Pred Count: 49, GT Count: 47\n",
      "input_captions: ['sticky note .']\n",
      "Pred Count: 50, GT Count: 47\n",
      "input_captions: ['sticky note .']\n",
      "Pred Count: 59, GT Count: 60\n",
      "Test:  [1010/1190]  eta: 0:05:28    time: 0.9988  data: 0.0077  max mem: 7550\n",
      "input_captions: ['sticky note .']\n",
      "Pred Count: 29, GT Count: 29\n",
      "input_captions: ['sticky note .']\n",
      "Pred Count: 116, GT Count: 121\n",
      "input_captions: ['sticky note .']\n",
      "Pred Count: 95, GT Count: 93\n",
      "input_captions: ['sticky note .']\n",
      "Pred Count: 74, GT Count: 75\n",
      "input_captions: ['sticky note .']\n",
      "Pred Count: 51, GT Count: 53\n",
      "input_captions: ['sticky note .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 93, GT Count: 94\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 41, GT Count: 40\n",
      "input_captions: ['nail polish .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 67, GT Count: 100\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 362, GT Count: 272\n",
      "Test:  [1020/1190]  eta: 0:05:09    time: 1.1553  data: 0.0073  max mem: 7550\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 95, GT Count: 95\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 44, GT Count: 44\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 119, GT Count: 118\n",
      "input_captions: ['nail polish .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 161, GT Count: 158\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 215, GT Count: 211\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 354, GT Count: 351\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 69, GT Count: 60\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 59, GT Count: 59\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 130, GT Count: 146\n",
      "Test:  [1030/1190]  eta: 0:04:50    time: 1.2558  data: 0.0074  max mem: 7550\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 43, GT Count: 43\n",
      "input_captions: ['nail polish .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 33, GT Count: 34\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 241, GT Count: 221\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 38, GT Count: 36\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 114, GT Count: 114\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 549, GT Count: 508\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 51, GT Count: 51\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 210\n",
      "new count: 105.0\n",
      "Pred Count: 105.0, GT Count: 141\n",
      "input_captions: ['sunglasses .']\n",
      "Pred Count: 170, GT Count: 144\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 199\n",
      "new count: 119.39999999999999\n",
      "Pred Count: 119.39999999999999, GT Count: 90\n",
      "Test:  [1040/1190]  eta: 0:04:33    time: 1.9662  data: 0.0073  max mem: 7550\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 368, GT Count: 253\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 160\n",
      "new count: 80.0\n",
      "Pred Count: 80.0, GT Count: 90\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 306\n",
      "new count: 153.0\n",
      "Pred Count: 153.0, GT Count: 194\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 87\n",
      "new count: 43.5\n",
      "Pred Count: 43.5, GT Count: 36\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 90\n",
      "new count: 45.0\n",
      "Pred Count: 45.0, GT Count: 45\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 143\n",
      "new count: 71.5\n",
      "Pred Count: 71.5, GT Count: 73\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 112\n",
      "new count: 56.0\n",
      "Pred Count: 56.0, GT Count: 60\n",
      "input_captions: ['watch .']\n",
      "Pred Count: 67, GT Count: 67\n",
      "input_captions: ['watch .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 42, GT Count: 29\n",
      "input_captions: ['watch .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "Test:  [1050/1190]  eta: 0:04:19    time: 3.9153  data: 0.0072  max mem: 7550\n",
      "input_captions: ['watch .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['watch .']\n",
      "Pred Count: 32, GT Count: 32\n",
      "input_captions: ['watch .']\n",
      "Pred Count: 69, GT Count: 58\n",
      "input_captions: ['sheep .']\n",
      "Pred Count: 45, GT Count: 44\n",
      "input_captions: ['sheep .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 120, GT Count: 117\n",
      "input_captions: ['sheep .']\n",
      "Pred Count: 134, GT Count: 128\n",
      "input_captions: ['sheep .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 140, GT Count: 198\n",
      "input_captions: ['sheep .']\n",
      "Pred Count: 31, GT Count: 31\n",
      "input_captions: ['sheep .']\n",
      "Pred Count: 210, GT Count: 195\n",
      "input_captions: ['sheep .']\n",
      "Pred Count: 95, GT Count: 122\n",
      "Test:  [1060/1190]  eta: 0:04:00    time: 3.0310  data: 0.0074  max mem: 7550\n",
      "input_captions: ['sheep .']\n",
      "Pred Count: 120, GT Count: 109\n",
      "input_captions: ['sheep .']\n",
      "Pred Count: 175, GT Count: 180\n",
      "input_captions: ['sheep .']\n",
      "Pred Count: 70, GT Count: 67\n",
      "input_captions: ['sheep .']\n",
      "Pred Count: 80, GT Count: 81\n",
      "input_captions: ['sheep .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 176, GT Count: 166\n",
      "input_captions: ['sheep .']\n",
      "Pred Count: 52, GT Count: 51\n",
      "input_captions: ['sheep .']\n",
      "Pred Count: 220, GT Count: 190\n",
      "input_captions: ['sheep .']\n",
      "Pred Count: 221, GT Count: 209\n",
      "input_captions: ['sheep .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 20, GT Count: 20\n",
      "input_captions: ['sheep .']\n",
      "Pred Count: 77, GT Count: 75\n",
      "Test:  [1070/1190]  eta: 0:03:40    time: 1.0134  data: 0.0074  max mem: 7550\n",
      "input_captions: ['deer .']\n",
      "Pred Count: 22, GT Count: 22\n",
      "input_captions: ['deer .']\n",
      "Pred Count: 19, GT Count: 18\n",
      "input_captions: ['deer .']\n",
      "Pred Count: 24, GT Count: 21\n",
      "input_captions: ['deer .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 31\n",
      "new count: 15.5\n",
      "Pred Count: 15.5, GT Count: 16\n",
      "input_captions: ['deer .']\n",
      "Pred Count: 13, GT Count: 10\n",
      "input_captions: ['deer .']\n",
      "Pred Count: 17, GT Count: 15\n",
      "input_captions: ['deer .']\n",
      "Pred Count: 34, GT Count: 31\n",
      "input_captions: ['deer .']\n",
      "Pred Count: 80, GT Count: 77\n",
      "input_captions: ['deer .']\n",
      "Pred Count: 16, GT Count: 17\n",
      "input_captions: ['deer .']\n",
      "Pred Count: 21, GT Count: 21\n",
      "Test:  [1080/1190]  eta: 0:03:21    time: 1.0636  data: 0.0074  max mem: 7550\n",
      "input_captions: ['deer .']\n",
      "Pred Count: 44, GT Count: 39\n",
      "input_captions: ['elephant .']\n",
      "Pred Count: 21, GT Count: 20\n",
      "input_captions: ['elephant .']\n",
      "Pred Count: 29, GT Count: 26\n",
      "input_captions: ['elephant .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 28, GT Count: 27\n",
      "input_captions: ['elephant .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 74\n",
      "new count: 44.4\n",
      "Pred Count: 44.4, GT Count: 63\n",
      "input_captions: ['elephant .']\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['elephant .']\n",
      "Pred Count: 15, GT Count: 16\n",
      "input_captions: ['elephant .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 13, GT Count: 13\n",
      "input_captions: ['elephant .']\n",
      "Pred Count: 23, GT Count: 22\n",
      "input_captions: ['elephant .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "Test:  [1090/1190]  eta: 0:03:02    time: 1.0936  data: 0.0074  max mem: 7550\n",
      "input_captions: ['elephant .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 25, GT Count: 23\n",
      "input_captions: ['elephant .']\n",
      "Pred Count: 24, GT Count: 23\n",
      "input_captions: ['elephant .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 35\n",
      "new count: 21.0\n",
      "Pred Count: 21.0, GT Count: 36\n",
      "input_captions: ['elephant .']\n",
      "Pred Count: 42, GT Count: 38\n",
      "input_captions: ['elephant .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 27, GT Count: 22\n",
      "input_captions: ['elephant .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 16, GT Count: 11\n",
      "input_captions: ['elephant .']\n",
      "Pred Count: 105, GT Count: 107\n",
      "input_captions: ['elephant .']\n",
      "Pred Count: 24, GT Count: 21\n",
      "input_captions: ['lego .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 34, GT Count: 23\n",
      "input_captions: ['lego .']\n",
      "Pred Count: 356, GT Count: 384\n",
      "Test:  [1100/1190]  eta: 0:02:43    time: 1.1869  data: 0.0073  max mem: 7550\n",
      "input_captions: ['lego .']\n",
      "Pred Count: 30, GT Count: 30\n",
      "input_captions: ['lego .']\n",
      "Pred Count: 506, GT Count: 512\n",
      "input_captions: ['lego .']\n",
      "Pred Count: 20, GT Count: 15\n",
      "input_captions: ['lego .']\n",
      "Pred Count: 98, GT Count: 96\n",
      "input_captions: ['lego .']\n",
      "Pred Count: 100, GT Count: 100\n",
      "input_captions: ['lego .']\n",
      "Pred Count: 28, GT Count: 32\n",
      "input_captions: ['lego .']\n",
      "Pred Count: 258, GT Count: 256\n",
      "input_captions: ['lego .']\n",
      "Pred Count: 101, GT Count: 100\n",
      "input_captions: ['carrom board piece .']\n",
      "Pred Count: 20, GT Count: 19\n",
      "input_captions: ['carrom board piece .']\n",
      "Pred Count: 22, GT Count: 19\n",
      "Test:  [1110/1190]  eta: 0:02:25    time: 1.1061  data: 0.0071  max mem: 7550\n",
      "input_captions: ['carrom board piece .']\n",
      "Pred Count: 21, GT Count: 19\n",
      "input_captions: ['carrom board piece .']\n",
      "Pred Count: 21, GT Count: 18\n",
      "input_captions: ['carrom board piece .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['carrom board piece .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['carrom board piece .']\n",
      "Pred Count: 21, GT Count: 19\n",
      "input_captions: ['carrom board piece .']\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['carrom board piece .']\n",
      "Pred Count: 16, GT Count: 13\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 87, GT Count: 87\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 78, GT Count: 77\n",
      "input_captions: ['keyboard key .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 86, GT Count: 84\n",
      "Test:  [1120/1190]  eta: 0:02:06    time: 1.0110  data: 0.0072  max mem: 7550\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 77, GT Count: 78\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 105, GT Count: 104\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 77, GT Count: 78\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 79, GT Count: 79\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 83, GT Count: 83\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 104, GT Count: 104\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 169\n",
      "new count: 72.42857142857143\n",
      "Pred Count: 72.42857142857143, GT Count: 96\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 71\n",
      "new count: 35.5\n",
      "Pred Count: 35.5, GT Count: 40\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 129\n",
      "new count: 77.39999999999999\n",
      "Pred Count: 77.39999999999999, GT Count: 64\n",
      "input_captions: ['sunglasses .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Using TT-Norm\n",
      "orig count: 111\n",
      "new count: 66.6\n",
      "Pred Count: 66.6, GT Count: 64\n",
      "Test:  [1130/1190]  eta: 0:01:49    time: 2.2704  data: 0.0077  max mem: 7550\n",
      "input_captions: ['comic book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 45, GT Count: 44\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 48, GT Count: 47\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 42, GT Count: 42\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 253, GT Count: 233\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 108, GT Count: 104\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 218, GT Count: 217\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 76, GT Count: 72\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 123, GT Count: 110\n",
      "input_captions: ['marker .']\n",
      "Pred Count: 240, GT Count: 212\n",
      "input_captions: ['carrom board piece .']\n",
      "Pred Count: 22, GT Count: 19\n",
      "Test:  [1140/1190]  eta: 0:01:30    time: 2.3849  data: 0.0084  max mem: 7550\n",
      "input_captions: ['carrom board piece .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 31, GT Count: 29\n",
      "input_captions: ['carrom board piece .']\n",
      "Pred Count: 33, GT Count: 24\n",
      "input_captions: ['sauce bottle .']\n",
      "Pred Count: 16, GT Count: 16\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 41, GT Count: 41\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 37, GT Count: 25\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 166, GT Count: 159\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 66, GT Count: 59\n",
      "input_captions: ['lego .']\n",
      "Pred Count: 188, GT Count: 36\n",
      "input_captions: ['lego .']\n",
      "Pred Count: 0, GT Count: 13\n",
      "input_captions: ['lego .']\n",
      "Pred Count: 900, GT Count: 2560\n",
      "Test:  [1150/1190]  eta: 0:01:12    time: 1.2463  data: 0.0086  max mem: 7550\n",
      "input_captions: ['lego .']\n",
      "Pred Count: 86, GT Count: 85\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 108, GT Count: 108\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 129, GT Count: 123\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 111, GT Count: 124\n",
      "input_captions: ['keyboard key .']\n",
      "Pred Count: 48, GT Count: 48\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 93, GT Count: 92\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 51, GT Count: 39\n",
      "input_captions: ['apple .']\n",
      "refining tt norm with SAM\n",
      "refining tt norm with SAM\n",
      "Pred Count: 19, GT Count: 19\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 152, GT Count: 140\n",
      "input_captions: ['apple .']\n",
      "Pred Count: 22, GT Count: 22\n",
      "Test:  [1160/1190]  eta: 0:00:54    time: 1.4586  data: 0.0081  max mem: 7550\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 81, GT Count: 78\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 47, GT Count: 46\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 67, GT Count: 67\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 47, GT Count: 47\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 48, GT Count: 48\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 28, GT Count: 28\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 24, GT Count: 24\n",
      "input_captions: ['egg .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 39, GT Count: 35\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 91, GT Count: 85\n",
      "input_captions: ['egg .']\n",
      "Pred Count: 39, GT Count: 38\n",
      "Test:  [1170/1190]  eta: 0:00:36    time: 1.4918  data: 0.0078  max mem: 7550\n",
      "input_captions: ['comic book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 25, GT Count: 23\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 25, GT Count: 25\n",
      "input_captions: ['comic book .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 40, GT Count: 34\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 36, GT Count: 33\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 49, GT Count: 45\n",
      "input_captions: ['comic book .']\n",
      "Pred Count: 142, GT Count: 143\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 66, GT Count: 66\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 105, GT Count: 103\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 72, GT Count: 72\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 215, GT Count: 211\n",
      "Test:  [1180/1190]  eta: 0:00:18    time: 1.3209  data: 0.0071  max mem: 7550\n",
      "input_captions: ['nail polish .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 119, GT Count: 114\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 33, GT Count: 33\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 88, GT Count: 87\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 98, GT Count: 98\n",
      "input_captions: ['nail polish .']\n",
      "Pred Count: 89, GT Count: 87\n",
      "input_captions: ['sheep .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 200, GT Count: 181\n",
      "input_captions: ['sheep .']\n",
      "Pred Count: 54, GT Count: 54\n",
      "input_captions: ['sheep .']\n",
      "refining tt norm with SAM\n",
      "Pred Count: 37, GT Count: 36\n",
      "input_captions: ['sheep .']\n",
      "Pred Count: 41, GT Count: 38\n",
      "Test:  [1189/1190]  eta: 0:00:01    time: 1.2547  data: 0.0073  max mem: 7550\n",
      "Test: Total time: 0:35:40 (1.7984 s / it)\n",
      "# of Images Tested: 1190\n",
      "MAE: 8.84280612244898, RMSE: 95.16586508923993\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=6 torchrun --nproc_per_node=1 --master_port=29501 main_inference.py --output_dir ./gdino_test \\\n",
    "-c config/cfg_fsc147_test.py --eval --datasets config/datasets_fsc147_test.json \\\n",
    "--pretrain_model_path ./gdino_train/checkpoint_best_regular.pth --options text_encoder_type=checkpoints/bert-base-uncased \\\n",
    "--sam_tt_norm --remove_bad_exemplar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
